{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1\n"
     ]
    }
   ],
   "source": [
    "#nltk\n",
    "import nltk\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natachaperez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/natachaperez/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/natachaperez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./natachaenv/lib/python3.8/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./natachaenv/lib/python3.8/site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in ./natachaenv/lib/python3.8/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./natachaenv/lib/python3.8/site-packages (from gensim) (6.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.2\n"
     ]
    }
   ],
   "source": [
    "#gensim\n",
    "#pip install cython\n",
    "#pip install Xcode Command Line Tools\n",
    "#python setup.py build_ext --inplace\n",
    "#pip install gensim\n",
    "import gensim\n",
    "print(gensim.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction d'un data frame contenant l'ensembles des données de la BD, en utilisant du SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "connexion = sqlite3.connect('Database.db')\n",
    "cursor = connexion.cursor()\n",
    "\n",
    "query = '''SELECT \n",
    "    offres.intitule,\n",
    "    offres.description_offre,\n",
    "    offres.date_creation,\n",
    "    offres.salaire_min_annuel,\n",
    "    offres.salaire_max_annuel,\n",
    "    offres.salaire_annuel_mean,\n",
    "    offres.qualification_libelle,\n",
    "    offres.experience,\n",
    "    offres.type_contrat,\n",
    "    offres.secteur_activite,\n",
    "    d_ville.ville,\n",
    "    d_ville.latitude,\n",
    "    d_ville.longitude,\n",
    "    d_ville.code_postal,\n",
    "    d_ville.departement AS ville_departement,\n",
    "    d_entreprise.entreprise_nom,\n",
    "    d_entreprise.entreprise_description,\n",
    "    h_departement.departement,\n",
    "    h_departement.departement_nom,\n",
    "    h_departement.region\n",
    "        \n",
    "    FROM offres\n",
    "    JOIN d_ville ON offres.id_ville = d_ville.id\n",
    "    JOIN d_entreprise ON offres.id_entreprise = d_entreprise.id\n",
    "    JOIN h_departement ON d_ville.departement = h_departement.departement;\n",
    "'''\n",
    "df = pd.read_sql_query(query, connexion)\n",
    "\n",
    "connexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intitule</th>\n",
       "      <th>description_offre</th>\n",
       "      <th>date_creation</th>\n",
       "      <th>salaire_min_annuel</th>\n",
       "      <th>salaire_max_annuel</th>\n",
       "      <th>salaire_annuel_mean</th>\n",
       "      <th>qualification_libelle</th>\n",
       "      <th>experience</th>\n",
       "      <th>type_contrat</th>\n",
       "      <th>secteur_activite</th>\n",
       "      <th>ville</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>ville_departement</th>\n",
       "      <th>entreprise_nom</th>\n",
       "      <th>entreprise_description</th>\n",
       "      <th>departement</th>\n",
       "      <th>departement_nom</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer F/H (H/F)</td>\n",
       "      <td>Le saviez-vous ?\\n\\nNous rejoindre, c'est rejo...</td>\n",
       "      <td>29/12/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Autres activités informatiques</td>\n",
       "      <td>MASSY</td>\n",
       "      <td>49.687882</td>\n",
       "      <td>1.395968</td>\n",
       "      <td>76270.0</td>\n",
       "      <td>seine-maritime</td>\n",
       "      <td>None</td>\n",
       "      <td>Nous rejoindre, c'est rejoindre l'un des leade...</td>\n",
       "      <td>seine-maritime</td>\n",
       "      <td>None</td>\n",
       "      <td>normandie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer H/F</td>\n",
       "      <td>Rejoindre le Groupe IRCEM, c'est participer à ...</td>\n",
       "      <td>29/12/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>None</td>\n",
       "      <td>ROUBAIX</td>\n",
       "      <td>50.688369</td>\n",
       "      <td>3.181903</td>\n",
       "      <td>59100.0</td>\n",
       "      <td>nord</td>\n",
       "      <td>IRCEM</td>\n",
       "      <td>None</td>\n",
       "      <td>nord</td>\n",
       "      <td>None</td>\n",
       "      <td>hauts-de-france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analytics Engineer F/H - Marketing (H/F)</td>\n",
       "      <td>Descriptif du poste:\\n\\nRôle : L Analytics Eng...</td>\n",
       "      <td>29/12/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Restauration de type rapide</td>\n",
       "      <td>ORLY</td>\n",
       "      <td>48.742795</td>\n",
       "      <td>2.394977</td>\n",
       "      <td>94310.0</td>\n",
       "      <td>val-de-marne</td>\n",
       "      <td>CPF</td>\n",
       "      <td>Depuis 2002, Amorino émerveille les gourmands ...</td>\n",
       "      <td>val-de-marne</td>\n",
       "      <td>None</td>\n",
       "      <td>île-de-france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA ENGINEER - H/F</td>\n",
       "      <td>Description :\\n\\n\\nvous rejoindrez une équipe ...</td>\n",
       "      <td>28/12/2023</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Administration publique (tutelle) des activité...</td>\n",
       "      <td>ORLEANS</td>\n",
       "      <td>47.873504</td>\n",
       "      <td>1.917316</td>\n",
       "      <td>45100.0</td>\n",
       "      <td>loiret</td>\n",
       "      <td>DSI Pôle Emploi</td>\n",
       "      <td>None</td>\n",
       "      <td>loiret</td>\n",
       "      <td>None</td>\n",
       "      <td>centre-val de loire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA ENGINEER - H/F</td>\n",
       "      <td>Description :\\n\\n\\nvous rejoindrez une équipe ...</td>\n",
       "      <td>28/12/2023</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Administration publique (tutelle) des activité...</td>\n",
       "      <td>AIX EN PROVENCE</td>\n",
       "      <td>43.536112</td>\n",
       "      <td>5.398630</td>\n",
       "      <td>13080.0</td>\n",
       "      <td>bouches-du-rhône</td>\n",
       "      <td>DSI Pôle Emploi</td>\n",
       "      <td>None</td>\n",
       "      <td>bouches-du-rhône</td>\n",
       "      <td>None</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   intitule  \\\n",
       "0            Senior Data Engineer F/H (H/F)   \n",
       "1                         Data Engineer H/F   \n",
       "2  Analytics Engineer F/H - Marketing (H/F)   \n",
       "3                       DATA ENGINEER - H/F   \n",
       "4                       DATA ENGINEER - H/F   \n",
       "\n",
       "                                   description_offre date_creation  \\\n",
       "0  Le saviez-vous ?\\n\\nNous rejoindre, c'est rejo...    29/12/2023   \n",
       "1  Rejoindre le Groupe IRCEM, c'est participer à ...    29/12/2023   \n",
       "2  Descriptif du poste:\\n\\nRôle : L Analytics Eng...    29/12/2023   \n",
       "3  Description :\\n\\n\\nvous rejoindrez une équipe ...    28/12/2023   \n",
       "4  Description :\\n\\n\\nvous rejoindrez une équipe ...    28/12/2023   \n",
       "\n",
       "  salaire_min_annuel salaire_max_annuel salaire_annuel_mean  \\\n",
       "0               None               None                None   \n",
       "1               None               None                None   \n",
       "2               None               None                None   \n",
       "3            45000.0            55000.0             50000.0   \n",
       "4            45000.0            55000.0             50000.0   \n",
       "\n",
       "  qualification_libelle experience type_contrat  \\\n",
       "0                  None        oui          CDI   \n",
       "1                  None        oui          CDI   \n",
       "2                 Cadre        oui          CDI   \n",
       "3                  None        oui          CDI   \n",
       "4                  None        oui          CDI   \n",
       "\n",
       "                                    secteur_activite            ville  \\\n",
       "0                     Autres activités informatiques            MASSY   \n",
       "1                                               None          ROUBAIX   \n",
       "2                        Restauration de type rapide             ORLY   \n",
       "3  Administration publique (tutelle) des activité...          ORLEANS   \n",
       "4  Administration publique (tutelle) des activité...  AIX EN PROVENCE   \n",
       "\n",
       "    latitude  longitude code_postal ville_departement   entreprise_nom  \\\n",
       "0  49.687882   1.395968     76270.0    seine-maritime             None   \n",
       "1  50.688369   3.181903     59100.0              nord            IRCEM   \n",
       "2  48.742795   2.394977     94310.0      val-de-marne              CPF   \n",
       "3  47.873504   1.917316     45100.0            loiret  DSI Pôle Emploi   \n",
       "4  43.536112   5.398630     13080.0  bouches-du-rhône  DSI Pôle Emploi   \n",
       "\n",
       "                              entreprise_description       departement  \\\n",
       "0  Nous rejoindre, c'est rejoindre l'un des leade...    seine-maritime   \n",
       "1                                               None              nord   \n",
       "2  Depuis 2002, Amorino émerveille les gourmands ...      val-de-marne   \n",
       "3                                               None            loiret   \n",
       "4                                               None  bouches-du-rhône   \n",
       "\n",
       "  departement_nom                      region  \n",
       "0            None                   normandie  \n",
       "1            None             hauts-de-france  \n",
       "2            None               île-de-france  \n",
       "3            None         centre-val de loire  \n",
       "4            None  provence-alpes-côte d'azur  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Senior Data Engineer F/H (H/F)', 'Data Engineer H/F',\n",
       "       'Analytics Engineer F/H - Marketing (H/F)', 'DATA ENGINEER - H/F',\n",
       "       'DATA ENGINEER GCP - Java (H/F)', 'DATA ENGINEER (H/F)',\n",
       "       'DATA ENGINEER CLOUD (H/F/NB)', 'Data Engineer/BI (H/F)',\n",
       "       'Data Engineer - (H/F)', 'Data Engineer Hadoop / POEI (H/F)',\n",
       "       'Data Engineer (H/F)', 'Data Engineer- F/H - Comptabilité (H/F)',\n",
       "       'Data engineer F/H - Système, réseaux, données (H/F)',\n",
       "       'Technical Data Engineer Confirmed (H/F)',\n",
       "       'Data Engineer Senior (H/F)',\n",
       "       'Technical Data Engineer Senior (H/F)',\n",
       "       'Technical Data Engineer (H/F)',\n",
       "       'Data Engineer AWS Spark - Nantes (IT) / Freelance (H/F)',\n",
       "       'DATA ENGINEER - BUSINESS INTELLIGENCE (H/F)',\n",
       "       'Senior Data Engineer (H/F)', 'DATA ENGINEER H/F',\n",
       "       'Data Engineer / DevOps F/H - Informatique de gestion (H/F)',\n",
       "       'Data Engineer - Spark Scala Hadoop (H/F)',\n",
       "       'DATA ENGINEER CLOUD (H/F)', 'Data engineer  F/H - Halpades (H/F)',\n",
       "       'Senior Data Engineer F/H - Système, réseaux, données (H/F)',\n",
       "       'Data Engineer F/H - Système, réseaux, données (H/F)',\n",
       "       'Data Engineer ((H/F))', 'Data Engineer Cloud & ETL (H/F)',\n",
       "       'Data Architect / Data Engineer / Data Scientist - Avignon (H/F)',\n",
       "       'Data Architect / Data Engineer / Data Scientist - Valence (H/F)',\n",
       "       'Data Engineer/Dataiku en remote F/H - Système, réseaux, données (H/F)',\n",
       "       'Data Engineer/Dataiku en remote (H/F)',\n",
       "       'DATA ENGINEER H/F (IT) / Freelance',\n",
       "       'Data Engineer Spark/Scala (H/F)',\n",
       "       'Data Engineer - H/F - CDI (H/F)', 'Data Engineer F/H (H/F)',\n",
       "       'Alternant Data Engineer KALTDE1 F/H - Système, réseaux, données (H/F)',\n",
       "       'Expert Data Engineer (H/F)', 'Data Engineer Lyon H/F (H/F)',\n",
       "       'Data Engineer Ile-de-France H/F (H/F)',\n",
       "       'Data Engineer Spark/Scala F/H - Système, réseaux, données (H/F)',\n",
       "       'Data Analyst/Engineer (H/F)', 'Data engineer H/F',\n",
       "       'Data Engineer - Lille F/H - Système, réseaux, données (H/F)',\n",
       "       'DATA ENGINEER F/H - Système, réseaux, données (H/F)',\n",
       "       'Consultante ou Consultant Data Engineer F/H - Valoway (H/F)',\n",
       "       'Consultante ou Consultant Data Engineer confirmé F/H - Valoway (H/F)',\n",
       "       'DATA Engineer AWS ( 2 ans à 5 ans) (IT) / Freelance (H/F)',\n",
       "       'Data engineer Talend F/H - Tebubio (H/F)',\n",
       "       'data engineer pyspark databricks powerbi (IT) / Freelance (H/F)',\n",
       "       'Data Engineer / Développeur BI BigData H/F',\n",
       "       'Data Engineer Java / Scala (H/F)', 'Data Engineer  (H/F)',\n",
       "       'SENIOR DATA ENGINEER GCP - H/F',\n",
       "       'Lead Data Scientist - Demand Forecast H/F',\n",
       "       'DATA SCIENTIST (H/F)', 'CDI CLINICAL DATA SCIENTIST (H/F)',\n",
       "       '(SENIOR) DATA SCIENTIST (H/F)', 'SENIOR DATA SCIENTIST - H/F',\n",
       "       'Lead data scientist - Search & Recommandation (F/H) (H/F)',\n",
       "       'Data scientist (H/F)', 'Consultant Data - AIX ((H/F))',\n",
       "       'Data Steward - Responsable gestion de données F/H - Système, réseaux, données (H/F)',\n",
       "       'STAGE_Marketing strategy and tech analyst F/H (H/F)',\n",
       "       'Ingénieur Data Scientist H/F',\n",
       "       'Alternant Data Scientist F/H - Système, réseaux, données (H/F)',\n",
       "       'Stagiaire Project Manager Dashboard Ops e-commerce F/H (H/F)',\n",
       "       'Data Scientist Stagiaire H/F',\n",
       "       'Consultante - Consultant Data Scientist confirmé F/H - Valoway (H/F)',\n",
       "       'Consultante - Consultant Data Scientist F/H - Valoway (H/F)',\n",
       "       'Data Scientist / Data Analyst (H/F)', 'Data scientist H/F',\n",
       "       'Data Scientist junior (H/F)',\n",
       "       'Data Scientist F/H - Système, réseaux, données (H/F)',\n",
       "       'Data & AI Strategy Manager F/H (H/F)', 'Ingénieur Talend (H/F)',\n",
       "       'Développeur Java F/H (H/F)',\n",
       "       'Software Engineering Manager (F/H) (H/F)',\n",
       "       'Développeur BI/Data Scientist H/F', 'Data Scientist (H/F)',\n",
       "       'Data Scientist F/H - SHOPOPOP (H/F)', 'Data Scientist H/F',\n",
       "       'Data scientist', 'Data Scientist - AIX EN PROVENCE (H/F)',\n",
       "       'CDI- Senior Data Scientist (H/F) - Gif-sur-Yvette (91)',\n",
       "       'DATA SCIENTIST H/F', 'Ingénieur Data (débutant) - F/H (H/F)',\n",
       "       'Expert big data / Hadoop / Cloudera (Rodez) H/F (IT) / Freelance',\n",
       "       'Data analyste informatique (H/F) (IT) / Freelance',\n",
       "       'Ingénieur Data Scientist expérimenté - (H/F)',\n",
       "       \"Ingénieur data scientist \\x96 ia dans l'industrie  f/h (H/F)\",\n",
       "       'Data Scientist H/F (H/F)',\n",
       "       'Data Scientist - Secteur Lifesciences F/H - Système, réseaux, données (H/F)',\n",
       "       'Data scientist F/H - Système, réseaux, données (H/F)',\n",
       "       'Ingénieur Data Talend expériementé (H/F)',\n",
       "       'SAP Master Data Expert F/H - Système, réseaux, données (H/F)',\n",
       "       'Ingénieur Data Analyst H/F', 'Data Analyst (F/H) (H/F)',\n",
       "       'Consultant Data Scientist - Banque et Assurance - Paris F/H - Système, réseaux, données (H/F)',\n",
       "       'Data Scientist Senior F/H - Système, réseaux, données (H/F)',\n",
       "       'DATA Scientist - LYON F/H - Système, réseaux, données (H/F)',\n",
       "       'Data scientist / Alternance (H/F)',\n",
       "       'DATA analyste informatique EXPERT SQL (IT) / Freelance (H/F)',\n",
       "       'Responsable de Pôle Data H/F', 'Data Scientist F/H (H/F)',\n",
       "       'Data Analyst RSE confirmé F/H (H/F)',\n",
       "       'Data Scientist - H/F - CDI (H/F)',\n",
       "       'Data scientist spécialisé en données de santé (H/F)',\n",
       "       'Data Scientist ((H/F))', 'AI/Data Scientist F/H (H/F)',\n",
       "       \"Data scientist disposant d une forte culture scientifique en agronomie F/H - Maîtrise d'ouvrage et fonctionnel (H/F)\",\n",
       "       'Data Scientist spécialisé(e) en agronomie F/H - Système, réseaux, données (H/F)',\n",
       "       'Alternant Data Scientist F/H - EFFi GEMY (H/F)',\n",
       "       'Data scientist Montpellier Python,Terraform, Bitbucket, Jenkins, Airflow, Docker, Kubernetes, GCP (IT) / Freelance (H/F)',\n",
       "       'Data analyste informatique Python Montpellier (IT) / Freelance (H/F)',\n",
       "       'Data Analyst - H/F',\n",
       "       'Data Scientist (GPS & Geo experience) H/F (IT) / Freelance',\n",
       "       'CDI - DATA ANALYST SENIOR DROM - (F/H/X) (H/F)',\n",
       "       'Data analyste informatique (IT) / Freelance (H/F)',\n",
       "       'data analyste informatique UML (IT) / Freelance (H/F)',\n",
       "       'Lead data analyste informatique (H/F) (IT) / Freelance',\n",
       "       'Consultant Data (H/F)',\n",
       "       'Data Scientist F/H - Réseau Primever France (H/F)',\n",
       "       'Data scientist f/h (H/F)',\n",
       "       \"Data scientist bureau d'etudes « support et services » f/h (H/F)\",\n",
       "       'Data Scientist en Recherche Appliquée - Confirmé (H/F)',\n",
       "       'CDI - Global Finance Data Analyst (W/M) (H/F)',\n",
       "       'Data Scientist / Développeur.se Dataiku (H/F)',\n",
       "       'POEI DATA SCIENTIST (H/F)',\n",
       "       'Technical leader data scientist f/h (H/F)',\n",
       "       'Data ingénieur - F/H', 'Data Ingénieur (Nantes) F/H',\n",
       "       'Data Engineer senior F/H', 'Data Engineer Senior F/H',\n",
       "       'Data Engineer F/H', 'Data Engineer - Power BI F/H',\n",
       "       'Azure Data Engineer F/H', 'Big Data Engineer F/H',\n",
       "       'Lead Data Engineer F/H', 'Data Engineer - F/H',\n",
       "       'Data Engineer/Dataiku en remote F/H', 'LEAD DATA ENGINEER F/H',\n",
       "       'Chef de projet Data ? Data Engineer F/H', 'Data engineer F/H',\n",
       "       'Data Engineer Spark/Scala F/H', 'Lead Data Engineer - F/H',\n",
       "       'Data Engineer /X F/H', 'Data Engineer Python & Databricks F/H',\n",
       "       'Consultante ou Consultant Data Engineer F/H',\n",
       "       'Data Engineer Confirmé(e) F/H', 'Data Engineer GCP F/H',\n",
       "       'DATA Engineer F/H', 'Data engineer Greentech Nantes F/H',\n",
       "       'Lead Data Engineer / Architect F/H', 'Data Engineer Talend F/H',\n",
       "       'Data Analyst / Data engineer F/H', 'Data Engineer AirFlow F/H',\n",
       "       'Data Engineer AWS F/H', 'Data engineer BI DATA - F/H',\n",
       "       'Data Engineer - data factory F/H', 'Data engineer confirmé - F/H',\n",
       "       'Data Engineer Confirmé - Databricks - Leader Transport et Logistique F/H',\n",
       "       'Data Architect / Data Engineer / Data Scientist - Valence F/H',\n",
       "       'Data Architect / Data Engineer / Data Scientist - Avignon F/H',\n",
       "       'Data engineer gcp confirmé F/H',\n",
       "       'Data Engineer-Cloud Confirmé.e PAU F/H', 'Data Engineer- F/H',\n",
       "       'DATA SCIENTIST F/H', 'Ingénieur Data Scientist F/H',\n",
       "       'Senior Data Scientist F/H',\n",
       "       'DATA SCIENTIST pour le Data Lab IGAD F/H',\n",
       "       'DATA Scientist - LYON F/H', 'Data Scientist - Lyon F/H',\n",
       "       'Data Scientist IA F/H', 'Data Scientist Python F/H',\n",
       "       'Data Scientist ML Engineer F/H',\n",
       "       'Ingénieur Data Scientist expérimenté - F/H',\n",
       "       'Analyste Performance (Data Scientist) F/H',\n",
       "       'Data Scientist / ML Ops Engineer F/H',\n",
       "       'Data Scientist / Machine Learning Engineer F/H',\n",
       "       \"Ingénieur Data Scientist ? IA dans l'industrie F/H\",\n",
       "       'Consultant Confirmé Citizen Data Scientist - N F/H',\n",
       "       'Data Scientist en Recherche Appliquée - Confirmé F/H',\n",
       "       'Consultant Data Scientist - Banque et Assurance - Paris F/H',\n",
       "       'Senior Data Scientist - Lutte contre la Fraude et les abus F/H',\n",
       "       'Data Scientist Expert en données pour l évaluation de l IA F/H',\n",
       "       'Phd / Jeune Docteur - Data Scientist & IA F/H',\n",
       "       'PhD / Jeune Docteur - Data scientist & IA F/H',\n",
       "       'Analyste développeur - data scientist F/H',\n",
       "       \"Data scientist / Chargé(e) d'études sur la petite enfance F/H\",\n",
       "       'Expert en sciences des données spécialisé en IA - Data scientist F/H',\n",
       "       'Développeur Datascience Flux Vision F/H'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intitule'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_poste(row):\n",
    "    intitule_lower = row['intitule'].lower()\n",
    "    if 'data scientist' in intitule_lower or 'ingénieur data scientist' in intitule_lower:\n",
    "        return 'data scientist'\n",
    "    elif 'data engineer' in intitule_lower or 'engineer' in intitule_lower or 'ingénieur' in intitule_lower or 'engineering' in intitule_lower :\n",
    "        return 'data engineer'\n",
    "\n",
    "\n",
    "# Apply the categorize_poste function to create the 'poste' column\n",
    "df['poste'] = df.apply(categorize_poste, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intitule</th>\n",
       "      <th>description_offre</th>\n",
       "      <th>date_creation</th>\n",
       "      <th>salaire_min_annuel</th>\n",
       "      <th>salaire_max_annuel</th>\n",
       "      <th>salaire_annuel_mean</th>\n",
       "      <th>qualification_libelle</th>\n",
       "      <th>experience</th>\n",
       "      <th>type_contrat</th>\n",
       "      <th>secteur_activite</th>\n",
       "      <th>...</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>ville_departement</th>\n",
       "      <th>entreprise_nom</th>\n",
       "      <th>entreprise_description</th>\n",
       "      <th>departement</th>\n",
       "      <th>departement_nom</th>\n",
       "      <th>region</th>\n",
       "      <th>poste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer F/H (H/F)</td>\n",
       "      <td>Le saviez-vous ?\\n\\nNous rejoindre, c'est rejo...</td>\n",
       "      <td>29/12/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Autres activités informatiques</td>\n",
       "      <td>...</td>\n",
       "      <td>49.687882</td>\n",
       "      <td>1.395968</td>\n",
       "      <td>76270.0</td>\n",
       "      <td>seine-maritime</td>\n",
       "      <td>None</td>\n",
       "      <td>Nous rejoindre, c'est rejoindre l'un des leade...</td>\n",
       "      <td>seine-maritime</td>\n",
       "      <td>None</td>\n",
       "      <td>normandie</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer H/F</td>\n",
       "      <td>Rejoindre le Groupe IRCEM, c'est participer à ...</td>\n",
       "      <td>29/12/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>50.688369</td>\n",
       "      <td>3.181903</td>\n",
       "      <td>59100.0</td>\n",
       "      <td>nord</td>\n",
       "      <td>IRCEM</td>\n",
       "      <td>None</td>\n",
       "      <td>nord</td>\n",
       "      <td>None</td>\n",
       "      <td>hauts-de-france</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analytics Engineer F/H - Marketing (H/F)</td>\n",
       "      <td>Descriptif du poste:\\n\\nRôle : L Analytics Eng...</td>\n",
       "      <td>29/12/2023</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Cadre</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Restauration de type rapide</td>\n",
       "      <td>...</td>\n",
       "      <td>48.742795</td>\n",
       "      <td>2.394977</td>\n",
       "      <td>94310.0</td>\n",
       "      <td>val-de-marne</td>\n",
       "      <td>CPF</td>\n",
       "      <td>Depuis 2002, Amorino émerveille les gourmands ...</td>\n",
       "      <td>val-de-marne</td>\n",
       "      <td>None</td>\n",
       "      <td>île-de-france</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA ENGINEER - H/F</td>\n",
       "      <td>Description :\\n\\n\\nvous rejoindrez une équipe ...</td>\n",
       "      <td>28/12/2023</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Administration publique (tutelle) des activité...</td>\n",
       "      <td>...</td>\n",
       "      <td>47.873504</td>\n",
       "      <td>1.917316</td>\n",
       "      <td>45100.0</td>\n",
       "      <td>loiret</td>\n",
       "      <td>DSI Pôle Emploi</td>\n",
       "      <td>None</td>\n",
       "      <td>loiret</td>\n",
       "      <td>None</td>\n",
       "      <td>centre-val de loire</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA ENGINEER - H/F</td>\n",
       "      <td>Description :\\n\\n\\nvous rejoindrez une équipe ...</td>\n",
       "      <td>28/12/2023</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>oui</td>\n",
       "      <td>CDI</td>\n",
       "      <td>Administration publique (tutelle) des activité...</td>\n",
       "      <td>...</td>\n",
       "      <td>43.536112</td>\n",
       "      <td>5.398630</td>\n",
       "      <td>13080.0</td>\n",
       "      <td>bouches-du-rhône</td>\n",
       "      <td>DSI Pôle Emploi</td>\n",
       "      <td>None</td>\n",
       "      <td>bouches-du-rhône</td>\n",
       "      <td>None</td>\n",
       "      <td>provence-alpes-côte d'azur</td>\n",
       "      <td>data engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   intitule  \\\n",
       "0            Senior Data Engineer F/H (H/F)   \n",
       "1                         Data Engineer H/F   \n",
       "2  Analytics Engineer F/H - Marketing (H/F)   \n",
       "3                       DATA ENGINEER - H/F   \n",
       "4                       DATA ENGINEER - H/F   \n",
       "\n",
       "                                   description_offre date_creation  \\\n",
       "0  Le saviez-vous ?\\n\\nNous rejoindre, c'est rejo...    29/12/2023   \n",
       "1  Rejoindre le Groupe IRCEM, c'est participer à ...    29/12/2023   \n",
       "2  Descriptif du poste:\\n\\nRôle : L Analytics Eng...    29/12/2023   \n",
       "3  Description :\\n\\n\\nvous rejoindrez une équipe ...    28/12/2023   \n",
       "4  Description :\\n\\n\\nvous rejoindrez une équipe ...    28/12/2023   \n",
       "\n",
       "  salaire_min_annuel salaire_max_annuel salaire_annuel_mean  \\\n",
       "0               None               None                None   \n",
       "1               None               None                None   \n",
       "2               None               None                None   \n",
       "3            45000.0            55000.0             50000.0   \n",
       "4            45000.0            55000.0             50000.0   \n",
       "\n",
       "  qualification_libelle experience type_contrat  \\\n",
       "0                  None        oui          CDI   \n",
       "1                  None        oui          CDI   \n",
       "2                 Cadre        oui          CDI   \n",
       "3                  None        oui          CDI   \n",
       "4                  None        oui          CDI   \n",
       "\n",
       "                                    secteur_activite  ...   latitude  \\\n",
       "0                     Autres activités informatiques  ...  49.687882   \n",
       "1                                               None  ...  50.688369   \n",
       "2                        Restauration de type rapide  ...  48.742795   \n",
       "3  Administration publique (tutelle) des activité...  ...  47.873504   \n",
       "4  Administration publique (tutelle) des activité...  ...  43.536112   \n",
       "\n",
       "   longitude  code_postal ville_departement   entreprise_nom  \\\n",
       "0   1.395968      76270.0    seine-maritime             None   \n",
       "1   3.181903      59100.0              nord            IRCEM   \n",
       "2   2.394977      94310.0      val-de-marne              CPF   \n",
       "3   1.917316      45100.0            loiret  DSI Pôle Emploi   \n",
       "4   5.398630      13080.0  bouches-du-rhône  DSI Pôle Emploi   \n",
       "\n",
       "                              entreprise_description       departement  \\\n",
       "0  Nous rejoindre, c'est rejoindre l'un des leade...    seine-maritime   \n",
       "1                                               None              nord   \n",
       "2  Depuis 2002, Amorino émerveille les gourmands ...      val-de-marne   \n",
       "3                                               None            loiret   \n",
       "4                                               None  bouches-du-rhône   \n",
       "\n",
       "  departement_nom                      region          poste  \n",
       "0            None                   normandie  data engineer  \n",
       "1            None             hauts-de-france  data engineer  \n",
       "2            None               île-de-france  data engineer  \n",
       "3            None         centre-val de loire  data engineer  \n",
       "4            None  provence-alpes-côte d'azur  data engineer  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294 entries, 0 to 293\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   intitule                294 non-null    object \n",
      " 1   description_offre       294 non-null    object \n",
      " 2   date_creation           294 non-null    object \n",
      " 3   salaire_min_annuel      65 non-null     object \n",
      " 4   salaire_max_annuel      59 non-null     object \n",
      " 5   salaire_annuel_mean     65 non-null     object \n",
      " 6   qualification_libelle   193 non-null    object \n",
      " 7   experience              294 non-null    object \n",
      " 8   type_contrat            294 non-null    object \n",
      " 9   secteur_activite        223 non-null    object \n",
      " 10  ville                   294 non-null    object \n",
      " 11  latitude                294 non-null    float64\n",
      " 12  longitude               294 non-null    float64\n",
      " 13  code_postal             294 non-null    object \n",
      " 14  ville_departement       294 non-null    object \n",
      " 15  entreprise_nom          230 non-null    object \n",
      " 16  entreprise_description  208 non-null    object \n",
      " 17  departement             294 non-null    object \n",
      " 18  departement_nom         0 non-null      object \n",
      " 19  region                  294 non-null    object \n",
      " 20  poste                   271 non-null    object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 48.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.loc[df['poste'].isna(), ['poste', 'intitule', 'description_offre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    poste                                           intitule  \\\n",
      "97   None                      Consultant Data - AIX ((H/F))   \n",
      "98   None  Data Steward - Responsable gestion de données ...   \n",
      "99   None  STAGE_Marketing strategy and tech analyst F/H ...   \n",
      "104  None  Stagiaire Project Manager Dashboard Ops e-comm...   \n",
      "117  None               Data & AI Strategy Manager F/H (H/F)   \n",
      "119  None                         Développeur Java F/H (H/F)   \n",
      "133  None  Expert big data / Hadoop / Cloudera (Rodez) H/...   \n",
      "134  None  Data analyste informatique (H/F) (IT) / Freelance   \n",
      "135  None  Data analyste informatique (H/F) (IT) / Freelance   \n",
      "145  None  SAP Master Data Expert F/H - Système, réseaux,...   \n",
      "147  None                           Data Analyst (F/H) (H/F)   \n",
      "153  None  DATA analyste informatique EXPERT SQL (IT) / F...   \n",
      "154  None                       Responsable de Pôle Data H/F   \n",
      "157  None                Data Analyst RSE confirmé F/H (H/F)   \n",
      "168  None  Data analyste informatique Python Montpellier ...   \n",
      "169  None                                 Data Analyst - H/F   \n",
      "172  None     CDI - DATA ANALYST SENIOR DROM - (F/H/X) (H/F)   \n",
      "175  None  Data analyste informatique (IT) / Freelance (H/F)   \n",
      "176  None  data analyste informatique UML (IT) / Freelanc...   \n",
      "177  None  Lead data analyste informatique (H/F) (IT) / F...   \n",
      "178  None                              Consultant Data (H/F)   \n",
      "183  None      CDI - Global Finance Data Analyst (W/M) (H/F)   \n",
      "293  None            Développeur Datascience Flux Vision F/H   \n",
      "\n",
      "                                     description_offre  \n",
      "97   RESPONSABILITÉS : \\n\\nVos missions ?\\nIntégré ...  \n",
      "98   Descriptif du poste:\\nDans le cadre de notre p...  \n",
      "99   Le saviez-vous ? :\\n\\nNous rejoindre, c'est re...  \n",
      "104  Le saviez-vous ? :\\n\\nNous rejoindre, c'est re...  \n",
      "117  Nous rejoindre, c'est rejoindre l'un des leade...  \n",
      "119  Le saviez-vous ? \\n\\nNous rejoindre, c'est rej...  \n",
      "133  Notre client dans le secteur Banque et finance...  \n",
      "134  Espace-Freelance, réseau de consultants indépe...  \n",
      "135  Insitoo Freelance, facilitateur du freelancing...  \n",
      "145  Descriptif du poste:\\n\\nNous recherchons un SA...  \n",
      "147  Le saviez-vous ? :\\nNous rejoindre, cest rejoi...  \n",
      "153  - Vous participerez à l?analyse et à la résolu...  \n",
      "154  POSTE : Responsable de Pôle Data H/F\\nDESCRIPT...  \n",
      "157  Le saviez-vous ? :\\nNous rejoindre, cest rejoi...  \n",
      "168  Data analyst Python Montpellier\\n+ 1j/3sem à M...  \n",
      "169  Description :\\nDescription\\nL COMMERCE est com...  \n",
      "172  Bienvenue chez CANAL+ Group ! Séries, films, d...  \n",
      "175  Mission Long Terme:\\nNous recherchons un Data ...  \n",
      "176  Nous sommes actuellement à la recherche d?un a...  \n",
      "177  Insitoo Freelance, facilitateur du freelancing...  \n",
      "178  Qui sommes-nous ?\\n\\nNous sommes passionnés pa...  \n",
      "183  .\\nChez Sephora, nous sommes unis et défendons...  \n",
      "293  Description de la mission :\\n\\nLa croissance t...  \n"
     ]
    }
   ],
   "source": [
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On enlève les offres qui ne sont pas catégorisées en 'data scientist' ni 'data engineer':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['poste'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 271 entries, 0 to 292\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   intitule                271 non-null    object \n",
      " 1   description_offre       271 non-null    object \n",
      " 2   date_creation           271 non-null    object \n",
      " 3   salaire_min_annuel      63 non-null     object \n",
      " 4   salaire_max_annuel      57 non-null     object \n",
      " 5   salaire_annuel_mean     63 non-null     object \n",
      " 6   qualification_libelle   182 non-null    object \n",
      " 7   experience              271 non-null    object \n",
      " 8   type_contrat            271 non-null    object \n",
      " 9   secteur_activite        214 non-null    object \n",
      " 10  ville                   271 non-null    object \n",
      " 11  latitude                271 non-null    float64\n",
      " 12  longitude               271 non-null    float64\n",
      " 13  code_postal             271 non-null    object \n",
      " 14  ville_departement       271 non-null    object \n",
      " 15  entreprise_nom          225 non-null    object \n",
      " 16  entreprise_description  199 non-null    object \n",
      " 17  departement             271 non-null    object \n",
      " 18  departement_nom         0 non-null      object \n",
      " 19  region                  271 non-null    object \n",
      " 20  poste                   271 non-null    object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 46.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poste\n",
       "data engineer     167\n",
       "data scientist    104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['poste'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec sur description_offre pour 'data scientist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scientist_df= df.loc[df['poste'] == 'data scientist']\n",
    "#data_scientist_df_test = df.loc[df['poste'] == 'data scientist', ['poste', 'intitule']]\n",
    "#print(data_scientist_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 104 entries, 50 to 292\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   intitule                104 non-null    object \n",
      " 1   description_offre       104 non-null    object \n",
      " 2   date_creation           104 non-null    object \n",
      " 3   salaire_min_annuel      23 non-null     object \n",
      " 4   salaire_max_annuel      21 non-null     object \n",
      " 5   salaire_annuel_mean     23 non-null     object \n",
      " 6   qualification_libelle   66 non-null     object \n",
      " 7   experience              104 non-null    object \n",
      " 8   type_contrat            104 non-null    object \n",
      " 9   secteur_activite        77 non-null     object \n",
      " 10  ville                   104 non-null    object \n",
      " 11  latitude                104 non-null    float64\n",
      " 12  longitude               104 non-null    float64\n",
      " 13  code_postal             104 non-null    object \n",
      " 14  ville_departement       104 non-null    object \n",
      " 15  entreprise_nom          78 non-null     object \n",
      " 16  entreprise_description  70 non-null     object \n",
      " 17  departement             104 non-null    object \n",
      " 18  departement_nom         0 non-null      object \n",
      " 19  region                  104 non-null    object \n",
      " 20  poste                   104 non-null    object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 17.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_scientist_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/kc5dv8dd4_18gtz7tjx528p40000gn/T/ipykernel_5762/2523644901.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_scientist_df['ID'] = range(1, len(data_scientist_df) + 1)\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'ID' starting from 1\n",
    "data_scientist_df['ID'] = range(1, len(data_scientist_df) + 1)\n",
    "data_scientist_df = data_scientist_df[['ID'] + [col for col in data_scientist_df.columns if col != 'ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 104 entries, 50 to 292\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   ID                      104 non-null    int64  \n",
      " 1   intitule                104 non-null    object \n",
      " 2   description_offre       104 non-null    object \n",
      " 3   date_creation           104 non-null    object \n",
      " 4   salaire_min_annuel      23 non-null     object \n",
      " 5   salaire_max_annuel      21 non-null     object \n",
      " 6   salaire_annuel_mean     23 non-null     object \n",
      " 7   qualification_libelle   66 non-null     object \n",
      " 8   experience              104 non-null    object \n",
      " 9   type_contrat            104 non-null    object \n",
      " 10  secteur_activite        77 non-null     object \n",
      " 11  ville                   104 non-null    object \n",
      " 12  latitude                104 non-null    float64\n",
      " 13  longitude               104 non-null    float64\n",
      " 14  code_postal             104 non-null    object \n",
      " 15  ville_departement       104 non-null    object \n",
      " 16  entreprise_nom          78 non-null     object \n",
      " 17  entreprise_description  70 non-null     object \n",
      " 18  departement             104 non-null    object \n",
      " 19  departement_nom         0 non-null      object \n",
      " 20  region                  104 non-null    object \n",
      " 21  poste                   104 non-null    object \n",
      "dtypes: float64(2), int64(1), object(19)\n",
      "memory usage: 18.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_scientist_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS= data_scientist_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESENTATION D'ELIPCE :\n",
      "Expert(e) en développement logiciel & data et interprétation métier, Elipce se positionne sur 3 axes : efficacité opérationnelle, business intelligence et centre de services logiciels.\n",
      "Pour accompagner nos clients, nous créons des solutions digitales adaptées, qui correspondent à leur fonctionnement et à la réalité de leur entreprise. \n",
      "Nous proposons également des solutions d'externalisation permettant d'assurer la maintenance, l'évolution ou le développement d'applications logicielles pour le compte de nos clients, via la mise à disposition de pool de compétences au sein des équipes client et sur nos plateaux techniques.\n",
      "Nous nous engageons à fournir des solutions de qualité, à promouvoir l'innovation et à cultiver une véritable cohésion au sein de notre équipe.\n",
      "DESCRIPTION DU POSTE : \n",
      "Au sein d'une équipe, vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs SI.\n",
      "MISSIONS PRINCIPALES : \n",
      "Modéliser, traiter et transformer des données complexes\n",
      "Concevoir une solution de stockage de données (modèle en étoile)\n",
      "Développer des connecteurs ou passerelles de données à l'aide des outils ETL (Talend)\n",
      "Lire, comprendre et rédiger des documents techniques en lien avec le poste de Data Architect / Data Engineer : dictionnaire de données, modélisation Merise, UML, matrice de bus\n",
      "Rester à jour et en veille sur les différentes technologies et méthodes liées au poste de Data Architect / Data Engineer par le biais de l'auto formation ou la formation professionnelle\n",
      "Des compétences en machine learning / IA au sens large sont appréciées\n",
      "PROFIL RECHERCHÉ : \n",
      "Vous êtes Data Architect et / ou Data Engineer et / ou Data Scientist confirmé ou aguerri . Vous souhaitez intégrer une équipe jdynamique et relever de nouveaux challenges. Vous avez besoin de transversalité, d'autonomie et ne pas être cantonné à une seule tâche; Vous êtes curieux et souhaitez explorer des données en provenance de différents secteurs (industrie, finance, transport, service).\n",
      "Vous êtes ou avez été analyste programmeur ? Vous êtes curieux de savoir la différence entre une base de données et un entrepôt de données ? Vous avez envie d'aller plus loin que le simple stockage et vous souhaitez apprendre à valoriser les données ? Ce poste vous permettra de vous épanouir par la formation aux technologies et techniques en business intelligence. N'hésitez pas à postuler !\n",
      "Qualités requises :\n",
      "Couteau Suisse\n",
      "Organisé, réactif et rigoureux\n",
      "Etre créatif, avoir le sens de l'innovation\n",
      "Avoir un état d'esprit analytique et de synthèse\n",
      "Force de proposition\n",
      "\n",
      "BONUS :\n",
      "\n",
      "Mutuelle prise en charge à 100 %\n",
      "Accord d'intéressement\n",
      "Vélo électrique de fonction (à la demande)\n",
      "Séance de sport en entreprise\n"
     ]
    }
   ],
   "source": [
    "#récupérer sous forme de liste\n",
    "corpus = DS['description_offre'].tolist()\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presentation d'elipce :\n",
      "expert(e) en développement logiciel & data et interprétation métier, elipce se positionne sur 3 axes : efficacité opérationnelle, business intelligence et centre de services logiciels.\n",
      "pour accompagner nos clients, nous créons des solutions digitales adaptées, qui correspondent à leur fonctionnement et à la réalité de leur entreprise. \n",
      "nous proposons également des solutions d'externalisation permettant d'assurer la maintenance, l'évolution ou le développement d'applications logicielles pour le compte de nos clients, via la mise à disposition de pool de compétences au sein des équipes client et sur nos plateaux techniques.\n",
      "nous nous engageons à fournir des solutions de qualité, à promouvoir l'innovation et à cultiver une véritable cohésion au sein de notre équipe.\n",
      "description du poste : \n",
      "au sein d'une équipe, vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs si.\n",
      "missions principales : \n",
      "modéliser, traiter et transformer des données complexes\n",
      "concevoir une solution de stockage de données (modèle en étoile)\n",
      "développer des connecteurs ou passerelles de données à l'aide des outils etl (talend)\n",
      "lire, comprendre et rédiger des documents techniques en lien avec le poste de data architect / data engineer : dictionnaire de données, modélisation merise, uml, matrice de bus\n",
      "rester à jour et en veille sur les différentes technologies et méthodes liées au poste de data architect / data engineer par le biais de l'auto formation ou la formation professionnelle\n",
      "des compétences en machine learning / ia au sens large sont appréciées\n",
      "profil recherché : \n",
      "vous êtes data architect et / ou data engineer et / ou data scientist confirmé ou aguerri . vous souhaitez intégrer une équipe jdynamique et relever de nouveaux challenges. vous avez besoin de transversalité, d'autonomie et ne pas être cantonné à une seule tâche; vous êtes curieux et souhaitez explorer des données en provenance de différents secteurs (industrie, finance, transport, service).\n",
      "vous êtes ou avez été analyste programmeur ? vous êtes curieux de savoir la différence entre une base de données et un entrepôt de données ? vous avez envie d'aller plus loin que le simple stockage et vous souhaitez apprendre à valoriser les données ? ce poste vous permettra de vous épanouir par la formation aux technologies et techniques en business intelligence. n'hésitez pas à postuler !\n",
      "qualités requises :\n",
      "couteau suisse\n",
      "organisé, réactif et rigoureux\n",
      "etre créatif, avoir le sens de l'innovation\n",
      "avoir un état d'esprit analytique et de synthèse\n",
      "force de proposition\n",
      "\n",
      "bonus :\n",
      "\n",
      "mutuelle prise en charge à 100 %\n",
      "accord d'intéressement\n",
      "vélo électrique de fonction (à la demande)\n",
      "séance de sport en entreprise\n"
     ]
    }
   ],
   "source": [
    "#passer en minuscule\n",
    "corpus = [doc.lower() for doc in corpus]\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presentation d'elipce :\n",
      "expert(e) en développement logiciel & data et interprétation métier, elipce se positionne sur  axes : efficacité opérationnelle, business intelligence et centre de services logiciels.\n",
      "pour accompagner nos clients, nous créons des solutions digitales adaptées, qui correspondent à leur fonctionnement et à la réalité de leur entreprise. \n",
      "nous proposons également des solutions d'externalisation permettant d'assurer la maintenance, l'évolution ou le développement d'applications logicielles pour le compte de nos clients, via la mise à disposition de pool de compétences au sein des équipes client et sur nos plateaux techniques.\n",
      "nous nous engageons à fournir des solutions de qualité, à promouvoir l'innovation et à cultiver une véritable cohésion au sein de notre équipe.\n",
      "description du poste : \n",
      "au sein d'une équipe, vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs si.\n",
      "missions principales : \n",
      "modéliser, traiter et transformer des données complexes\n",
      "concevoir une solution de stockage de données (modèle en étoile)\n",
      "développer des connecteurs ou passerelles de données à l'aide des outils etl (talend)\n",
      "lire, comprendre et rédiger des documents techniques en lien avec le poste de data architect / data engineer : dictionnaire de données, modélisation merise, uml, matrice de bus\n",
      "rester à jour et en veille sur les différentes technologies et méthodes liées au poste de data architect / data engineer par le biais de l'auto formation ou la formation professionnelle\n",
      "des compétences en machine learning / ia au sens large sont appréciées\n",
      "profil recherché : \n",
      "vous êtes data architect et / ou data engineer et / ou data scientist confirmé ou aguerri . vous souhaitez intégrer une équipe jdynamique et relever de nouveaux challenges. vous avez besoin de transversalité, d'autonomie et ne pas être cantonné à une seule tâche; vous êtes curieux et souhaitez explorer des données en provenance de différents secteurs (industrie, finance, transport, service).\n",
      "vous êtes ou avez été analyste programmeur ? vous êtes curieux de savoir la différence entre une base de données et un entrepôt de données ? vous avez envie d'aller plus loin que le simple stockage et vous souhaitez apprendre à valoriser les données ? ce poste vous permettra de vous épanouir par la formation aux technologies et techniques en business intelligence. n'hésitez pas à postuler !\n",
      "qualités requises :\n",
      "couteau suisse\n",
      "organisé, réactif et rigoureux\n",
      "etre créatif, avoir le sens de l'innovation\n",
      "avoir un état d'esprit analytique et de synthèse\n",
      "force de proposition\n",
      "\n",
      "bonus :\n",
      "\n",
      "mutuelle prise en charge à  %\n",
      "accord d'intéressement\n",
      "vélo électrique de fonction (à la demande)\n",
      "séance de sport en entreprise\n"
     ]
    }
   ],
   "source": [
    "# Retirer les chiffres dans l'ensemble du corpus\n",
    "chiffres = list(\"0123456789\")\n",
    "#print(chiffres)\n",
    "corpus= [\"\".join([mot for mot in list(doc) if not mot in chiffres]) for doc in corpus]\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "#liste des ponctuations\n",
    "import string\n",
    "ponctuations = list(string.punctuation)\n",
    "print(ponctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presentation delipce \n",
      "experte en développement logiciel  data et interprétation métier elipce se positionne sur  axes  efficacité opérationnelle business intelligence et centre de services logiciels\n",
      "pour accompagner nos clients nous créons des solutions digitales adaptées qui correspondent à leur fonctionnement et à la réalité de leur entreprise \n",
      "nous proposons également des solutions dexternalisation permettant dassurer la maintenance lévolution ou le développement dapplications logicielles pour le compte de nos clients via la mise à disposition de pool de compétences au sein des équipes client et sur nos plateaux techniques\n",
      "nous nous engageons à fournir des solutions de qualité à promouvoir linnovation et à cultiver une véritable cohésion au sein de notre équipe\n",
      "description du poste  \n",
      "au sein dune équipe vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs si\n",
      "missions principales  \n",
      "modéliser traiter et transformer des données complexes\n",
      "concevoir une solution de stockage de données modèle en étoile\n",
      "développer des connecteurs ou passerelles de données à laide des outils etl talend\n",
      "lire comprendre et rédiger des documents techniques en lien avec le poste de data architect  data engineer  dictionnaire de données modélisation merise uml matrice de bus\n",
      "rester à jour et en veille sur les différentes technologies et méthodes liées au poste de data architect  data engineer par le biais de lauto formation ou la formation professionnelle\n",
      "des compétences en machine learning  ia au sens large sont appréciées\n",
      "profil recherché  \n",
      "vous êtes data architect et  ou data engineer et  ou data scientist confirmé ou aguerri  vous souhaitez intégrer une équipe jdynamique et relever de nouveaux challenges vous avez besoin de transversalité dautonomie et ne pas être cantonné à une seule tâche vous êtes curieux et souhaitez explorer des données en provenance de différents secteurs industrie finance transport service\n",
      "vous êtes ou avez été analyste programmeur  vous êtes curieux de savoir la différence entre une base de données et un entrepôt de données  vous avez envie daller plus loin que le simple stockage et vous souhaitez apprendre à valoriser les données  ce poste vous permettra de vous épanouir par la formation aux technologies et techniques en business intelligence nhésitez pas à postuler \n",
      "qualités requises \n",
      "couteau suisse\n",
      "organisé réactif et rigoureux\n",
      "etre créatif avoir le sens de linnovation\n",
      "avoir un état desprit analytique et de synthèse\n",
      "force de proposition\n",
      "\n",
      "bonus \n",
      "\n",
      "mutuelle prise en charge à  \n",
      "accord dintéressement\n",
      "vélo électrique de fonction à la demande\n",
      "séance de sport en entreprise\n"
     ]
    }
   ],
   "source": [
    "#retrait des ponctuations\n",
    "corpus = [\"\".join([char for char in list(doc) if not (char in ponctuations)]) for doc in corpus]\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['presentation delipce experte en développement logiciel  data et interprétation métier elipce se positionne sur  axes  efficacité opérationnelle business intelligence et centre de services logicielspour accompagner nos clients nous créons des solutions digitales adaptées qui correspondent à leur fonctionnement et à la réalité de leur entreprise nous proposons également des solutions dexternalisation permettant dassurer la maintenance lévolution ou le développement dapplications logicielles pour le compte de nos clients via la mise à disposition de pool de compétences au sein des équipes client et sur nos plateaux techniquesnous nous engageons à fournir des solutions de qualité à promouvoir linnovation et à cultiver une véritable cohésion au sein de notre équipedescription du poste  au sein dune équipe vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs simissions principales  modéliser traiter et transformer des données complexesconcevoir une solution de stockage de données modèle en étoiledévelopper des connecteurs ou passerelles de données à laide des outils etl talendlire comprendre et rédiger des documents techniques en lien avec le poste de data architect  data engineer  dictionnaire de données modélisation merise uml matrice de busrester à jour et en veille sur les différentes technologies et méthodes liées au poste de data architect  data engineer par le biais de lauto formation ou la formation professionnelledes compétences en machine learning  ia au sens large sont appréciéesprofil recherché  vous êtes data architect et  ou data engineer et  ou data scientist confirmé ou aguerri  vous souhaitez intégrer une équipe jdynamique et relever de nouveaux challenges vous avez besoin de transversalité dautonomie et ne pas être cantonné à une seule tâche vous êtes curieux et souhaitez explorer des données en provenance de différents secteurs industrie finance transport servicevous êtes ou avez été analyste programmeur  vous êtes curieux de savoir la différence entre une base de données et un entrepôt de données  vous avez envie daller plus loin que le simple stockage et vous souhaitez apprendre à valoriser les données  ce poste vous permettra de vous épanouir par la formation aux technologies et techniques en business intelligence nhésitez pas à postuler qualités requises couteau suisseorganisé réactif et rigoureuxetre créatif avoir le sens de linnovationavoir un état desprit analytique et de synthèseforce de propositionbonus mutuelle prise en charge à  accord dintéressementvélo électrique de fonction à la demandeséance de sport en entreprise', 'description du poste  au sein dune équipe vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs simissions principales  modéliser traiter et transformer des données complexesconcevoir une solution de stockage de données modèle en étoiledévelopper des connecteurs ou passerelles de données à laide des outils etl talendlire comprendre et rédiger des documents techniques en lien avec le poste de data architect  data engineer  dictionnaire de données modélisation merise uml matrice de busrester à jour et en veille sur les différentes technologies et méthodes liées au poste de data architect  data engineer par le biais de lauto formation ou la formation professionnelledes compétences en machine learning  ia au sens large sont appréciéesprofil recherché  vous êtes data architect et  ou data engineer et  ou data scientist confirmé ou aguerri  vous souhaitez intégrer une équipe jeune dynamique et relever de nouveaux challenges  vous avez besoin de transversalité dautonomie et ne pas être cantonné à une seule tâche vous êtes curieux et souhaitez explorer des données en provenance de différents secteurs industrie finance transport service   vous êtes ou avez été analyste programmeur vous êtes curieux de savoir la différence entre une base de données et un entrepôt de données  vous avez envie daller plus loin que le simple stockage et vous souhaitez apprendre à valoriser les données ce poste vous permettra de vous épanouir par la formation aux technologies et techniques en business intelligence nhésitez pas à postuler qualités requises  organisé réactif et rigoureux goût du travail en équipeetre créatif avoir le sens de linnovation avoir un état desprit analytique et de synthèseforce de propositionbonus mutuelle prise en charge à   accord dintéressementvélo électrique de fonction à la demande séance de sport en entreprise', 'poste  lead data scientist  demand forecast hfdescription  vous cherchez à travailler dans une entreprise dynamique où votre travail rime avec impact social et environnemental  bienvenue chez nous carrefour recherche pour sa direction data france une lead data scientist  demand forecast fhnous utilisons des approches de machine learning pour résoudre des défis commerciaux et opérationnels comme les ruptures en magasin la prévision des ventes loptimisation de lassortiment des produits la personnalisation de lexpérience sur le site carrefourfrau sein de léquipe de data science supply vous serez le référent technique dune équipe rassemblant data scientists et data engineers vous travaillerez principalement autour de la modélisation et de la prévision de la demande client de ses défis non stationnarité des données prévision multi échelles scalabilité et de son utilisation pour loptimisation des décisions tout au long de la chaîne dapprovisionnement commandes préparation de colis livraison vous travaillerez dans un cadre agile et favorisant la collaboration en outre vous collaborez avec notre lead data scientist en recherche opérationnellemissions contribuer aux projets en tant que data scientist  concevoir développer et optimiser des systèmes de recommandation de produits et des moteurs de recherche  structurer planifier et coordonner les travaux de léquipe en collaborant activement avec les data translators les équipes métiers et les autres équipes techniques  aligner la construction des solutions techniques aux enjeux métier et business et aux objectifs de carrefour  conseiller guider assurer la montée en compétences et lévolution des différents ingénieurs de léquipe  être garant des méthodologies de science des données et de développement logiciel de léquipe facilitant notamment la qualification des projets les développements itératifs lindustrialisation des solutions leur maintenabilité la mesure et le suivi de leur performance  arbitrer si nécessaire les débats techniques  rester attentif aux nouveautés techniques afin de pouvoir challenger et proposer des solutions si besoinvous pourrez également participer aux échanges réguliers de notre communauté dune cinquantaine dingénieurs data scientists engineers devops  séminaires partage de retours de conférences débats sur les problématiques ml de développement logicielen tant que lead data scientist vous rapporterez au data science manager de votre équipeprofildiplômé en informatique ou mathématique appliquée au moins au niveau master ou justifiant dune expérience professionnelle équivalente vous disposez de très solides connaissances sur les algorithmes dapprentissage statistiqueà lissue dau moins  années dexpérience professionnelle vous avez développé une solide expertise sur   chaque étape du cycle de vie dun projet de data science  collecte des données et préparation modélisation évaluation et déploiement des modèles  des problématiques de modélisation et de prévision sur des séries temporelles  la manipulation de base de données à grande échellevous avez également participé à lindustrialisation de solutions fondées sur du machine learning idéalement dans un contexte cloudvous êtes désormais capable de travailler dans nimporte quel champ de la data science et également de conseiller et guider des data scientists et data engineers juniors sur ces projetsvous êtes motivé par les problématiques opérationnelles très concrètes que lon peut notamment rencontrer dans lunivers de la grande distribution pour cela vous aimez interagir avec des professionnels dhorizons différents grâce à dexcellentes qualités relationnelles et de communication vous êtes en mesure de communiquer vos idées complexes à différents publics nontechniques opérationnels comexvous avez pris part à des projets de développement collaboratifs et la qualité et la simplicité du code vous tiennent à coeurvous maîtrisez le français et êtes en mesure de mener des discussions avec les opérationnels de carrefour france vous maîtrisez un anglais technique a minimales petits plusvos talents de data engineer seront également les bienvenus pour faciliter le traitement de nos téraoctets de donnéesadoptant une approche itérative nous accordons une grande valeur à vos expériences de développeur logiciel agileavoir implémenté testé et validé une solution fondée sur le ml dans le domaine du retail ou du ecommerce est une expérience très précieuse à nos yeux chez carrefour nous avon', 'recherche data scientist hfdans le cadre du développement de notre entité abylsen stra sciences  technologies rhônealpes auvergne bourgogne spécialisée dans le transport automobile aéronautique défense spatiale et ferroviaire lindustrie lourde métallurgie aciérie et lenergie nous recherchons un data scientist hf pour intégrer notre équipe et apporter votre expertise sur lensemble de nos projetsvotre rôle consistera à  collecter et analyser les données internes et externes par lutilisation de méthodes statistiques pour connaitre et exploiter en continu les évolutions des domaines dapplication  sélectionner et mettre en oeuvre des algorithmes dapprentissage automatique pertinents sur les cas dusage machine learning deep learning etc  communiquer les résultats et les solutions avec les équipes métiers et instances de direction en veillant à vulgariser les concepts complexes  maintenir faire évoluer et documenter les modèles existants e', 'recherche cdi clinical data scientist hfcdi clinical data scientisten tant que clinical data scientist vous intégrerez léquipe rd demobot et votre objectif sera de construire un processus pipeline de traitement de données multimodales image audio texte etc et non structurées dans le but détablir des corrélations entre biomarqueurs dans un contexte clinique vous travaillerez notamment sur etablissement de corrélations entre des biomarqueurs analyse de données multimodales et non structuréesrecherche algorithmique de patternsdata preprocessingdata visualizationfeatures extraction pour prédiction clinique information extractionfeatures selectionfeatures engineeringdata clustering  dimensionality reductionprofil recherché vous avez une expérience professionnelle en data science impliquant notamment du traitement de données multimodales et non structurées vous êtes familier du pipeline usuel de prétraitement traitement et posttraitement des donné', 'recherche senior data scientist hfmirakl leader et pionnier de léconomie de plateforme propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur ecommerce afin daccélérer de façon durable et rentable leur croissance depuis  mirakl accompagne les entreprises bc et bb avec la technologie la plus avancée sécurisée et évolutive leur permettant de digitaliser leur activité et délargir leur offre via la marketplace ou le dropship faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus defficacité offrir une expérience dachat personnalisée à leurs clients et augmenter leurs profits grâce au retail media basée à paris et boston mirakl est certifiée great place to worknos équipes techniques et produits nommées mirakl labs sont principalement réparties entre nos  hubs situés à paris et à bordeaux elles collaborent au quotidien afin dadresser les problématiques de nos clients et', 'description rattachée au head data analytics vos projets seront à destination de iliad maison mère vous serez amenée à accompagner la direction groupe dans leurs besoins danalyse de données par la réalisation de cas dusage en machine learning recherche opérationnelle statistiques etc en collaboration avec les data engineers et en relation avec les diverses entités métier et fonction transversales du groupe en france et à létrangeraccompagnée par le management du pôle et en interaction avec les data engineersvous implémenterez des méthodes de science des données et danalyse statistique pour répondre à des besoins métiers concrets concernant des sujets à fort impact stratégique pour le groupevous développerez une connaissance approfondie des activités de freeiliad et entretiendrez une communication étroite avec le métier pour assurer la pertinence de vos solutionsvous encadrerez les membres juniors de léquipe sur les questions techniquesvous serez une référence technique sur vos sujets capable de les animer au sein de léquipe et plus largement de la communauté data du groupevous vous assurerez de créer une documentation pertinente sur vos différents sujetsparmi les principaux sujets abordés par léquipe data figurent\\xa0le ciblage des offres commercialeslexcellence opérationnelle dans le déploiement des réseauxloptimisation de la qualité de service    profil recherché     hardskills\\xa0 ans dexpériences en data science préférablement appliquée au businesscapacité à produire du code robuste et à implémenter des solutions dans un environnement de production pythonau fait des dernières techniques et solutions innovantesi heard you speak english this will be a real strength in an international context softskills\\xa0capacité à comprendre et traduire des enjeux business complexes en solution techniqueesprit déquipe et communication efficace avec ses pairs et ses managerscapable dadapter un message à nimporte quelle audience y compris non techniqueaxé sur les résultats pragmatique et agilecapable de challenger les autres et de recevoir du feedbackniveau de formationbac ou ou équivalent dans le domaine de la data école dingénieur écoles spécialisées formation universitaire avec une spécialisation sciences des donnéesevolution possiblelead data scientistprincipal data scientist', 'carrefour recherche pour sa direction data france une lead data scientist  search  recommandation fhau sein du pôle de data science customer vous serez le référent technique dune équipe rassemblant data scientists et data engineers votre mission principale consistera à travailler sur divers projets de data science centrés sur les défis du ecommerce cela inclut notamment la personnalisation des systèmes de recommandation et loptimisation du moteur de recherche de produits vous travaillerez dans un cadre agile et favorisant la collaboration missionscontribuer aux projets en tant que data scientist  concevoir développer et optimiser des systèmes de recommandation de produits et des moteurs de recherchestructurer planifier et coordonner les travaux de léquipe en collaborant activement avec les data translators les équipes métiers et les autres équipes techniquesaligner la construction des solutions techniques aux enjeux métier et business et aux objectifs de carrefourconseiller guider assurer la montée en compétences et lévolution des différents ingénieurs de léquipeêtre garant des méthodologies de science des données et de développement logiciel de léquipe facilitant notamment la qualification des projets les développements itératifs lindustrialisation des solutions leur maintenabilité la mesure et le suivi de leur performancearbitrer si nécessaire les débats techniquesrester attentif aux nouveautés techniques afin de pouvoir challenger et proposer des solutions si besoinvous pourrez également participer aux échanges réguliers de notre communauté dune cinquantaine dingénieurs data scientists engineers devops  séminaires partage de retours de conférences débats sur les problématiques ml de développement logiciel en tant que lead data scientist vous rapporterez au data science manager de votre équipe  profildiplômé en informatique ou mathématique appliquée au moins au niveau master ou justifiant dune expérience professionnelle équivalente vous disposez de très solides connaissances sur les algorithmes dapprentissage statistiqueà lissue dau moins  années dexpérience professionnelle vous avez développé une solide expertise sur chaque étape du cycle de vie dun projet de data science  collecte des données et préparation modélisation évaluation et déploiement des modèlesla manipulation de base de données à grande échelleexpérience dans le secteur de lecommerce du retail ou du marketing serait un plusvous avez également participé à lindustrialisation de solutions fondées sur du machine learning idéalement dans un contexte cloudvous êtes désormais capable de travailler dans nimporte quel champ de la data science et également de conseiller et guider des data scientists et data engineers juniors sur ces projetsvous êtes motivé par les problématiques opérationnelles très concrètes que lon peut notamment rencontrer dans lunivers de la grande distribution pour cela vous aimez interagir avec des professionnels dhorizons différents grâce à dexcellentes qualités relationnelles et de communication vous êtes en mesure de communiquer vos idées complexes à différents publics nontechniquesvous avez pris part à des projets de développement collaboratifs et la qualité et la simplicité du code vous tiennent à cœurvous maîtrisez le français et êtes en mesure de mener des discussions avec les opérationnels de carrefour france vous maîtrisez un anglais technique a minimachez carrefour nous avons à cœur de ne passer à côté daucun talent et sommes fiers de compter des équipes représentatives de la société dans son ensemblenous encourageons ainsi tous types de profils à postuler à cette offre et garantissons un processus de recrutement dénué de toutes formes de discriminations', 'description du poste vous cherchez à acquérir des compétences daujourdhui et un métier qui a de lavenir en alternancenotre mission  rendre léducation accessible à touslalternance avec openclassrooms cest apprendre un métier avec une formation mêlant   de théorie et   de pratique pour être   prêt à lemploi  grâce à nos équipes qui épaulent chaque profil dans la recherche dun employeur nous affichons un taux dinsertion de nos étudiants de plus de   en entreprise notre école en ligne propose des centaines de formations sur des métiers du numérique   en ligne avec un diplôme reconnu par létat à la clé vous former avec openclassrooms cest aussi rejoindre une communauté internationale de plus de   étudiants actifs et motivés dans  paysnous recherchons un profil motivé pour occuper le poste de data scientist pythonmachine learning en alternance pour une de nos entreprises partenaires grande distribution secteur bancaire luxe services etcsi votre candidature est retenue votre scolarité sera entièrement financée par votre employeurattention  pour postuler à cette offre en alternance vous devez faire une formation diplômante avec openclassrooms ou réaliser un changement décole dans le cadre dun contrat en alternancedescription du profil prérequis à la formationpour postuler à cette offre en alternance vous devez faire une formation diplômante avec openclassrooms ou réaliser un changement décole dans le cadre dun contrat en alternance', 'chez thales nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr plus vert et plus inclusif un avenir de confiance mais ces technologies ne viennent pas de nulle part lintelligence humaine est le moteur derrière la technologie qui fait la renommée de thales les projets que nous conduisons sont complexes et nos clients exigeants pour répondre aux besoins actuels et futurs de nos clients nous maîtrisons plus dune centaine de disciplines de loptique à la physique quantique du traitement du signal à la connectivité et à lintelligence artificielle rejoindre thales cest repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés cest donc être au cœur dune formidable aventure technique une attention portée à léquilibre des collaborateurs au service de leur réussite cest pourquoi notamment nous nous efforçons de créer un environnement de travail accueillant et daccorder la flexibilité nécessaire à léquilibre entre vie professionnelle et vie personnelle nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons des parcours professionnels riches chez thales nous jouons collectif ce qui signifie travailler en équipe côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le groupe de son savoirfaire cest aussi la possibilité dévoluer de changer de fonction ou dactivité voire de pays    qui sommesnous     thales propose des systèmes dinformation et de communication sécurisés et interopérables pour les forces armées les forces de sécurité et les opérateurs dimportance vitale ces activités qui regroupent radiocommunications réseaux systèmes de protection systèmes dinformation critiques et cybersécurité répondent aux besoins de marchés où lutilisation des nouvelles technologies numériques est déterminante thales intervient tout au long de la chaîne de valeur des équipements aux systèmes en passant par le soutien logistique et les services associés    nos équipes de lactivité systèmes dinformation critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance la résilience et la sécurité des systèmes dinformation afin de faire face aux ruptures technologiques et aux cybermenaces    le département augmented data recherche un ingénieur data scientist expérimenté hf basé à sophiaantipolis     qui etesvous       de formation bac  minimum vous maitrisez le fonctionnement des algorithmes de machine learning et possédez de bonnes connaissances en ingénierie logicielle\\xa0      vous avez de lexpérience sur une plateforme cloud azureawsgcp\\xa0      vous êtes familier avec certains outils data tels que dataiku mlflow dvc kibana sagemaker\\xa0      vous maitrisez des langages de développement logiciel python spark scala java cc \\xa0      tensorflow keras pytorch scikitlearn ou pandas  nont pas de secrets pour vous\\xa0      vous maitrisez langlais\\xa0      vous souhaitez mettre en application vos compétences pour la résolution de problèmes complexes dans des domaines métiers variés\\xa0      vous aimez transmettre vos savoirs faires et accompagner les utilisateurs dans la prise en main de vos solutions innovantes\\xa0      vous aimez travailler en équipe au quotidien et vous savez interagir en mode «\\xa0agile\\xa0» pour vous le succès nest que collectif       vous avez plus de  ans dexpérience sur un poste équivalent    vous vous reconnaissez  alors parlons missions     ce que nous pouvons accomplir ensemble     le département augmented data fédère et coordonne les savoirfaire algorithmie big data data science et data viz au travers dune structure permettant daccélérer la transformation des enjeux data de nos clients    nos savoirs faires\\xa0      data science intelligence artificielle algorithmie expertise imagerie\\xa0      data engineering devops mlops    nos partenaires\\xa0      recherche  inria cnrs inserm ia\\xa0      externes  nvidia elastic mongodb    vos missions en collaboration avec les membres de notre structure augmented data       assurer la veille technologique pour suivre les évolutions en machine learning et ia      accompagner nos clients dans leurs projets de valorisation de données en proposant des solutions techniques innovantes et pertinentes      sélectionner concevoir implémenter et valider des solutions data science dans des domaines variés industrie spatial défense santé      participer aux réflexions sur', 'description du poste nous rejoindre cest rejoindre lun des leaders mondiaux de la distribution qui met laccent au quotidien sur la diversité la rse et le digital pour satisfaire nos clients et nos collaborateurs en tant que partenaire premium des jeux olympiques et paralympiques de paris  nous partageons les valeurs du sport en permettant à nos équipes de se dépasser et encourageons une alimentation saine au juste prix pour tousvous cherchez à travailler dans une entreprise dynamique où votre travail rime avec impact social et environnemental  bienvenue chez nous carrefour recherche pour sa direction data groupe une data scientist confirmé fhbon à savoir  cdi  cadre  massy  asapnous utilisons des approches de machine learning pour résoudre des défis commerciaux et opérationnels comme les ruptures en magasin la prévision des ventes loptimisation de lassortiment des produits la personnalisation de lexpérience sur le site carrefourfrvos missionsau sein du pôle de data science vous intégrerez une talentueuse feature team rassemblant différentes compétences vous évoluerez dans un environnement agile et collaboratifen intervenant à toutes les étapes des projets vous pourrez discuter avec les équipes opérationnelles et dirigeantes pour identifier leurs difficultés et réfléchir comment le machine learning peut les aider à les résoudreévaluer la qualité des données les nettoyer les agréger et mener des études adhocconcevoir implémenter et comparer différents algorithmes et méthodes statistiquesconcevoir et mener des protocoles de test en conditions réelles magasins entrepôts développer des outils de visualisation des donnéesmettre en production maintenir et itérer sur les solutionsvous pourrez également participer aux échanges réguliers de notre communauté dune quarantaine dingénieurs data scientists engineers devops  séminaires partage de retours de conférences débats sur les problématiques ml de développement logiciel en tant que data scientist vous rapporterez au data science manager de votre équipevotre profildiplômé en informatique ou mathématique appliquée au moins au niveau master ou justifiant dune expérience professionnelle équivalente vous disposez de très solides connaissances sur les algorithmes dapprentissage statistiqueà lissue dau moins  années dexpérience professionnelle vous avez développé une expertise sur chaque étape du cycle de vie dun projet de data science  collecte des données et préparation modélisation évaluation et déploiement des modèlesla manipulation de base de données à grande échellevous êtes motivé par les problématiques opérationnelles très concrètes que lon peut notamment rencontrer dans lunivers de la grande distribution pour cela vous aimez interagir avec des professionnels dhorizons différents grâce à dexcellentes qualités relationnelles et de communication vous êtes en mesure de communiquer vos idées complexes à différents publics nontechniquesvous aimez aborder de nouveaux défis de machine learning dans différents domainesvous avez pris part à des projets de développement collaboratifs et la qualité et la simplicité du code vous tiennent à cœurvous maîtrisez le français et êtes notamment en mesure de mener des discussions avec les opérationnels de carrefour france vous maîtrisez un anglais technique a minimales petits plustravaillant quotidiennement sur gcp dans une démarche serverless nous apprécions vos expériences sur nimporte quelle plateforme cloudvos talents de data engineer seront également les bienvenus pour faciliter le traitement de nos téraoctets de donnéesadoptant une approche itérative nous accordons une grande valeur à vos expériences de développeur logiciel agileavoir implémenté testé et validé une solution fondée sur le ml dans le domaine du retail ou du ecommerce est une expérience très précieuse à nos yeux notre environnement techniquepython sql terraform docker gitlab jenkins gcp cloud composer  airflow cloudrun bigquery dataproc  spark cloud batch kubernetes engine vertex ai cloud storageinformations complémentaires  lieu  massy gare rer b et rer cintéressement et participationtélétravailmutuelle  prévoyanceremboursement des frais de transport à hauteur de  de remise sur achats avec la carte passvous aurez accès aux infrastructures du campus salle de sport crèche plusieurs options de restauration au sein du siège avec participation ce infirmerie téléconsultation médicale conciergerie coiffeur etc carrefour sengage pour la santé et le bienêtre de ses collaborateurs en leur proposant u', 'poste  ingénieur data scientist hfdescription  qui etesvous   de formation bac  minimum vous maitrisez le fonctionnement des algorithmes de machine learning et possédez de bonnes connaissances en ingénierie logicielle   vous avez de lexpérience sur une plateforme cloud azureawsgcp   vous êtes familier avec certains outils data tels que dataiku mlflow dvc kibana sagemaker   vous maitrisez des langages de développement logiciel python spark scala java cc   tensorflow keras pytorch scikitlearn ou pandas nont pas de secrets pour vous   vous maitrisez langlais   vous souhaitez mettre en application vos compétences pour la résolution de problèmes complexes dans des domaines métiers variés   vous aimez transmettre vos savoirs faires et accompagner les utilisateurs dans la prise en main de vos solutions innovantes   vous aimez travailler en équipe au quotidien et vous savez interagir en mode « agile » pour vous le succès nest que collectif   vous avez plus de  ans dexpérience sur un poste équivalentvous vous reconnaissez  alors parlons missionsce que nous pouvons accomplir ensemble le département augmented data fédère et coordonne les savoirfaire algorithmie big data data science et data viz au travers dune structure permettant daccélérer la transformation des enjeux data de nos clientsnos savoirs faires   data science intelligence artificielle algorithmie expertise imagerie   data engineering devops mlopsnos partenaires   recherche  inria cnrs inserm ia   externes  nvidia elastic mongodbvos missions en collaboration avec les membres de notre structure augmented data   assurer la veille technologique pour suivre les évolutions en machine learning et ia  accompagner nos clients dans leurs projets de valorisation de données en proposant des solutions techniques innovantes et pertinentes  sélectionner concevoir implémenter et valider des solutions data science dans des domaines variés industrie spatial défense santé  participer aux réflexions sur la gestion du cycle de vie des algorithmes et des données en production  contribuer à lintégration et au déploiement en production des solutions développées conteneurisation services managés apis  communiquer et partager votre savoirfaire au travers de publications conférences et webinarsla perspective de rejoindre un groupe innovant vous motive  alors rejoigneznous en postulant à cette offrevotre carrière chez thales  différentes opportunités vous permettront de découvrir dautres domaines ou sites vous pourrez évoluer et développer vos compétences dans différents domaines   explorez un espace attentif au développement personnel développez vos talents dans un autre domaine du groupe thales en découvrant de nouveaux produits de nouveaux clients un nouveau pays ou en vous orientant vers une solution plus complexe choisissez entre une expertise technique ou un parcours de leadership construisez une carrière internationale au sein dun groupe dingénierie de premier planavantages intéressement et participation groupe annuels activités socioculturelles du cse mutuelle pouvant couvrir conjointe et enfants sans surcoût package de congés avantageux et évolutif rtts accord télétravail primes de cooptation mobilité groupe convention collective de la métallurgie etcinnovation passion ambition  rejoignez thales et créez le monde de demain dès aujourdhuiprofil ', 'descriptif du postesi vous êtes à la recherche dune alternance\\xa0en data science rejoignez kaisens datales sujets porteront sur le nlp la nlg moteur de recherche et chatbotkaisens data entreprise à la pointe des technologies ia développe des solutions logicielles clé en mainun département indépendant propose du conseil à haute valeur ajoutée il accompagne également des sociétés de cac dans plusieurs domaines industrie santé banques assurances etc ainsi nous sommes présents dans tous les secteurs à forte intensité technologique qui contribuent à une société plus connectée et plus durableresponsabilités·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 implémenter et tester des algorithmes modules en se basant sur des méthodes machine learning deep learning ou système expert python py spark·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 déploiement des modules dans un environnement de production·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 participer à la spécification et la mise en place des projets client·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 faire des recherches bibliographiques en fonction des nouveaux concepts en ia·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 documentation des modules développéprofil recherché \\xa0 \\xa0 \\xa0bonne connaissance en python pyspark est un plus \\xa0 \\xa0\\xa0\\xa0maîtrise de certaines bases de données sql et nosql mongodb mysql \\xa0\\xa0\\xa0 \\xa0connaissances des librairies scikitlearn pandas matplotlib tenserflow opencv est un plus \\xa0\\xa0 \\xa0 bonne communication à loral et à lécrit \\xa0 \\xa0 \\xa0autonome curieuxse et passionnée des nouvelles technologies\\xa0', 'description du posteintégrée au sein de léquipe data et rattachée aux responsables de produits data vous serez en charge de lexploitation des données de lentreprise afin den extraire de la valeur pour aider le comité exécutif à prendre des décisions stratégiques et opérationnellespionnier du courtage en prêt immobilier depuis  ans cafpi vit aujourdhui un tournant important avec un fort enjeu de digitalisation et une réelle ambition de développement dans ce contexte de nombreux projets data verrons le jour en la mission du stage sarticulera en deux parties · un projet de scoring ia sur un produit spécifique chez cafpi rac regroupement de crédits le scoring sera une ia permettant de classifier le client remplissant un formulaire web afin de déterminer si ce client est prometteur compliqué ou impossible à financer cette classification permettra ensuite de traiter en priorité certains clients et déliminer automatiquement certains dossiers· vous piloterez des analyses relatives à la production de lentreprise  récupération des données et fiabilisation de la base analyses spécifiques  reporting analyses stratégiques permettant daiguiller le développement du produit proposition de plans dactionstotalement intégré dans lécosystème cafpi vous collaborerez avec lensemble des services it marketing commerce opération vous serez également amené à collaborer sur les projets dintelligence artificielle avec les autres membres de léquipe dataprofilvous êtes en bac et souhaitez valider votre cursus ingénieur ou master  en data ou vous êtes à la recherche dun stage en césure vous maitrisez les techniques de modélisation statistique motivé dynamique et bon communicant vous souhaitez un stage à responsabilité pour lancer votre carrière professionnellece que nous te proposons   une gratification compétitive des tickets restaurant des évènements déquipe réguliersdurée du stage   moislocalisation  bayonnedébut du stage  janvier cafpi valorise la diversité et linclusion et encourage toutes les personnes qualifiées à postuler rejoigneznous pour contribuer au succès de notre entreprise ', 'ambitieux dans le développement de notre pôle dexcellence ia et le développement de nos partenariats google et microsoft nous recrutons notre consultante ou consultant data scientist à paris vous rejoignez notre communauté de ds avec nos leads yann et julien afin daccompagner nos clients dans leurs enjeux business et leur recherche de performance grâce à lutilisation de la donnée et à la puissance de lia votre mission\\u202f   accompagner nos clients à inventer de nouveaux modèles de valeurs à identifier leurs problématiques métiers et à qualifier leurs besoins  nouveaux modèles business performance opérationnelle data marketing marketing produit résultats financiers optimisation de processus métiers relation client collaborateur  prévisions dactivités  auditer analyser mettre en œuvre et industrialiser les solutions les plus adaptées et performantes notamment avec une approche mlops  animer et accompagner des communautés data et métiers à ladoption des bonnes pratiques  ateliers dacculturation et didéation formation à lutilisation des outils cadrage des cas dusages auprès des métiers poc  réaliser une veille régulière et partagée sur létat de lart de la data science  être partie prenante des projets transverses de valoway  communication et conférences recrutement pôles dexcellence ia missions davantvente de conseil et de cadrage rex webinaires   nos principaux environnements techniques\\u202f   modélisation  machine learning transfer learning nlp computer vision llm  langages  python sql spark   cloud providers gcp azure aws  visualisation power bi tableau software google data studio looker   notre environnement de travail  vous souhaitez en savoir plus sur le poste de data scientist chez valoway  cest notre équipe qui en parle le mieux  tedxlarochelle avec yann  tech lead les ia ne sont pas    lagilité est au cœur de notre organisation elle se traduit notamment par un mode de travail hybride et la possibilité dalterner entre présence chez nos clients dans nos bureaux ou en télétravail en fonction des sujets à mener  vous collaborez avec des consultants ayant un haut niveau de compétences appuyées par des missions stratégiques et des cas dusages significatifs dans des environnements complexes des secteurs de lassurance de la banque de lindustrie du transport du retail ou de la grande distribution  pour ce poste de data scientist en cdi le salaire indicatif que nous vous proposons à paris est compris entre  k€ et  k€ brut annuel cette rémunération sétudie en fonction de vos expériences et de votre profil vous bénéficierez également de rtt et dune carte swile appuyé par une expérience dau moins  ans notamment en développement automatisation de modèles prédictifs vous êtes capable de cadrer un projet en autonomie avec une vraie culture de services et de succès client autonome et doté dune solide sensibilité business vous êtes force de proposition et aimez évoluer dans un environnement challengeant   nous rejoindre en tant que consultante ou consultant chez valoway cest également un état desprit  intégrer une équipe animée par linnovation le développement de son expertise et qui souhaite relever de nouveaux challenges    autonomie dans la relation client  débrouillardise et curiosité  sens du partage et du travail en équipe  ce poste vous correspond  vous souhaitez en savoir plus  adresseznous votre candidature  notre process de recrutement pour ce poste    un échange avec emma ou sonia nos rh sur votre projet professionnel  un échange technique et culture avec nos consultantes et consultants  julien notre team lead louise yann ou alice afin de vous donner un aperçu de notre quotidien et vous embarquer dans notre vision   un entretien avec gwénolé directeur et louis vincent fondateur de valoway pour vous partager les enjeux de valoway  la durée moyenne du process est dun mois et peut sadapter en fonction de vos obligations nous sommes flexibles ', 'ambitieux dans le développement de notre pôle dexcellence ia et le développement de nos partenariats google microsoft et dataiku nous recrutons notre consultante ou consultant data scientist à rennes vous rejoignez notre communauté de ds avec nos leads yann et julien afin daccompagner nos clients dans leurs enjeux business et leur recherche de performance grâce à lutilisation de la donnée et à la puissance de lia votre mission\\u202f   accompagner nos clients à inventer de nouveaux modèles de valeurs à identifier leurs problématiques métiers et à qualifier leurs besoins  nouveaux modèles business performance opérationnelle data marketing marketing produit résultats financiers optimisation de processus métiers relation client collaborateur  prévisions dactivités  auditer analyser mettre en œuvre et industrialiser les solutions les plus adaptées et performantes notamment avec une approche mlops  animer et accompagner des communautés data et métiers à ladoption des bonnes pratiques  ateliers dacculturation et didéation formation à lutilisation des outils cadrage des cas dusages auprès des métiers poc  réaliser une veille régulière et partagée sur létat de lart de la data science  être partie prenante des projets transverses de valoway  communication et conférences recrutement pôles dexcellence ia missions davantvente de conseil et de cadrage rex webinaires   nos principaux environnements techniques\\u202f   modélisation  machine learning transfer learning nlp computer vision llm  langages  python sql spark   cloud providers gcp azure aws  visualisation power bi tableau software google data studio looker   notre environnement de travail  vous souhaitez en savoir plus sur le poste de data scientist chez valoway  cest notre équipe qui en parle le mieux  alice alice « lia générative générateur de satisfaction client  » lors de who run the tech   lagilité est au cœur de notre organisation elle se traduit notamment par un mode de travail hybride et la possibilité dalterner entre présence chez nos clients dans nos bureaux ou en télétravail en fonction des sujets à mener  vous collaborez avec des consultants ayant un haut niveau de compétences appuyées par des missions stratégiques et des cas dusages significatifs dans des environnements complexes des secteurs de lassurance de la banque de lindustrie du transport du retail ou de la grande distribution  pour ce poste de data scientist en cdi le salaire indicatif que nous vous proposons à rennes est compris entre  k€ et  k€ brut annuel cette rémunération sétudie en fonction de vos expériences et de votre profil vous bénéficierez également de rtt et dune carte swile vous avez participé et mené des projets utilisés par les métiers embarquant des briques dintelligence artificielle appuyé par une expérience dau moins  ans notamment en développement automatisation de modèles prédictifs vous êtes capable de vulgariser et faire parler les données jusquà leur restitution avec une vraie culture de services et de succès client   nous rejoindre en tant que consultante ou consultant chez valoway cest également un état desprit  intégrer une équipe animée par linnovation le développement de son expertise et qui souhaite relever de nouveaux challenges    autonomie dans la relation client  débrouillardise et curiosité  sens du partage et du travail en équipe  ce poste vous correspond  vous souhaitez en savoir plus  adresseznous votre candidature  notre process de recrutement pour ce poste    un échange avec emma ou sonia nos rh sur votre projet professionnel  un échange technique et culture avec nos consultantes et consultants  julien notre team lead louise yann ou alice afin de vous donner un aperçu de notre quotidien et vous embarquer dans notre vision   un entretien avec gwénolé directeur et louis vincent fondateur de valoway pour vous partager les enjeux de valoway  la durée moyenne du process est dun mois et peut sadapter en fonction de vos obligations nous sommes flexibles ', 'ambitieux dans le développement de notre pôle dexcellence ia et le développement de nos partenariats google microsoft et dataiku nous recrutons notre consultante ou consultant data scientist à niort vous rejoignez notre communauté de ds avec nos leads yann et julien afin daccompagner nos clients dans leurs enjeux business et leur recherche de performance grâce à lutilisation de la donnée et à la puissance de lia votre mission\\u202f   accompagner nos clients à inventer de nouveaux modèles de valeurs à identifier leurs problématiques métiers et à qualifier leurs besoins  nouveaux modèles business performance opérationnelle data marketing marketing produit résultats financiers optimisation de processus métiers relation client collaborateur  prévisions dactivités  auditer analyser mettre en œuvre et industrialiser les solutions les plus adaptées et performantes notamment avec une approche mlops  animer et accompagner des communautés data et métiers à ladoption des bonnes pratiques  ateliers dacculturation et didéation formation à lutilisation des outils cadrage des cas dusages auprès des métiers poc  réaliser une veille régulière et partagée sur létat de lart de la data science  être partie prenante des projets transverses de valoway  communication et conférences recrutement pôles dexcellence ia missions davantvente de conseil et de cadrage rex webinaires   nos principaux environnements techniques\\u202f   modélisation  machine learning transfer learning nlp computer vision llm  langages  python sql spark   cloud providers gcp azure aws  visualisation power bi tableau software google data studio looker   notre environnement de travail  vous souhaitez en savoir plus sur le poste de data scientist chez valoway  cest notre équipe qui en parle le mieux  alice lia générative générateur de satisfaction client   lagilité est au cœur de notre organisation elle se traduit notamment par un mode de travail hybride et la possibilité dalterner entre présence chez nos clients dans nos bureaux ou en télétravail en fonction des sujets à mener  vous collaborez avec des consultants ayant un haut niveau de compétences appuyées par des missions stratégiques et des cas dusages significatifs dans des environnements complexes des secteurs de lassurance de la banque de lindustrie du transport du retail ou de la grande distribution  pour ce poste de data scientist en cdi le salaire indicatif que nous vous proposons à niort est compris entre  k€ et  k€ brut annuel cette rémunération sétudie en fonction de vos expériences et de votre profil vous bénéficierez également de rtt et dune carte swile vous avez participé et mené des projets utilisés par les métiers embarquant des briques dintelligence artificielle appuyé par une expérience dau moins  ans notamment en développement automatisation de modèles prédictifs vous êtes capable de vulgariser et faire parler les données jusquà leur restitution avec une vraie culture de services et de succès client   nous rejoindre en tant que consultante ou consultant chez valoway cest également un état desprit  intégrer une équipe animée par linnovation le développement de son expertise et qui souhaite relever de nouveaux challenges    autonomie dans la relation client  débrouillardise et curiosité  sens du partage et du travail en équipe  ce poste vous correspond  vous souhaitez en savoir plus  adresseznous votre candidature  notre process de recrutement pour ce poste    un échange avec emma ou sonia nos rh sur votre projet professionnel  un échange technique et culture avec nos consultantes et consultants  julien notre team lead louise yann ou alice afin de vous donner un aperçu de notre quotidien et vous embarquer dans notre vision   un entretien avec gwénolé directeur et louis vincent fondateur de valoway pour vous partager les enjeux de valoway  la durée moyenne du process est dun mois et peut sadapter en fonction de vos obligations nous sommes flexibles ', 'ambitieux dans le développement de notre pôle dexcellence ia et le développement de nos partenariats google et microsoft nous recrutons notre consultante ou consultant data scientist à nantes vous rejoignez notre communauté de ds avec nos leads yann et julien afin daccompagner nos clients dans leurs enjeux business et leur recherche de performance grâce à lutilisation de la donnée et à la puissance de lia votre mission\\u202f   accompagner nos clients à inventer de nouveaux modèles de valeurs à identifier leurs problématiques métiers et à qualifier leurs besoins  nouveaux modèles business performance opérationnelle data marketing marketing produit résultats financiers optimisation de processus métiers relation client collaborateur  prévisions dactivités  auditer analyser mettre en œuvre et industrialiser les solutions les plus adaptées et performantes notamment avec une approche mlops  animer et accompagner des communautés data et métiers à ladoption des bonnes pratiques  ateliers dacculturation et didéation formation à lutilisation des outils cadrage des cas dusages auprès des métiers poc  réaliser une veille régulière et partagée sur létat de lart de la data science  être partie prenante des projets transverses de valoway  communication et conférences recrutement pôles dexcellence ia missions davantvente de conseil et de cadrage rex webinaires   nos principaux environnements techniques\\u202f   modélisation  machine learning transfer learning nlp computer vision llm  langages  python sql spark   cloud providers gcp azure aws  visualisation power bi tableau software google data studio looker   notre environnement de travail  vous souhaitez en savoir plus sur le poste de data scientist chez valoway  cest notre équipe qui en parle le mieux   alice « lia générative générateur de satisfaction client  » lors de who run the tech   lagilité est au cœur de notre organisation elle se traduit notamment par un mode de travail hybride et la possibilité dalterner entre présence chez nos clients dans nos bureaux ou en télétravail en fonction des sujets à mener  vous collaborez avec des consultants ayant un haut niveau de compétences appuyées par des missions stratégiques et des cas dusages significatifs dans des environnements complexes des secteurs de lassurance de la banque de lindustrie du transport du retail ou de la grande distribution  pour ce poste de data scientist en cdi le salaire indicatif que nous vous proposons à nantes est compris entre  k€ et  k€ brut annuel cette rémunération sétudie en fonction de vos expériences et de votre profil vous bénéficierez également de rtt et dune carte swile vous avez participé et mené des projets utilisés par les métiers embarquant des briques dintelligence artificielle appuyé par une expérience dau moins  ans notamment en développement automatisation de modèles prédictifs vous êtes capable de vulgariser et faire parler les données jusquà leur restitution avec une vraie culture de services et de succès client   nous rejoindre en tant que consultante ou consultant chez valoway cest également un état desprit  intégrer une équipe animée par linnovation le développement de son expertise et qui souhaite relever de nouveaux challenges    autonomie dans la relation client  débrouillardise et curiosité  sens du partage et du travail en équipe  ce poste vous correspond  vous souhaitez en savoir plus  adresseznous votre candidature  notre process de recrutement pour ce poste    un échange avec emma ou sonia nos rh sur votre projet professionnel  un échange technique et culture avec nos consultantes et consultants  julien notre team lead louise yann ou alice afin de vous donner un aperçu de notre quotidien et vous embarquer dans notre vision   un entretien avec gwénolé directeur et louis vincent fondateur de valoway pour vous partager les enjeux de valoway  la durée moyenne du process est dun mois et peut sadapter en fonction de vos obligations nous sommes flexibles ', 'description du poste au sein de la direction datascience marketing et modélisation de la division du financement aux particuliers qui produit et distribue des crédits et des services auprès de particuliers en direct ou par lintermédiaire de partenaires distributeurs assureurs banquiers et fintech vous rejoignez le pôle datascience et risque en tant que data scientist risquevos missions au sein dun service de  personnes vous participez au développement etou à lévolution des modèles économétriques statistiques appliqués à la prédiction des risquesen qualité data scientiste risque vos principales missions seront de concevoir et analyser des bases de données de modélisation créer calibrer et back tester les modèles quantitatifs de prédiction daide à la décision et de mesure des risques documenter les modèles et instruire leur validation auprès des corps daudit contribuer au développement des solutions de datascience mises en place dans le cadre des nouveaux projets de gestion des risques participer à la dynamique déquipe sur la conception la réalisation et de développement des applications datascience pour comptepropre et au service de nos partenaires bbc participer au développement des méthodes dautomatisation de production des indicateurs des modèles des backtests et des restitutions alimentant le pilotage des activitésdescription du profil les principales compétences requises pour le poste sont maîtrise des techniques de modélisation du risque modèles économétriques modèles statistiques modèles probabilistes machine learning techniques de data visualisation etc connaissances bancaires et réglementaires outils  niveau dautonomie et de compréhension suffisants des applications et si maîtrise des langages de programmation sas en particulier r python serait un plus bonne communication écrite et orale fiabilité rigueur et organisation curiosité ouverture desprit capacité dalertede formation supérieure en statistiques vous possédez à minima au moins  à  ans dexpériences au sein dune banque dun établissement financier dun régulateur dune agence de notation ou dun cabinet de conseil ce qui vous a permis dacquérir des connaissances en modélisation du risque de la réglementation bâle  et de la modélisation statistiquenous avons la conviction que la diversité de nos collaborateurs sous toutes ses formes est une richesse pour notre entreprise et ses clients nos postes sont ainsi ouverts à tous nous garantissons légalité de vos chances dans nos processus de recrutement et tout au long de votre carrière chez franfinanceposte basé à nanterre  rer a rueilmalmaisonjusquà  jours de télétravail par semaine', 'description du poste nous vous proposons de rejoindre le data lab en qualité de data scientist au sein de léquipe retailtout dabord vous prendrez part à des missions de linspection générale ou de laudit au cours de ces missions vous vous assurerez de comprendre et expliciter la problématique notamment avec une orientation « data »vous identifierez les données à forte valeur visàvis de la mission et assurerez la liaison avec les propriétaires de ces donnéesvous organiserez la collecte des données dans le respect de leur sensibilité et du cycle de vie définivous réaliserez lanalyse des données en accord avec les besoins des intervenants de la missionlorsque possible etou nécessaire vous vous attacherez à présenter les résultats de vos analyses à la fois aux intervenants de la mission ainsi quau service auditévous rédigerez un rapport danalyse détaillévous serez le référent « data » de la mission et assurerez le contact privilégié entre les intervenants de la mission et le data labvous participerez également à la définition de loffre de service du data lab vous serez amené à travailler avec la dsi digad pour déterminer loffre outillée adéquate et nécessaire à lactivité danalyse de donnéesvous participerez à des activités transverses que ce soit au niveau du data lab ou plus globalement digad vous participerez à la formation des inspecteurs et des auditeurs à lanalyse de donnéesvous participerez à la « communauté data » particulièrement au sein du data lab mais également au niveau du groupeenfin vous travaillerez à des sujets plus orientés « recherche » vous assurerez une veille technologique sur le sujet de la data sciencevous prendrez part aux activités de recherche menées par le data labdescription du profil vous êtes diplômé dun bac bac en ecole dingénieur master spécialisé avec dexpérience significative sur le domaine data vous parlez anglais couramment lu parlé et écrit votre curiosité intellectuelle et votre intérêt pour le secteur bancaire vous pousse à comprendre les activités dont vous travaillez les données et les besoins de vos clients vous êtes rigoureux avez le sens des responsabilités et du résultat et aimez résoudre des problèmes vous avez lesprit dinitiative et la volonté de dépasser le cadre existant vous faites preuve à la fois dune autonomie dans votre activité et dun goût pour le travail en équipe vous témoignez dune forte appétence pour les sujets afférents aux données vous démontrez une connaissance approfondie des domaines du data mining et du machine learning notamment dun point de vue algorithmique outre les logiciels bureautiques usuels vous maîtrisez les langages de gestion de bases de données usuels sql sas etc ainsi quau moins un langage de programmation utilisé dans lanalyse de données python r js etc des compétences en visualisation de la donnée et outils associés type d voir en expérience utilisateur ux est un plus non requise la connaissance des applications et infocentres du groupe est un plusle poste est basé à paris certains déplacements à linternational peuvent être prévus', 'les risques non financiers sont au cœur des préoccupations du groupe par le coût quils engendrent et les contraintes réglementaires fortes sy attachant ils découlent de la défaillance dun processus du personnel dun système interne ou dun événement extérieurdans le cadre de lévolution de son organisation la direction des risques non financiers et du contrôle permanent sest doté dun datalabdatalab dont la mission est de construire mettre à disposition et produire des analyses de risques destinées à lensemble des acteurs du groupe concernés par ces problématiquesles activités liées à la gestion des risques non financiers et du contrôle permanent sont en profonde transformation en lien avec lextension des capacités de stockage de calcul et de traitement des donnéesnous vous proposons de rejoindre le datalab des risques nonfinanciers en qualité de data scientist  data analystconcrètement vous serez amenée à   porter un sujet orienté « recherche et développement » sur la gestion des risques non financiers avec lapport de la science des données détection de signaux faibles création dindicateurs avancés de risque développement de modèles de prédiction exploitation de données internes et externes   contribuer en collaboration avec les autres data scientists et les équipes it dédiées à la mise en œuvre des solutions envisagées pour répondre aux besoins métiers exprimés identification et organisation de la collecte des données développement des modèlesalgorithmes mise en production communication des résultats et des analyses   participer à des activités transverses que ce soit au niveau du datalab ou plus globalement des fonctions risques du groupe définition de loffre de service du datalab sensibilisationformation des métiers veille technologique  vous préparez un bac en école dingénieuruniversitéécole de commerce avec une spécialisation en sciences des données informatique mathématiquesstatistiques   vous avez des connaissances en informatique et vous maîtrisez un langage de programmation python ou r et de gestion de bases de données sql sas   vous avez une première expérience en traitement du langage naturel  nlp  vous êtes curieuxse et vous avez un intérêt pour le secteur bancaire qui vous pousse à comprendre les activités dont vous travaillez les données  vous faites preuve à la fois dune autonomie dans votre activité dun goût pour le travail en équipe et votre sens de la rigueur et votre orientation résultat ne sont pas à démontrer   vous êtes à laise pour communiquer sur vos analyses  pédagogue vous savez vous adapter à vos interlocuteurs  vous aimez résoudre des problèmes pour lesquelles il ny a pas de solution évidente  youre fluent in english  vous êtes notre candidate idéale ', 'dans le cadre du développement de notre entité abylsen stra sciences  technologies rhônealpes auvergne bourgogne spécialisée dans le transport automobile aéronautique défense spatiale et ferroviaire lindustrie lourde métallurgie aciérie et lenergie nous recherchons un data scientist hf pour intégrer notre équipe et apporter votre expertise sur lensemble de nos projets votre rôle consistera à   collecter et analyser les données internes et externes par lutilisation de méthodes statistiques pour connaitre et exploiter en continu les évolutions des domaines dapplication   sélectionner et mettre en oeuvre des algorithmes dapprentissage automatique pertinents sur les cas dusage machine learning deep learning etc   communiquer les résultats et les solutions avec les équipes métiers et instances de direction en veillant à vulgariser les concepts complexes   maintenir faire évoluer et documenter les modèles existants en collaboration avec les utilisateursce poste est fait pour vous si vous avez   une formation de minimum bac avec une spécialisation en statistique ou informatique décisionnelle  une première expérience significative sur un poste similaire environnement technique   bases de données sqlnosql  langages de programmation java sql python r sas etc  méthodes et algorithmes de machine learning et de deep learning audelà de vos connaissances techniques cest véritablement votre personnalité qui fera la différence  abylsen cest également   des opportunités dévolution  explorez de nouveaux horizons professionnels votre carrière na pas de limites   une formation continue  notre plateforme learning vous offre des formations en ligne adaptées  un environnement inclusif  chez abylsen nous célébrons la diversité et linclusion  des avantages   statut contractuel cdi   jours de congés payés et  jours de rtt  comité dentreprise  prise en charge des transports à   accord de participation  prime vacances rejoigneznous pour une aventure où chaque jour est une opportunité de repousser les limites et de transformer les défis en succès ensemble écrivons lavenir de lingénierie et de linnovation  dans le cadre de légalité des chances toutes nos offres demploi sont ouvertes aux personnes en situation de handicap', 'lunalogic est un cabinet de conseil créé en  présent à paris londres hongkong et casablanca spécialisé sur lensemble de la chaîne de valeur financière les expertises du cabinet sont reconnues par les plus grands établissements financiers et reposent sur une politique de recrutement sélective grandes écoles dingénieurs et universités reconnues ces expertises recouvrent  les risques et lanalyse quantitative  la data science et les nouvelles technologies au service de la financeengagés dans une démarche de développement de qualité et de performance nous renforçons notre pôle finance et recrutons une consultante data scientist nous recherchons une data scientist junior talentueux et passionnée pour rejoindre une institution financièrele profil recherché pour la mission a validé un diplôme dingénieur science des données et de décisionles compétences requises pour ce poste sont              expérience démontrée en data science à minima un stage en lien avec le diplôme obtenu             solides compétences en ia intelligence artificielle             compétences en matière de blockchains et de smart contracts             anglais courant poste en cdi à pourvoir immédiatement rémunération attractive selon profilvous souhaitezvous investir pleinement au sein dune société en pleine évolution en intégrant un poste à forte valeur ajoutée dans ce cas rejoigneznous en nous adressant votre candidature dès à présent sous la référence  si vous êtes intéressé merci de nous adresser votre cv', 'descriptif du posteimaginez demainau sein du département « rd information system » vous rejoignez léquipe rd data science qui est en charge de la spécification du développement de la mise en production et de la maintenance dun système décisionnel permettant daider les équipes devops dans la supervision et loptimisation de notre chaîne de production\\xa0 intégration continue et déploiement continudans lapproche devops les équipes prennent en charge les parties continuous monitoring and learning soit\\xa0le développement des robots de collection et dagrégation de données massives issues de nos chaînes de développement dopérations et de productionla conception le développement et le test des algorithmes innovants\\xa0 descriptive analytics predictive analytics discovery analytics and perspective analytics\\xa0la présentation des résultats sous forme de dashboard pour nos équipes devops\\xa0vos missions\\xa0dans ce contexte nous avons lancé des projets ambitieux autour du développement des systèmes intelligents automatisant autant que possible la vérification le suivi et loptimisation de la qualité de nos développements et proposant des solutions innovantes pour corriger optimiser et sadapter continuellement à lévolution de nos produitsen tant que data scientist vous interviendrez sur ces projets internes et serez amené à réaliser les missions suivantes assurer une veille technique et scientifique sur divers sujets notamment lévolution des modèles génératifs large language models  llmidentifier et exploiter les sources de données pertinentes à nos projetsproposer de nouvelles approches doptimisation finetuning prompt engineering pour améliorer lefficacité des modèles génératifs dans laide au développement softwareevaluer les nouvelles approches proposées en termes defficacité et de performance en utilisant des métriques adaptéessassurer de la bonne industrialisation des solutions tests unitaires tests de non régression approche devopsdévelopper des outils des processus et des rapports ou des visualisations de données spécifiques pour documenter capitaliser et communiquer votre travail et vos résultatsvous travaillerez en collaboration avec léquipe data science et les autres équipes du département plus particulièrement les équipes\\xa0 si bi et les architectesprofil recherché\\xa0vous justifiez dune expérience antérieure en apprentissage automatique et en traitement du langage naturel avec une expertise en modèles génératifsvous maîtrisez des langages de programmation tels que python et des bibliothèques ml pertinentesvous êtes familier avec les environnements dintégration continue et les meilleures pratiquesvotre anglais est courant à lécrit comme à loral', 'le groupe nrj riche de ses  collaborateurs figure parmi les principaux groupes de médias privés français et est aujourdhui un acteur incontournable du marché de la communication grâce à une offre globale radio tv digital et des marques fortes sur la radio nrj cherie fm nostalgie rire  chansons la télévision nrj  cherie  nrj hits et par sa filiale de diffusion towercast a linternational le groupe est implanté dans  autres pays soit par le biais dimplantations directes soit via des partenariats ou des contrats de licence de marque nrjenergy première marque radio internationale etou nostalgienostalgia nrj sengage depuis plusieurs années en faveur de linsertion des personnes en situation de handicap audelà de nos différences nous accordons la plus grande importance aux compétences et aux motivations de chacun         date de démarrage souhaitée  type de contrat  cddstatut  cadredurée du contrat    moisposte ouvert aux travailleurs en situation de handicaprattachée au directeur de la stratégie et des etudes vos missions seront les suivantes   détection de signaux pertinents à destination des antennes du groupe et de la direction générale à partir des données émanant des réseaux sociaux via talkwalker maintien dune écoute sociale média du marché intégrant les antennes et contenus du groupe et de la concurrence réalisation danalyses de données internes et externes remis aux antennes du groupe via tableau  excel détection de nouveaux talents et de nouveaux contenus pour le groupe mise en place danalyses sur les tendances de consommation du grand public et de nos consommateursinternautesauditeurstéléspectateurs collaboration avec les différents services pour la propagation des données pertinentes auprès des entités concernées   de formation bac vous justifiez dune expérience dau moins  ans sur un poste similaire a laise avec la data vous maîtrisez ms office tableau software talkwalker et la langue anglaise rigueur autonomie excellent relationnel et esprit déquipe sont les qualités requises pour réussir à ce postele groupe nrj a pour ambition de permettre à ses collaborateurs de sépanouir et de progresser tout en garantissant légalité de traitement la diversité et la nondiscrimination', 'cest un client final dans le monde de la logistiquele développeur bi business intelligence a pour mission de créer et gérer des solutions de veille stratégique et analytique permettant de transformer des données en connaissancesvotre quotidien sur le poste traduire les besoins des différents services en spécifications techniquesconcevoir développer et déployer des solutions biréaliser des tests unitaires et procéder au dépannagedévelopper et exécuter des requêtes de base de données et procéder à des analysescréer des visualisations et des rapports pour les projets demandésdévelopper et mettre à jour la documentation techniqueréaliser dextractions de données pour répondre aux demandes utilisateurs', 'nous cherchons un développeur python expérimenté pour notre équipe de data science spécialisé dans lintégration de technologies telles que la génération augmentée de récupération rag et ocr ainsi que dans lutilisation de modèles de langage à grande échelle llm via des api responsabilités principales   intégration de technologies avancées  intégrer des technologies comme rag et ocr dans les applications de data science  développement et intégration  concevoir et développer des applications en python intégrant des llm via api et des modèles préentraînés  optimisation et développement  assurer la robustesse et lévolutivité des applications développées    compétences et expertise requises   expertise en python  compétences avancées en développement python  expérience avec llm et api  expérience pratique avec lintégration de llm et lutilisation dapi de modèles préentraînés  bases en data science  compréhension des principes de base de la data science pour une collaboration efficace  une expérience sur le cloud serait un plusqualifications requises   formation  diplôme en informatique génie logiciel ou dans un domaine connexe    expérience professionnelle  expérience significative dans le développement dapplications python de préférence dans un contexte de data science', 'description du postequelques mots de contexteafin de soutenir son ambition de croissance somfy investit dans le renforcement de ses capacités digitales afin dextraire de la valeur du digital et des données une digital factory est en place pour construire un avantage concurrentiel fort en développant nos capacités data et digitales \\tla digital factory rassemble des talents du numérique pour accompagner le développement de solutions innovantes basées sur lalgorithme et lanalytique avancée augmenter les capacités digitales au sein de nos équipes adopter de nouvelles méthodes de travail par exemple agiles et globalement fournir un environnement efficace et attractif pour les talents et projets digitaux chez somfy \\tla digital factory conçoit construit exploite et met à niveau les solutions numériques propriétaires de somfy et déploie des solutions dans les entreprises  pays garantissant le bon niveau de localisation et dadoption le poste   dans le cadre dune création de poste vous rejoindrez une nouvelle équipe mettant en place les bases techniques de la digital factory vous travaillerez sur un projet digital stratégique pour le groupe somfy au sein dune équipe dataia créée from scratch en tant que data scientist vous développez des modèles et des solutions sur mesure basés sur des ensembles de données complexes en utilisant des mathématiques avancées et des techniques de visualisation afin de générer de la valeur ajoutée pour lentreprise en étroite collaboration avec les différents business missions principales \\tproposer de nouveaux modèles qui répondent aux besoins business en faisant preuve de créativité  \\tconcevoir et mettre en œuvre un code modulaire et maintenable  \\tcoordonner et être le référent des activités techniques en lien avec les équipes it data et autres afin de répondre aux demandes du business  \\tparticiper à la diffusion de la culturedes compétences dataia auprès de lensemble des équipes techniques  \\tchallenger et améliorer la stack technique existante et les processus de déploiement  nous sommes au début de cette  grande  aventure et les perspectives sont très belles léquipe se construit sagrandit les échanges sont riches et des moyens conséquents sont déployés pour parvenir à notre résultat envie de rejoindre laventure qualificationsformation et expérience  \\tdiplôme de master dingénieur ou phd dans un domaine quantitatif maths physique data science computer science \\tidéalement  années dexpérience en tant que data scientist y compris les stages et alternanceso\\ten industrialisation technique de solutions o\\ten collaboration avec un grand nombre dinterlocuteurs notamment le business \\texpérience dans des méthodologies agiles connaissances et savoirfaire  \\tmathématiques appliquées ml optimisation simulation \\tpython niveau expert \\tazure ai ou équivalent \\tgit \\ttrès bonne capacité à comprendre et intégrer des enjeux business \\tbonne maitrise de langlais et du français b minimumsoft skills \\tpro actifve et créatifve \\taisance relationnelle et esprit déquipe \\tecoute active informations complémentairescontrat cdi  plein temps démarrage début  avantages cse conciergerie activités wellness douches vestiaires restaurant dentreprise intéressement  participation indemnité kilométrique vélo j de télétravail an dont  semaines possibles hors domicile  journées solidairesan avec notre fondation la protection des données personnelles de nos candidats est un engagement du groupe somfy nous demandons donc à tout candidat de nous soumettre sa candidature exclusivement via notre système sécurisé et non par email ou par courrier postal', 'la société edvance recherche une data qualiticienne poste en cdi à pourvoir dès que possible à montrouge   vous aurez pour mission principale la mise en place de la stratégie qualité des données dipnn direction ingénierie des projets de nouveau nucléaire chez edvance   pour cela     vous communiquerez et participerez à la mise en place des critères de data qualité dipnn au sein dedvance    vous appuierez les data owners dedvance dans la définition des règles qualité à mettre sous contrôle sur les datasets dont ils sont responsables    vous appuierez les data stewards dans la création des kpi pour piloter les règles qualité définies avec les data owners      une mission secondaire consistera en la mise en place dun comité modèle de donnée et prise en main de rodin référentiel outillé des données de lingénierie nucléaire au sein dedvance   pour cela      vous centraliserez les demandes dévolution du mdd métier en réunissant les bonnes personnes des différentes disciplines le po etc afin de valider les évolutions du mdd métier    vous demanderez limplémentation de ces évolutions dans rodin et suivrez leur intégration dans le bon timing dans les outils type dx     vous appuierez les process owner dans la prise en main de rodin    vous participerez à la connaissance de rodin    vous créerez le lien avec le catalogue des données partagé astrolabe     de formation bac avec une expérience confirmée sur des sujets similaires    vous vous intéressez et avez la capacité de comprendre les finalités et les enjeux des métiers de lingénierie nucléaire génie civil contrôle commande tuyauterie sur lensemble du cycle epcc engineering procurement construction and commissioning     vous avez le sens de lécoute et du service avec des capacités relationnelles développées si nécessaire vous pouvez tenir des conversations avec le top management  vous contribuez naturellement aux projets de transformation et êtes force de proposition     vous travaillez en équipe et savez faire preuve de pédagogie     vous êtes autonome et rigoureuxse     vous connaissez les outils de data visualisation power bi et lenvironnement agile safe   vous avez un niveau danglais opérationnel       nous sommes à la recherche de candidates dynamiques ingénieuxse et passionnées autant par les métiers de lingénierie que par les métiers de la data et les solutions concrètes que la digitalisation peut apporter aux ingénieurs si vous pensez avoir les compétences et les qualités nécessaires pour rejoindre notre équipe nhésitez pas à postuler ', 'votre poste    la data chez shopopop est à la fois utilisée comme aide à la décision en support des choix techniques marketing et commerciaux et intégrée directement au sein de nos produits avec la forte croissance de lentreprise les missions au sein de léquipe data nont cessé de croître et nous sommes actuellement en train de finaliser la création dun datawarehouse   paul notre data scientist sétant envoler pour létranger cest avec impatience que jeanmarc team lead data et jordan data scientist attendent daccueillir leur future collègue au poste de data engineer   vous rejoindrez une équipe tech travaillant en contexte agile     engineering manager   cto   sre   lead dev transverse   équipe frontend  développeurs front   équipe backend  lead dev et  développeurs back   équipe mobile  développeurs mobile   head of product   product owners   product designers   testeurs qa    lécosystème de données permet dintervenir sur lensemble des domaines métiers ici la data met son grain de sel partout  en contact quotidien avec lensemble des services de shopopop le poste a une réelle portée opérationnelle     une pincée de segmentation pour davantage de visibilité selon les besoins marketing et business   de lanalyse de churn pour améliorer la rétention de nos cotransporteurs    une cuillerée de yield management pour optimiser la marge  le tout saupoudré danalyse géospatiale pour optimiser la logistique et la visibilité des livraisons ✨    en plus de loptimisation la création et limplémentation de ces algorithmes dans un environnement microservices vous serez en charge de les tester et dassurer leur mise en production pour faire évoluer le produit la partie analyse de données fera aussi partie de votre quotidien   si ce que vous avez lu jusquici vous a mis en appétit voici plus de détail    vos missions     créer optimiser développer et implémenter des microservices avec fastapi et optimiser la code base en python liée à la visibilité des livraisons dans un environnement de production  développer et maintenir une pipeline data intégrant des sources de données diverses     identifier les leviers daméliorations data sur lenvironnement de production  faire des analyses ponctuelles de données sur des besoins métiers produit et marketing et mener des analyses exploratoires en travaillant étroitement avec les équipes métier pour comprendre et répondre à leurs besoins  participer aux tâches récurrentes de léquipe data telles que la maintenance pipeline data et lamélioration des méthodes danalyse et de modélisation    environnement technique  python pandas et scikit learn fastapi mysql  postgresql dbt qlik sense github jira confluence cloud vous avez au moins  ans dexpérience en analyse de données avec du développement python afin dêtre à même de vous intégrer rapidement à lenvironnement de développement et de partager votre expérience   charmeureuse de serpent dans lâme développer et déployer en production du code en python dans un environnement cloud ☁ fait parti de votre quotidien   vous maîtrisez la stack python data science et le sql  vous avez de lexpérience en data engineering en statistique en machine learning et en data visualisation    vous avez déjà été amenée à participer à la création et au maintien dune pipeline data ️      déroulement des entretiens   ️⃣ premier échange téléphonique avec notre camille notre talent acquisition manager ️⃣ entretien avec jeanmarc notre team lead data et jordan notre data scientist ️⃣ dernier entretien avec matthieu notre head of product   et voilà bienvenue chez nous      ce que nous offrons à nos collaborateurs     vous arrivez au bon moment pour prendre une place stratégique dans une organisation en croissance  vous rejoignez une équipe data bienveillante où lentraide tient une place importante  vous bénéficiez dune grande autonomie et dun environnement où vos prises dinitiatives sont encouragées  et en bonus    jusquà  jours de télétravail possibles par semaine  forfait mobilité durable abonnement transport pris en charge à   € pour lutilisation de mobilités douces  carte swile € par journée travaillée pris en charge à   des locaux flambant neufs à nantes proches de la gare   un espace déjeuner et un espace repos où le café le thé et les gourmandises sont à volonté  une mutuelle ', 'descriptif du postenous recherchons une data scientist qui sera rattachée à léquipe tech ilelle travaillera en étroite collaboration avec les équipes produits et ia pour favoriser la mise en œuvre de nos solutions techniques et ladoption de notre plateforme par nos clientsles missions  aider au développement et amélioration des algorithmes ia de yzr contribuer à loptimisation de nos solutions nlp participer aux déploiement de nos modèles ia sur le cloud awsprofil recherché passion envers la data science et engineering compétences en python déjà utilisé et paramétré des modèles de ml et dl autonome et créatifdéroulement des entretiens optionnel premier entretien avec lela chargée de recrutement test technique  à  minutes entretien technique', 'rejoins la team data créée par nicolas greffard docteur en intelligence artificielle déjà composée de  data scientists et data engineer talentueux nous recherchons de nouvelles pépites pour rejoindre notre équipe de choc et répondre aux multiples problématiques data science de nos clients nantais mais également contribuer à nos projets de rd et travailler sur des conférences incroyables devfest salon de la datata future mission si tu lacceptes nous te proposons dintervenir au sein de nos grandes dsi clientes sur des sujets de collecte dalimentation et de transformation de données autour de lintelligence artificielletoutes les missions ne sont pas identiques mais voici des exemples de choses sur lesquelles nos data scientists sont intervenus  échange avec les architectes les po et ppo les développeurs et la gouvernance de données  deep learning rnn lstm cnn dqn et machine learning  analyse de données  statistiques descriptives et exploratoires data mining  traitement dimages pattern matching extraction de descripteurs tfidf et classification etc et traitement de texte traitement du langage  textmining wordvec bow bert etc  restitutiondes résultats  dataviz indicateurs dashboards tableaux de bord optimisation dapplication streamlit  mlops  pour pour amener lia jusquà la prod  amélioration de modèles  validation croisée sélection de descripteurs métriques derreurs  assurer la veille technologique sur les algorithmes et outils de data science  langages  principalement du python souvent du sql et parfois du r ou même du sas  framework  ceux qui reviennent sans arrêt  tensorflow pytorch huggingface sklearn lime streamlit écosystème hadoop  intégration continue   en fonction des contextes applicatifs  docker dockercompose docker swarm github actions jenkins kubernetes concoursepourquoi choisir valeuriad  en plus dêtre aujourdhui un acteur nantais reconnu de lexpertise it nous nous inscrivons depuis notre création dans une démarche dentreprise opale et holacratique où lensemble de nos prises de décisions et projets sont réalisés par et avec lensemble de nos  coéquipiersrejoindre valeuriad cest pouvoir sinvestir dans la coconstruction de lentreprise  par un rôle avec une fiche de poste et un temps dédié gestionnaire des cis porteur des partenariats écoles organisateur dévénements po des projets internes gestion de lacadémie valeuriad  par les projets stratégiques  jours mis à disposition pour les coéquipiers chaque année pour créer et faire grandir des projets structurants création de nouveaux avantages à lancienneté création dindicateurs mensuels pour être toujours plus transparents mécénat de compétences pour des associations caritatives par les projets cagnottes € par coéquipiers et par an pour réaliser des projets collaboratifs qui te tiennent à cœur avec dautres valeurieux découverte du cécifoot challenge écologique challenges sportifs pour des dons à des associations humanitaires borne photo par les ateliers collaboratifs chaque mois des brainstorming et ateliers de travail sont proposés par les différents porteurs de projets et sont ouverts à tous les volontairesmais avanttout nous sommes une équipe soudée des collègues qui apprécient passer du temps ensemble lors de nos soirées hebdomadaires et se créer des souvenirs inoubliables cest pour ça que chez valeuriad le plus important pour nous reste le savoirêtre  des passionnés du dynamisme des sourires de lécoute et le sens de la fête ', 'au sein de léquipe it en charge de la certification des métriques de risque les développeurs contribuent à la transformation digitale de la banque dinvestissementen sappuyant sur une plateforme python  big data existante lobjectif est de proposer des solutions innovantes aux analystes pour notamment améliorer la qualité de la certification et leur faire gagner du tempsen collaboration avec votre maître de stage qui assurera votre formation lela stagiaire participera à ces outils nouvelle génération qui allient un savoirfaire à la fois it et finance de marchéconcrètement vous serez amenée à   découvrir le métier dun data scientist en contribuant directement sur ces sujets ouet sur du tooling transversal que cela soit de lexploration ou de lindustrialisation  acquérir des connaissances en python big data et finance de marché  interagir au sein dune équipe internationale et multicompétencesnous adapterons le contenu du stage en fonction de vous et de ce qui a le plus de valeur ajoutée pour la banquedes pistes à explorer pourront être proposées au stagiaire mais celuicelleci pourra aussi en proposer et les expérimenter vous préparez un bac  en ecole de commerce université ou en ecole dingénieur avec une spécialité en informatique  vous avez le réflexe de demander « pourquoi  » « pour qui  » « quand  » et « combien   vous avez des connaissances en python machine learning  youre fluent in english  vous êtes notre candidate idéale ', 'le contextedans le cadre de son programme applied ai sur lintelligence artificielle le département ri travaille sur lévaluation de limpact environnemental de lintelligence artificielle ce sujet représente un réel enjeu sachant que la seule phase dapprentissage dun algorithme de deep learning peut émettre des centaines de tonnes de co égalant ainsi limpact environnemental de plusieurs voitures sur lensemble de leur durée de vie\\xa0dans le cadre de votre stage vous serez amenée à travailler sur la conception destimateurs mathématiques pour la consommation énergétique de modèles de deep learning une fois que plusieurs estimateurs auront été identifiés ces derniers seront testés sur différents cas dutilisation et différents types de modèles afin den comprendre la précision et les limites finalement lestimateur ou les estimateurs retenus pourront être étendu afin de prendre en compte dautres impacts environnementaux que la seule empreinte carbonevotre tâcheen tant que stagiaire data scientist hf votre tâche en sont liées à\\xa0    etat de lart des approches analysant la consommation énergétique des modèles de deep learning    définition dun cadre détude pour linfluence des différents paramètres sur la consommation énergétique    identification dun ensemble destimateur mathématique de la consommation énergétique dun modèle de deep learning donné    analyse critique synthèse des résultats et rédaction scientifique    extension de ces estimateurs à dautres impacts environnementaux', 'danone france ne cherche pas à être la meilleure entreprise au monde mais meilleure pour le monde  cest pour cela que nos  marques en france sont certifiées b corp tm b corp est la boussole de notre stratégie rse  cette certification permet de nous remettre en question afin de progresser continuellement et mesurer notre performance sociale et environnementalele département medical  nutritional science recrute une data scientist senior en cdi dans léquipe clinical research  health data le poste est basé à gifsuryvette  sur le plateau de saclay au sein du danone global research  innovation center centre daniel carasso qui est au cœur de la recherche  innovation de danone il est constitué de laboratoires et dateliers pilotes à la pointe de la science et de la technologie avec des collaborateurs œuvrant collectivement pour innover sur les produits laitiers et végétaux les eaux et la nutrition spécialisée de demainla direction r i medical  nutritional science a pour vocation de créer de la valeur et des opportunités de croissance pour danone autour de la nutrition etou de la santérattachée au chef déquipe data science  data engineering lela data scientist senior a pour mission de réaliser des analyses de bout en bout pour différents départements de la r i de danone pour les équipes de gifsuryvette de france des paysbas de singapour du recueil du besoin métier à lanalyse et la mise en production des produits data science développés selon les bonnes pratiques data science établiestravailler en collaboration avec les autres experts data eg data architect data engineer expert biréaliser une veille régulière des techniques data science identifier les opportunités pour les autres métiers de la r i  les présenter concevoir des roadmaps pour les projets datacommuniquer à nos partenaires de la r i des résultats et concepts data avec pédagogiecontribuer à lharmonisation et la standardisation des pratiques de data science dans léquipe et faciliter lapplication de ces bonnes pratiques par des profils data science plus juniorsla garantie dun package de rémunération pertinent compétitif et évolutif grâce à un benchmark externe et une équité interne il se compose entre autres dun salaire fixe dun variable annuel dune prime dintéressement etou participation et dune action danoneune flexibilité de travail et lieux de travail avec télétravail hebdomadaire de  joursle développement des compétences de chacun avec la danone academy france et un cycle de conversation managérialla possibilité dutiliser  jours par an de bénévolat via notre plateforme vendredides avantages pour la parentalité et les aidants avec la possibilité de convertir une partie de sa rémunération en temps notamment  jours de plus de congé maternité  paternitédautres avantages tels que la mutuelle la retraite supplémentaire le cse  du pass navigo rembourséles indispensables formation msc ou équivalent voire phd idéalement en data science mathématiques appliquées ou statistiquesexcellente maîtrise de python pandas github shell voire rtrès bonne pratique des outils de data science python scikitlearn pytorch tensorflow keras passionné par la data science et ses applicationsfrançais et anglais courantsbon relationnel bonne communication curieux aptitudes en résolution de problèmesles  expérience ou connaissances en biologie science de la vie biotechnologieexpérience professionnelle dans lindustrie dans des rôles similaires au sein dun data lab par exempleparticipation à des compétitions kaggle hackathon nous sommes fiers de promouvoir la diversité et légalité des chances au sein de nos équipes nous sommes convaincus que nos différences font la différence et quun environnement de travail inclusif stimulera notre croissance en tant quentreprise en tant quéquipes et en tant quindividus nous considérerons donc toutes les candidatures en favorisant une culture de travail inclusive où chaque individu peut se sentir à sa placeaussi nous avons fait le choix de supprimer lécriture inclusive de nos offres demploi car sa complexité pénalise les personnes affectées dun handicap cognitif notamment la dyslexie la dysphasie ou lapraxietoutes les candidatures seront considérées sans tenir compte de lorigine du parcours de la religion du sexe de lorientation sexuelle de lidentité de genre du handicapnos quatre valeurs fondamentales hope  humanisme ouverture proximité et enthousiasme nous servent de b', 'dans le cadre de ses activités le datalab de cnp assurances recrute un data scientist junior le datalab est une équipe composée dune dizaine de data scientist centralisant lexpertise en ia au sein de cnp assurances et au service de toutes les directions métiers de nos partenaires et de nos clients nous travaillons sur des domaines variés de la data science parmi lesquels  nlpnlu  classification de mails analyse de sentiments ner computer vision  classification de documents ocr reconnaissance faciale données structurées  ciblage marketing séries temporelles rapprochement flou entre bases speechtotext au sein du datalab vous aurez pour missions  de développer des modèles dintelligence artificielle et de les intégrer dans une solution de boutenbout dassurer une veille technologique pour utiliser les outils les plus performants sur le marché et être au courant des dernières tendances et avancées dans le domaine de lia de créer des documentations pour votre projet de savoir communiquer vos résultats au client de façon claire et synthétique de répondre à des demandes ponctuelles des clients de gérer le cycle de vie de votre modèle suivi de production amélioration continue détection du drift etcprofil savoirfaire  connaissances avancées en python connaissances avancées sur la théorie du deep learning savoir produire du code prodready dans une logique dindustrialisation maitrise des principaux framework de développement en python tensorflow pytorch savoir être  autonomie capacité à travailler en équipe curiosité intellectuelleinformations fonction data scientist  classe ccna ', 'nous recrutons une ingénieur data scientist expérimenté pour rejoindre notre business unit industrie au sein de la business line data  process intelligence elle accompagne nos clients dans leurs problématiques associées à la transformation digitale nos offres se déclinent autour de la data intelligence  de la maintenance prédictive de la digitalisation des processus industriels et du si métiersvotre mission  analyser de gros volumes de données de type série temporelle développer et déployer des modèles prédictifs et assurer la communication avec le client  contribuer aux activités de prospection et davantvente de loffre maintenance prédictive compréhension du besoin proposition de solutions techniques réalisation de missions daudit  lenvironnement technique  java python r spark  time series qui êtesvous de formation bac vous avez une expérience minimum de  ans en tant que data scientist la maîtrise des techniques de data mining  machine learning et des architectures bigdata est indispensable à lexercice de votre fonction un niveau danglais courant est requisvous êtes autonome et vous savez faire preuve dinitiative  vous êtes doté dun bon relationnel et avez le sens du service  alors vous êtes la pépite que nous recherchons a compétences égales ce poste est ouvert aux personnes en situation de handicapqui sommesnous la business unit industrie contribue aux développements de programmes dans les domaines de la simulation la transformation digitale et le développement de systèmes critiques elle est un acteur référent sur lintelligence de la donnée data engineering  data science la digitalisation des processus plm la simulation numérique le développement de logiciels embarqués  certifiés ainsi que la sécurisation des systèmes cybersécuritépourquoi choisir cs group pour notre filière expert qui valorise vos compétences techniques notre engagement dans linnovation avec un budget rd de  millions deurosan nos engagements sociétaux et environnementaux  index dégalité professionnelle à  partenaire de lassociation elles bougent membre de la planète tech care etcet bien sûr  la possibilité de télétravailler un programme de cooptation la complémentaire santé les rtt le ce', 'recherche data scientist hfdans le cadre du renforcement de nos équipes lyonnaises nous sommes à la recherche dun profil data sciencesont attendues les compétences suivantes  capacité à intégrer une structure proposant différents modèles d accompagnement  structuration de la donnée modélisation et visualisation connaissance des modèles ml supervisés et nonsupervisés maitrise de python ou r sql et nosql maitrise de la cross validation connaissance de la plateforme aws bac minimum en datascience expérience professionnelle significative en data science maîtrise indispensable des technologies de mldl niveau professionnel danglaisfondé en  efor a su en  ans se positionner comme lacteur européen de référence du conseil spécialisé en life sciencesavec plus de  collaborateurs répartis au sein de  agences en france en belgique en suisse et aux usa nous mettons lensemble de nos expertises et méthodes au service de nos clients a', 'recherche data scientist hfvos missions au sein du service data gouvernance et exploitation composé de  personnes vous rejoignez le lab ia rattaché au responsable du lab ia et de léquipe bivos missions principales sont les suivantes  concevoir développer et mettre en œuvre des solutions data science robustes et évolutives collecter nettoyer et analyser des données à grande échelle développer et optimiser des modèles de machine learning et dapprentissage profond interpréter et présenter les résultats de manière claire et efficace à un public non technique documenter vos processus et résultats pour faciliter la collaboration et la reproductibilitévotre profil vous êtes  titulaire dun bac minimum en data science statistiques informatique ou dans un domaine connexe avec une expérience dau moins  ans en tant que data scientist ou dans un rôle similaire dans un esn un cabinet de conseil data ou un service data dune entreprise exp', 'nous recherchons une data scientist hf ayant déjà une expérience réussie dans lindustrie pour rejoindre notre équipe performance opérationnellevotre mission\\xa0dans le cadre de notre stratégie industrie  vous ferez preuve dinnovation pour optimiser nos processus industriels vous développerez des solutions en\\xa0modélisation mathématique recherche opérationnelle et aide à la décision computer vision machine learning analyse de séries temporelles statistique data mining maintenance prédictive etcvos responsabilitéstravailler en étroite collaboration avec les équipes opérationnelles pour comprendre les besoins métier et identifier les opportunités doptimisation grâce à lintelligence artificielleanalyser les données concevoir des solutions développer vos modèles pour résoudre des problèmes opérationnelstravailler avec les équipes du système dinformation pour déployer votre solution sur la plateforme ia du site industriel', 'lambition de dassault systèmes est de jouer un rôle moteur dans linnovation durable grâce à la plateforme dexperiencecette plateforme est un environnement collaboratif permettant aux entreprises et aux particuliers dinnover en créant des produits et services à laide dexpériences virtuelles elle offre une vue en temps réel de lactivité et de lécosystème dentreprise en connectant les personnes les idées et les donnéeslanalyse et le traitement intelligent des données est une évolution technologique représentant un enjeu majeur pour nos solutions dans ce contexte nous sommes à la recherche dunune data scientist ayant plus de  années dexpérience pour concevoir des solutions dintelligence artificielle innovantes permettant denrichir nos solutions de gestion de portefeuille de produits configurables ces solutions permettront par exemple de générer des propositions doffres commerciales accompagnées de leurs expériences marketingposte en cdi basé à vélizyvillacoublay  vos missions vous intégrerez une équipe dynamique et internationale responsable du portefeuille de solutions de la marque enovia vous aurez lopportunité de collaborer avec nos experts métiers afin didentifier définir et prototyper des cas dutilisation de la data tout en garantissant leur mise en œuvre réussie grâce à une étroite collaboration avec nos équipes de design et de développementpour cela vous aurez la responsabilité de  contribuer à la création et à la définition de solutions dintelligence artificielle innovante en mettant en lumière sa valeur et son avantage concurrentiel collaborer étroitement avec les experts métiers pour déterminer les objectifs des solutions ainsi que les données nécessaires à sa réalisation concevoir et développer des preuves de concept convaincantes afin dillustrer la valeur et la faisabilité de nouvelles solutions superviser lintégralité du cycle de vie des projets de la phase de planification jusquà la mise en production articuler la valeur des solutions à travers de démonstrations impactantes rester à la pointe de la technologie en effectuant une veille constante pour suivre les dernières avancées en data sciencevos qualifications vous êtes titulaire dun diplôme de niveau bac école dingénieur ou parcours universitairevous justifiez dune expérience professionnelle de  ans minimum en tant que data scientistvous maitrisez la programmation en python pour la préparation et le traitement de donnéesvous avez une solide compréhension des principes fondamentaux de la collecte du nettoyage et de la préparation des donnéesvous avez une forte expertise sur les techniques dintelligence artificielle et de machine learning couvrant la conception de modèles lentraînement lévaluation et le déploiementvous êtes familierère avec les outils business intelligence tels que powerbi tableau ou équivalentsvous avez des compétences en data vizualisation et une aisance en communication permettant de présenter de manière concise et claire les résultats obtenus nous rejoindre cest aussiintégrer une entreprise scientifique au cœur de linnovation technologique portée par une forte croissance depuis plus de  ansprincipaux avantages et bénéfices environnement multiculturelcadre de travail convivial axé sur le bienêtre et la santé salles de sport  de musique conciergerieengagement en faveur de la diversité et de linclusionpolitique dynamique de développement de carrière  plan de formation mobilités internes etc', 'la cellule transverse data  analytics da optimise le pilotage de la performance en développant des solutions danalyse et de visualisation pour les décideurs et analystes métiers dans un contexte de forte croissance léquipe da recrute un data scientist hf pour résoudre des problèmes complexes et développer des solutions structurantes pour les diverses directions de la compagnie aérienne commerciale finance opérations maintenancea ce titre vos principales missions seront comprendre les enjeux métiers échanger avec les équipes pour recueillir et clarifier les cas dusage prendre en charge des projets de développement data science de bout en bout de la définition du use case à la livraison finale mettre en pratique vos connaissances data pour collecter traiter exploiter et valoriser les données  programmation python statistiques machine learning visualisation de données concevoir et mettre en œuvre des architectures dans le cloud azure entraîner et déployer des modèles de machine learning dans une démarche de mise en production participer et être garant des approches devops au sein de léquipe  versioning de code pipeline cicd tests etc documenter la construction des études rapports et analyses effectués présenter ses travaux et contribuer à la diffusion dune culture datadriven au sein des différentes directionprofil de formation bac ingénieurs ou universitaire à dominante data science machine learning recherche opérationnelle mathématiques vous justifiez de minimum  ans dexpérience en tant que data scientist ou poste similaire vous disposez de très bonnes connaissances des techniques de machine learning de statistiques avancées et de développement logiciel python orienté objet sql azure ml vous avez une expérience significative dans lutilisation du cloud azure être certifié microsoft azure est une vrai plus vous avez une expérience de développement dans un environnement devops azure devops repos cicdvous êtes à laise avec les outils de datavisualisation notamment power bi on vous reconnaît une rigueur pour le scripting et la maintenance de code vous êtes polyvalente structurée organisée et êtes garante des projets et des solutions développéesvous savez parfaitement vous exprimer en anglais des échanges avec transavia paysbas sont à prévoir autonome vous savez travailler en équipe et avez lesprit dinitiative vous possédez une forte appétence pour lunivers du transport aérien', 'descriptif du postedans le cadre du renforcement de nos équipes lyonnaises nous sommes à la recherche dun profil data science\\xa0sont attendues les compétences suivantes \\xa0 capacité à intégrer une structure proposant différents modèles d accompagnement  structuration de la donnée modélisation et visualisation connaissance des modèles ml supervisés et nonsupervisés maitrise de python ou r sql et nosql maitrise de la cross validation\\xa0 connaissance de la plateforme awsprofil recherché bac minimum en datascience expérience professionnelle significative en data science maîtrise indispensable des technologies de mldl niveau professionnel danglais\\xa0', 'descriptif du postevos missions au sein du service data gouvernance et exploitation composé de  personnes vous rejoignez le lab ia rattaché au responsable du lab ia et de léquipe bivos missions principales sont les suivantes  concevoir développer et mettre en œuvre des solutions data science robustes et évolutives collecter nettoyer et analyser des données à grande échelle développer et optimiser des modèles de machine learning et dapprentissage profond interpréter et présenter les résultats de manière claire et efficace à un public non technique documenter vos processus et résultats pour faciliter la collaboration et la reproductibilitéprofil recherchévotre profil vous êtes  titulaire dun bac minimum en data science statistiques informatique ou dans un domaine connexe avec une expérience dau moins  ans en tant que data scientist ou dans un rôle similaire dans un esn un cabinet de conseil data ou un service data dune entreprise expérimenté sur lenvironnement technique suivant   programmation python obligatoire et pyspark facultatif bibliothèques pandas numpy scipy matplotlib statsmodels outils data science jupyter notebook azure notebooks google colab frameworks pytorch tensorflow scikitlearn xgboost lightgbm onnx statistiques et analyses de données manipulation des bases de données et sql cloud computing aws azure gcp  outils analytics  analytique et orienté résolution de problèmes vous avez également une excellente capacité à communiquer et à documenter vos résultats vous travaillez à la fois de manière autonome et en équipe grâce à de solides compétences interpersonnelles vous recherchez un environnement de travail avec une éthique du travail solide à laquelle vous souhaitez participer activementce que nous proposons poste à pourvoir en cdi dès que possibleposte basé à chaponnay   notre site est peu desservi par les transports en communstatut cadrerémunération selon profil et expériencerestaurant dentreprise salle de sportbons dachat dune valeur de €mois à valoir dans nos enseignesmutuelle familiale et possibilité de places en crèche selon certaines conditionsorganisme de formation interne qui accompagne le développement des collaborateurspossibilité de télétravailrejoignez une entreprise avec de belles perspectives dévolution', 'posson packaging  salariés  m€ de ca en  est une entreprise familiale implantée en sarthe depuis  et à louailles depuis  dans une usine ultramoderne située sur léchangeur autoroutier de sablé sur sarthe  la flèchenous sommes engagés dans la responsabilité sociétale des entreprises rse depuis de nombreuses années notre entreprise est certifiée iso  pour son organisation iso  pour sa politique environnementale et iso  pour sa politique de prévention des risques santé et sécurité nous militons au sein de la frenchfab pour une industrie   made in france et respectueuse de son environnement en transformant   tonnes de carton en emballages recyclables  en  posson packaging modifie ses statuts et devient société à missionnous recherchons un e  data scientist pour venir compléter notre équipe vos principales missions seront \\tlidentification et la détection des besoins\\tlanalyse des données  collecter analyser les données industrielles et détecter les pistes daméliorations\\tla mise en œuvre et loptimisation des processus de contrôle de gestion et amélioration de la rentabilité prix de revient prévuréalisé\\tle développement de tableaux de bord et de rapports visuels pour présenter les résultats des analyses de données \\tla collaboration avec les équipes opérationnelles pour identifier les besoins en données et les solutions doptimisation\\tla gestion de projet  accompagner le projet mes manufacturing executing system en collaboration avec la direction technique et le service informatiqueenvironnement agréable de travailpossibilité de télétravail  journée par semainehoraires hsemaine contrat  cdiconvention collective de lindustrie du cartonnageprofil vous êtes titulaire dun master en data science statistiques mathématiques appliquées ou dans un domaine connexevous avez une compréhension approfondie des concepts de contrôle de gestion en industrievous justifiez dune expérience sur un poste de data scientist ou contrôleur de gestionconditions de rémunération et avantages rémunération  entre  € et  € brut annuelautres avantages \\tmise à disposition dun véhicule de fonction moyennant une contribution à partir dun an dancienneté\\taccord de participation et dintéressement\\tcse', 'descriptif du postepour le compte de clients bancaires et assurantiels vous  assurez le monitoring de la performance de votre solution sur lensemble du cycle de production en lien étroit avec les sponsors métiers et utilisateurs finaux intervenez sur la conception de solutions data science  ia du prototypage à lindustrialisation au sein déquipes pluridisciplinaires intervenez sur des thématiques faisant appel à du machine learning et scoring en lien avec la connaissance client lefficacité opérationnelle loptimisation de processus la lutte antifraude dans les directions data orientées risque et marketing évoluez dans un environnement technologique data science etou big data et vous serez ainsi amené à travailler en python r spark sas ou des solutions reconnues telles que dataikuen interne vous  participez aux réponses dappels doffres sur votre spécialité contribuez à la production de contenus dexpertise podcasts focus articles interviews et tables rondes pour le domaine dexcellence data jouez un rôle de référent pour les consultants juniors bénéficiez du programme de formations certifiantes spécialisées en data data science machine learning engineer cdo ainsi quà un large choix de formations en ligne sur lensemble des expertises portées par le groupeprofil recherchédiplômé dau moins un bac  école dingénieur de commerce ou universitaire vous justifiez de minimum  ans dexpérience significative en data science les principaux attendus sont   maîtrise des outils nécessaires aux missions proposées tels que python r sparksas et connaissance des solutions data science dataiku et les infrastructures cloud maîtrise des problématiques du risque de crédit sur la partie validation de modèle rwa lgd norme frs connaissance des métiers du secteur bancaire etou assurantiels partage de la culture de lengagement lesprit déquipe et lensemble des valeurs de square management maîtrise dun anglais courant', 'descriptif du posteau sein de la nouvelle direction data chargée de lexploitation et de la valorisation des données à travers le groupe nous recherchons un\\xa0data scientist confirmé hf pour intégrer une équipe dynamique en forte croissance composée de data scientists data engineers product owners devops et full stacks\\xa0 au quotidien vous serez amené à  désigner et créer des algorithmes construire des modèles prototyper les solutions imaginées sur des données hétérogènes et mondiales travailler en équipe avec les data scientists de la direction data identifier de nouvelles sources de données pertinentes proposer des\\xa0 use cases \\xa0innovants interagir étroitement avec les data engineers de la direction data et de la dsi pour lintégration mise en production des outils et algorithmes développer vos prototypes directement sur notre plateforme big data et aurez la responsabilité technique des projetsvous aurez la chance de participer à la mise en place de cette direction et interviendrez sur lensemble de la chaine data à nos côtésprofil recherchéamoureux de la data passionné par ses utilisations avec un esprit innovant et autonome vous cherchez à relever un défi et êtes motivé par les challenges en perspective\\xa0de formation bac  minimum de type école dingénieur vous avez au moins  années dexpérience préalable dans le traitement de données en industrie avec le développement dalgorithmes sur une infrastructure big data\\xa0vous avez idéalement déjà été amené à gérer des équipes en mode projet et êtes autonome sur larchitecture du projet le chiffrage des tâches et le respect des délais\\xa0vous maîtrisez un environnement cloud aws azure etc\\xa0vous avez une connaissance des modèles de machine learning aussi bien théorique que pratique et avez le désir dapprofondir ces compétences\\xa0 compétences requises  connaissance pointue en machine learning artificial intelligence econométrie avec des expériences dutilisations sur données réelles capacité reconnue à travailler avec les langages tels que java python scala etc et sur les infrastructures big data compréhension fine des enjeux business habilité à communiquer sur les algorithmes et les applications développées à des non experts anglais  français force de proposition et esprit innovant expérience de travail en équipe\\xa0la maîtrise de langlais est indispensable pour ce poste à dimension internationale', 'descriptif du postevenez extraire analyser et développer des algorithmes complexes dont le machine learning\\xa0votre objectif  optimiser le performances des métiers sur le domaine confiéet si être « data scientist » chez april vous permettait  de choisir un métier dont vous pourrez être fier  «accompagner et protéger à chaque moment qui compte simplement» telle est la mission et la raison dêtre partagée par lensemble de nos collaborateurs de développer votre expertise dans un environnement en pleine transformation au carrefour de linnovation et de lexpérience client  notre ambition à horizon  être un acteur digital omnicanal et agile champion de lexpérience client de vous engager au sein dune entreprise engagée  nous rejoindre cest faire partie dun groupe responsable qui agit en entreprise citoyenne en étant mobilisé autour de  axes santé aidants éducation et environnement avec un impact sociétal positif et réelnous nous engageons à promouvoir des emplois respectant la diversité et la différence ouverts à chacunvos futures missions  gestion des données et support à la décision participer aux ateliers dexpression des besoins internes métiers comprendre leurs problématiques et les traduire de manière analytique collecter et analyser les données internes et externes par lutilisation de méthodes statistiques pour connaitre et exploiter en continu les évolutions des domaines dapplication sélectionner et mettre en œuvre des algorithmes dapprentissage automatique pertinents sur les cas dusage machine learning deep learning etc communiquer les résultat et les solutions avec les équipes métiers et instances de direction en veillant à vulgariser les concepts complexes veille et développement de lactivité maintenir faire évoluer et documenter les modèles existants en collaboration avec les utilisateurs promouvoir lindustrialisation des modèles auprès des utilisateurs des domaines dapplication après la réalisation de poc effectuer une veille sur les nouvelles technologies et solutions digitales de data science et expérimenter de nouvelles méthodes de modélisation et data sciencecette opportunité est à pourvoir dans le cadre dun remplacementdirectement rattachée à jean marc responsable de léquipe data vous rejoindrez notre équipe lyonnaisedès votre arrivée vous bénéficierez dun parcours dintégration pour favoriser votre prise de posteprofil recherchévous disposez dun bac  type ecole dingénieur avec spécialisation en statistique ou informatique décisionnellemaster en data sciencestatistiqueseconométrie avec spécialisation informatique big data etc et dune première expérience sur un poste similairevous pourrez également mettre à profit  vos compétences techniques  modélisation techniques statistiques gestion de base de données data visualisation sécurité des données bases de données sqlnosql langages de programmation java sql python r sas etc méthodologie projet data science méthodes et algorithmes de machine learning et de deep learning pratique dune langue étrangère vos compétences transverses  capacité danalyse capacité de synthèse rigueur orientation client adaptabilité capacité dorganisation et de planification vision globale et appréhension de la complexité communication orale et écrite travail en équipe et en transverse écoute bienveillante et soutenantecette opportunité est faite pour vous  nattendez plus pour postuler en nous adressant votre cv accompagné de quelques lignes sur votre projet professionnel et ce qui pourrait vous épanouir aujourdhui ce sera la première étape de notre processus de recrutementsi vous nêtes pas sûre que cette offre soit la bonne dautres postes sont à pourvoir alors nhésitez pas à consulter notre site carrière etou notre page linkedin ', 'au sein du laboratoire vekia tu participes au développement des algorithmes numériques au cœur des motorisations vekia sappuyant sur le machine learning la recherche opérationnelle et lapprentissage par renforcementtu participeras à lensemble du processus de conception et développement  de lapport de nouvelles idées et de la veille scientifique à limplémentation industrielle en passant par le prototypage et les simulations numériquesen synthèse les principales missions du poste sont \\tparticipation à la vie et à lanimation de léquipe séminaires reading groups brainstormings\\tdéveloppement de pipelines de machine learning liées aux problématiques clients\\tprototypage de nouveaux algorithmes et simulations de performances\\timplémentation industrielle des algorithmes au sein des toolkits vekia\\tveille scientifiquequelles sont les principales technologies utilisées au sein du lab \\tpython et son écosystème numpyscipypandastensorflow\\tscala\\tspark\\tsql\\tgitton profil \\ttu es actuellement en master ii dune formation ingénieur avec une orientation forte sur les sujets machine learning et data sciences\\ttu es force de proposition\\ttu as bon niveau en anglais \\tidéalement tu as une appétence et  ou expérience dans le secteur de la supplychainbref si en plus tu as envie de travailler chez un éditeur logiciel que tu aimes laventure startup lutilisation pointue de la datascience et du machine learning et enfin que le monde de la supplychain tintéresse tu es fait pour travailler avec nous les  vekia  \\tun parcours dintégration pour découvrir vekia\\tenvironnement convivial\\thappy team évènements internes conviviaux et interactifs\\ttélétravail  mode hybridenous rejoindre cest aussi sépanouir en étant acteur de notre développement et en partageant des valeurs communes \\tteam player tu aimes le travail en équipe et fais preuve de solidarité et douverture aux autres\\tambitieux pour tes projets et ton entreprise tu as un esprit aventurier et aimes relever des défis en faisant preuve dengagement et de ténacité dans tes actes\\tfun  serious tu aimes tinvestir tout en privilégiant la convivialité et le plaisir\\thumble et honnête tu connais tes qualités et tes défauts et recherches continuellement à progresserle type de contrat apprentissage ou de professionnalisation sera déterminé selon lecole partenaire et le salaire brut sera fixé par des grilles conventionnelles selon la situation du candidat', 'description du poste le saviezvous  nous rejoindre cest rejoindre lun des leaders mondiaux de la distribution qui met laccent au quotidien sur la diversité la rse et le digital pour satisfaire nos clients et nos collaborateurs en tant que partenaire premium des jeux olympiques et paralympiques de paris  nous partageons les valeurs du sport en permettant à nos équipes de se dépasser et encourageons une alimentation saine au juste prix pour tousvous cherchez à travailler dans une entreprise dynamique où votre travail rime avec impact social et environnemental  bienvenue chez nous la direction analytics factory europe basée à massy  une data scientist senior en recherche opérationnelle hflutilisation massive de données et le développement dapproches analytiques rationnelles constituent un axe majeur du plan stratégique du groupe carrefour à horizon  les data analysts scientists engineers viz  gouv de lanalytics factory de carrefour france sont les piliers de cette transformation analytique au service de lensemble des équipes métier  marketing marchandises formats ecommerce supply chain finance etcnous utilisons une diversité dapproches data science  telles que machine learning et recherche opérationnelle  pour résoudre des problématiques commerciales et opérationnelles comme les ruptures de stock en magasin la prévision des ventes loptimisation de lassortiment des produits loptimisation des prix la personnalisation de lexpérience sur le site ecommercepricing analytics est un projet central de la transformation analytique engagée par carrefouril vise à fournir à la direction pricing des outils automatisés pour lamélioration de la pertinence et de la cohérence des prix de ses produits il sarticule autour des trois briques technologiques suivantes  détection de liens entre produits qui se traduisent en contraintes tarifaires et permettent dassurer la cohérence des prix en tenant compte de critères tels que le conditionnement ou encore le caractère bio des produits prévision des ventes des produits en fonction du prix en tenant compte notamment de la sensibilité de la demande aux variations du prix mesurée par lélasticité prix optimisation des prix en maximisant un objectif financier en sappuyant sur les prévisions de ventes et en tenant compte des contraintes tarifaires qui permettent dassurer la cohérence des prix entre les produits les contraintes légales économiques et concurrentiellesen tant que data scientist en recherche opérationnelle vous aurez la charge du développement des modules doptimisation du projet pricing analyticsvos missionsau sein du pôle data science vous intégrerez une talentueuse feature team rassemblant différentes compétences vous évoluerez dans un environnement agile et collaboratif animé par un esprit dentraide et damélioration continuevous interviendrez à différentes étapes des projets  discuter avec les équipes opérationnelles et dirigeantes pour identifier leurs besoins et leurs difficultés modéliser les problèmes leurs objectifs et leurs contraintes développer et évaluer des méthodes doptimisation pour leur apporter des solutions adapter le choix des méthodes doptimisation aux contraintes de temps dexécution collaborer avec les data scientists les data engineers et les développeurs deléquipe pour spécifier les évolutions sur lingestion et lexposition des données présenter vos travaux auprès des utilisateurs collecter leurs retours et itérer sur la solution dans une démarche damélioration continue guider et accompagner la montée en compétence des data scientists recherche opérationnelle juniorsvous participerez également aux échanges réguliers de notre communauté dune trentaine de spécialistes data scientists engineers devops  séminaires partage de retours de conférences débats sur les problématiques data science développement logiciel etcen tant que data scientist en recherche opérationnelle vous rapporterez au data science manager au sein de votre équipe vous bénéficierez également de lappui de notre lead data scientist en recherche opérationnellevotre profildiplômée en recherche opérationnelle ou en mathématiques appliquées  de niveau master a minima  ou justifiant dune expérience professionnelle équivalente vous disposez de très solides connaissances en optimisation sous contraintesvous avez déjà utilisé des solveurs doptimisation tels que gurobi cplex pulp et implémenté des métaheuristiques pour résoudre des problèmes en industrievotre formation couplée à votre expérience vous permettent daborder avec méthode et rigueur de nouvelles problématiq', 'être « data scientist fh » chez oney pourquoi cest mieux plus quun posteune mission pour vous  et quelle mission positionner la data science au cœur des projets dentreprise afin de développer le business et de garantir la maîtrise du risque de crédit sont les raisons dêtre de notre direction data  risquesacteur complémentaire et indispensable du département scores  data science nous vous proposons dêtre un créateur de valeur rapide pour lentreprise par lexploitation avancée de données variées dans des modèles très variés de type ml notammentvoici vos principales missions   vous résolvez des problématiques identifiées par la création et la maintenance des outils de scoring risque et marketing  vous vous assurez de leur performance et de leur stabilité dans des cadres de construction réglementaire et de la gouvernance interne définie  vous êtes responsable de la méthode de construction et de proposer des optimisations ou évolutions nécessaires par des éclairages méthodiques et argumentés  vous êtes le garant de la qualité des algorithmes développés par un pilotage régulier proactif et par une maitrise de ceuxci du sourcing  de la qualité des datas utilisées et de lutilisation opérationnelles des algorithmes  vous développez de nouveaux usages de la data et vous contribuez à la mise à disposition ou à la création de nouvelles data pour développer la performance de nos outils  vous accompagnez la communauté des citizen data scientist en cours de lancement et vous adoptez une posture de conseil auprès de non experts  vous participez à la communauté data oney pour démocratiser lanalyse avancée et lia au sein de lentrepriseen somme nous vous proposons dêtre un business partner primordial pour les métiers sachant évoluer dans un contexte projet transverse réglementaire fort et dans une gouvernance interne cadréece que nous plaira le plus chez vous cest vousmême  alors bien évidemment on vous préférera réactif curieux et pédagogue car cest ce qui vous permettra au mieux de réussir votre mission par ailleurs vous êtes doté dun esprit danalyse capable dargumenter et de documenter ses choix de synthèse et de vulgarisation pour savoir vendre vos projets à une audience sans bagage technique dun bon relationnel et dun optimisme fort vous dépassez les contraintes pour chercher les opportunités votre côté ingénieux et votre sens de lintuition vous permettront de composer avec un besoin dagilité et de déploiement rapide doutilsdans votre bagage on aimerait trouver un bac en statsdata science une expertise python spark sql  co et une forte appétence pour les technologies data science mais également sur lusage métier une capacité à communiquer avec les métiers et à comprendre leurs besoins une capacité de remise en cause de lexistant et une forte envie dinnover avec nous une première expérience réussie en tant que data scientist est requise une expérience avec de la gestion de projet etou en management transverse est également attendue', 'votre missionintégrée au sein de léquipe data vous participerez à toutes les phases de nos missions clients  cadrage des besoins data management modélisation choix et tests des algorithmes les plus pertinents implémentation et déploiement des solutions retenuesentourée de nos experts vous monterez rapidement en compétence sur les technologies suivantes  python scikitlearn pandas  mongodb elasticsearch   et participerez au développement de nouveaux produits innovants dans le cadre de notre datalabquelques exemples de missions  stratégie antichurn dun grand média français et mise en œuvre des solutions techniques pour retenir ses clients développement et commercialisation en saas dun système de gestion intelligente de la politique de stationnement pour une centaine de villes en france solution doptimisation du pricing des produits vendus via une plateforme de ventes aux enchères en ligne maximisation du taux douverture de mails pour les clients dune startup spécialiste de lemailing en saas algorithmes de détection de fraude auprès dassureursvotre profilissue dune grande école dingénieurs vous justifiez dune première expérience professionnelle sur des problématiques data stage ou premier emploi passionnée par les nouvelles technologies et friand de code vous êtes familier avec un langage de programmation à vocation analytique python r scala  une expérience en développement logiciel est un plus avoir suivi un mooc ex  udemy spécialisé en big data est également apprécié enfin vous êtes conscient que la modélisation ne représente que  à  maximum du temps passé sur nos projets et ne sera pas au cœur de vos missions a votre arrivée vous bénéficiez dun parcours guidé de formation propre à léquipe data nous finançons entre autres des formations aws via notre polyacademy nous vous donnons également accès à un large panel de formations aussi bien techniques que business en vue de faciliter votre montée en compétences et de créer des ponts entre nos différents métiersla maîtrise de la langue française à lécrit et à loral est indispensable', 'dans le cadre de son développement et du renforcement de son équipe rd  personnes la société souhaite aujourdhui recruter un profil expert en analyse de données de santévos missions seront les suivantes     acquisition prétraitement et augmentation de bases de données médicales conception entraînement et validation de réseaux de neurones participation à des études de cadrage architecture technique et rédaction de spécifications communications scientifiques dans des conférences et congrès internationaux veille technologique participation au montage détudes cliniques développement des relations avec des kol du secteur médical profil recherché nous cherchons un candidat disposant en particulier des compétences suivantes    master ou ingénieur en sciences des données de santé première expérience dans le traitement de données médicales maîtrise de python et du langage r  connaissance des outils dapprentissage automatique keras tensorflow ou pytorch vous avez à cœur de fournir un code de qualité et avez idéalement pu expérimenter le fait de travailler dans un environnement collaboratif gitlab connaissance de la physiologie humaine expérience souhaitée avec la technologie aws amazon web services maitrise de la langue anglaise vous êtes curieux créatif et force de propositions vous intégrerez une structure à taille humaine au tout début dune aventure qui saura vous faire évoluer et travailler sur des projets complexes et diversifiésla confiance lautonomie lengagement lenvie de partager dinnover et de saméliorer sont autant de savoirs être et de valeurs essentielles', 'votre mission consistera à travailler sur les indicateurs métier des clients de loffre flux vision notamment dans les domaines du géomarketing du transport et du tourismevous aurez en tant que data engineer  data scientist pour mission de travailler au sein dune équipe de data analystdata scientistdata engineer sur les sujets suivants  mise en place dalgorithmes de data science pour la création et la qualification de nouveaux indicateurs statistiques préparation et qualification des données livrées aux clients participation à lamélioration de lappareil de production vous participerez également à lélaboration et à lamélioration des livrables clients rapport danalyse tableaux de bord intégration dans les outils de traitement de la donnée  vous travaillez en coordination avec les équipes de développement et les équipes dexploitation   vous êtes titulaire dun bac master ou école dingénieur spécialisé en mathématiques appliquées en statistiques ou dans le domaine du transport du géomarketing ou de laménagement du territoire vous avez une expérience significative dans lutilisation des outils informatiques de datascience tel que pandas kerasscikitlearn sql  vous disposez de compétences dans les solutions de dataviz  des connaissances dans les environnements cloud big data azure aws gcp est un plus dynamique doté dun bon relationnel vous avez le sens de léquipe et vous aimez avoir de lautonomie pour mener une activité de manière longitudinale', 'description de la mission\\xa0la croissance très importante du volume des données transitant sur le réseau mobile est à la fois une contrainte pour le dimensionnement des infrastructures et une opportunité de création de valeur pour orange flux vision est une offre dorange business services proposant un ensemble de services de mesures de fréquentation des territoires et de mobilités des personnes en exploitant une plateforme danalyse des données de signalisation des mobiles sur le réseau orange flux vision offre une large gamme dindicateurs statistiques permettant aux acteurs économiques de mieux comprendre les territoires avec applications dans des domaines clés tels que lobservation touristique les transports laménagement du territoire ou encore le géomarketing en quelques années flux vision est devenu une référence mondiale avec plus de  clients actifs dans  pays les données produites peuvent avoir un impact significatif sur les décisions importantes prises par les acteurs de ces différents domaines dapplicationla diversification des champs dapplications de ces données et lenrichissement des offres marketing impliquent un effort continue de conception de modèles et de développement dalgorithmes de traitement afin daugmenter la valeur analytique et prédictive des données restituées à nos clients dune grande diversité ces modèles associent les connaissances du monde des réseaux mobiles des mathématiques appliquées des sciences de linformation et tirent le meilleur des outils de la data science et du big data   dans le cadre du développement du service flux vision tant en france quà linternational nous cherchons une personne pour renforcer léquipe de développement léquipe flux vision travaille en mode intégré marketing  dev  analystes  ops et est constituée denviron  personnes réparties principalement entre deux sites belfort et rennesau sein de cette équipe votre mission consistera à développer et faire évoluer les composants logiciels de la chaîne de production flux vision vous serez donc amenés à dialoguer avec les datascientists et analystes pour comprendre les modèles et algorithmes à implémenter et les exploitantsdevops pour satisfaire les contraintes opérationnelles système dexploitation ressources des serveurs etcles volumes de données traitées ainsi que les modèles développés nécessitent des implémentations efficaces et optimiséesles principaux langages utilisés sont python et sa stack data science mais aussi c java javascript sqlprofil\\xa0vous êtes titulaire dun bac master ou école dingénieur spécialisé en informatique vous avez une expérience significative en développement en python avec sa stack datascience librairies numpy pandas etcdes connaissances dautres langages c rust powershell  en algorithmique et des hyperscalers aws azure ou gcp seraient un plus apprécié de même que des expériences sur des volumes importants de donnéesdynamique dotée dun bon relationnel vous avez le sens de léquipe et faites preuve dinitiativesvos capacités danalyse et de synthèse des problématiques vous permettent une autonomie suffisante pour piloter une activité et communiquer clairement avec les autres contributeurs de léquipevous souhaitez intégrer une structure qui saura être à lécoute de votre potentiel et qui vous permettra dévoluer alors envoyez sans plus attendre votre candidature\\xa0', 'responsabilités  vous avez toujours rêvé de repousser les limites de la technologie tout en travaillant dans un environnement où linnovation est la norme vous êtes passionnée par le pouvoir des données et souhaitez façonner lavenir grâce à votre expertise en science des données ne cherchez pas plus loin car nous avons lopportunité parfaite pour vousce que vous allez accomplir  \\xa0  résoudre les défis commerciaux et opérationnels avec du machine learning  travailler sur les données de ruptures en magasin la prévision des ventes loptimisation de lassortiment des produits la personnalisation de lexpérienceprofil recherché    de formation supérieure en  minimum  ans dexpérience avec une expertise sur les problématiques de prévision en tant que lead data scientist   capacité à mener des discussions avec différents métiers   guider les profils moins expérimentés sur leur pratiques de data science  connaissances en sql python terraform bitbucket jenkins airflow docker kubernetes gcp bigquery spark dataproc  expérience en développement logiciel agile avec multiples contributeurs git code review cicd bonnes pratiques  expérience du cloud idéalement gcpsi vous êtes prêt à plonger dans un univers où la technologie devient de la magie pure et où votre passion pour le management de projet peut briller rejoignez notre équipe dinnovateurs ensemble nous créerons des solutions qui changeront le monde\\xa0votre aventure commence ici prêt à écrire lhistoire  postulez maintenant pour devenir le héros de notre équipe et transformer votre carrière en une saga technologique passionnante \\xa0', 'on te parle de nous depuis  la matmut est complice de vie de ses sociétaires profondément humaine et fière de son appartenance à la famille mutualiste elle sadresse à tous  particuliers professionnels entreprises associations  en proposant une gamme complète de produits dassurance des biens et des personnes et de services financiers et dépargnela matmut recherche de nouveaux talents pour accompagner sa transformation et son développement avec engagement et ambition tout en conservant son adnconfiante et bienveillante envers ses salariés elle construit avec eux des parcours professionnels motivantsconvaincue que la diversité des potentiels est une richesse elle accompagne forme et fait grandir tous les talentsenvie de nous rejoindre nous recrutons des métiers assurantiels oui mais pas que aujourdhui nous sommes à la recherche dune aidata scientist fhton quotidien rattachée au département innovation intelligence artificielle à la direction data  analytics direction data indépendante entre le métier et lit tu auras pour mission principale daider à mener des projets de recherche appliquée en intelligence artificielle tu travailleras sur des projets dia générative danalyse dimages de textes ou séries temporelles tout en participant à la définition et au développement de sujets novateurs en intelligence artificielletes principales missions penser et implémenter des solutions dia avancées à partir dun besoin métier concretconcevoir développer et mettre en oeuvre des solutions innovantes en intelligence artificielle generative ai textimagetime series analysistravailler sur des projets à long terme dépassant la portée des projets traditionnels de data science avec lobjectif de fournir des solutions novatrices et utiles pour lentreprisemaintenir une expertise constante sur les dernières avancées scientifiques technologiques et méthodologiques dans le domaine de lia être capable de les intégrer de manière pragmatique dans les projetsdévelopper des prototypes et des solutions en utilisant principalement python et un framework de deep learning pytorch tensorflow appliquer les meilleures pratiques de développement y compris cicd git et dockerêtre capable dintervenir sur lensemble du cycle de vie des modèles de la collecte des données à lindustrialisation en passant par le déploiement le suivi des modèles et lutilisation doutils de mlopsavoir une excellente capacité dadaptation aux nouvelles technologies et méthodes émergentes en restant constamment à la pointe des avancées dans le domaine de liavulgariser et évangéliser la data et lia au sein du groupeet si cétait toi tu as au moins  ans dexpérience en iascience des donnéestu suis les avancées du domaine de lia et tintéresses aux architectures des modèles de létat de lart en image et textetu maîtrises python et un framework de deep learning pytorch ou tensorflowtu as une expérience en mlops et dans lutilisation de dockertu as une expérience dans des contextes big data et cloud gcp de préférencela technique ne te fait pas peur et tu sais tadapter à de nouvelles technologies de nouveaux frameworksmais aussi tu es à laise pour vulgariser les sujets iapour finir tu es doté dun esprit créatif et entreprenant tu es reconnu pour tes capacités dadaptation de vulgarisation ta technicité ton esprit déquipe et ta bonne humeur nos atouts rh aides au logement mutuelle à € intéressement et participation remboursement des frais de transport public à hauteur de  et cse aux nombreux avantagessi tu te reconnais partage avec nous ton cv nous avons de découvrir ton profil a compétence égale ce poste est ouvert aux travailleurs en situation de handicap ou assimilés au sens de larticle l du code du travail lues matmut sengage en faveur de la diversité légalité professionnelle lemploi des travailleurs handicapés', 'descriptif du posteun de nos clients est un grand semencier français basé dans la région de clermontferrandil utilise de plus en plus les technologies du numérique pour accélérer le développement de ses nouveaux produitsdans ce contexte afin de renforcer les équipes de la cellule «\\xa0data\\xa0» de notre client pendant minimum  mois nous recherchons un data scientist qui sera chargé de créer  programmer des algorithmes sur les données relatives au développement de nouvelles semencesla mission se déroule au sein dune équipe dexperts qui pourront apporter un renfort à lintervenant tant sur les aspects «\\xa0data science\\xa0» que sur les aspects «\\xa0agronomie\\xa0»toutefois lela candidate doit déjà disposer de compétences avérées dans les  domaines\\xa0 lieu  bien quintégrant une part de télétravail la mission nécessite une présence à clermontferrand pendant lintervention date de démarrage\\xa0 asap rémunération\\xa0 suivant expérience dude la candidateprofil recherché diplôme à bac en data science\\xa0 algorithmie et utilisation de langage dédiés à lanalyse de données variante\\xa0 nous sommes également intéressées par des compétences moins «\\xa0data science\\xa0» mais plus orientées en intelligence artificielle ia etou en analyse de données satellitaires  traitement dimages solide culture en matière de science agronomique idéalement ingénieur agronome ou équivalent une expérience professionnelle à partir de minimum  ans serait appréciée mais la candidature de débutants ayant une formation académique sur les  volets du profil seront également prises en compte avec intérêt ouvert à mission en durée déterminée\\xa0 mobile à clermontferrand pendant quelques mois niveau danglais correct au moins en lectureécriture de documentations', 'descriptif du postele postes en quelques motsvous développerez des algorithmes et produits digitaux danalyse de données de la collecte du besoin à lindustrialisation des solutionsquelques éléments de contextelimagrain it est une entité transverse à toutes les bu du groupe limagrain ses collaborateurs définissent mettent en oeuvre maintiennent et font évoluer lensemble des applications et infrastructures informatiques de limagrain quelles soient dédiées aux métiers à la recherche aux adhérents ou aux clients du groupeau sein de cette entité une partie des collaborateurs est dédiée à la conception et au développement doutils daide à la décision pour les agriculteurs par exemple nous exploitons les données satellitaires ou les images captées par drones afin de réaliser des prévisions de dates de récoltes ou de rendements agricolesdans ce contexte vous aurez pour rôle de concevoir développer et maintenir les nouveaux algorithmes sur lesquels sappuient nos produits digitauxcomment cela se traduit concrètementvous rejoindrez léquipe digital products  data analytics composée dune douzaine de personnes sous la responsabilité dalban responsable science des données vous interviendrez sur  la conceptualisation le développement et le maintien dalgorithmes dapprentissage machine et profond ia etc et produits digitaux danalyse de données fonctionnels et efficaces la réalisation en autonomie et avec rigueur scientifique des poc et prototypes la validation de ces prototypes au regard de leurs performances et de la satisfactions des besoins clients le développement des solutions validées et laccompagnement de leur industrialisation en conformité avec les standards de développement it le suivi et le maintien de ces solutions sous forme de produits qualité performances évolutions  la participation à la proposition de création de valeur par des produits digitaux sur la base de besoins spécifiés ou identifiés la contribution à la vision à la définition de la roadmap et à lévaluation de la valeur des produits et de leurs évolutions pour leurs utilisateurs la veille technologique et méthodologique liée à votre activité ce poste vous amènera à faire office de réfèrente dans le domaine de lanalyse de données au sein du groupe limagrainvous aurez loccasion déchanger régulièrement avec les membres de léquipe products owners développeurs  les autres départements de limagrain it les représentants des métiers en bu les experts scientifiques intervenant dans des domaines connexes biostatistique phénotypage  les organismes de recherche les prestataires informatiques profil recherchéles éléments qui vous permettront de réussir dans votre missionissue dune formation de niveau bac en agronomie avec une spécialisation en analyse de données en statistiques ou en informatique vous êtes à laise avec les langages de programmation python etou r ainsi quavec les standards de développement informatique devops mlops git cdci  et les méthodologies de gestion de projetidéalement vous avez une première expérience dans le domaine de lanalyse de données appliquée à lagronomievotre parcours vous a permis davoir une première approche des méthodes de modélisation statistique prédictive et dapprentissage machineprofond et pratique des librairies associées scikitlearn keras pytorch  voire des outils de modélisation des plantes modèles de culture tels que dssat stics ou apsim par exemplereconnue pour votre pragmatisme et votre curiosité scientifique vous êtes rigoureuxeuse sans être rigide et savez traiter les urgences et les prioritésdotée dun excellent relationnel vous savez adapter votre discours à vos interlocuteurs et savez faire preuve de pédagogie pour vulgariser les sujets les plus complexes votre capacité à convaincre et à vous approprier les points vous permet de porter les sujets et de les faire avancervotre niveau danglais vous permet de travailler dans un contexte international à lécrit comme à loralposte basé au sein de notre centre de recherche de chappes  ce que vous allez trouver chez nousen plus dun poste clé au sein de notre organisation nous vous accompagnerons dans le développement de vos compétences par le biais de formations et dune politique de gestion des ressources humaines proactivevous bénéficierez aussi davantages attractifs  un statut cadre au forfait jour  jan un accompagnement personnalisé  parcours dintégration et de formations mobilité  une rémunération selon profil et expérience accompagnée dune part variable un accord dintéressement un plan depargne de retraite unique une charte de télétravail  jsemain', 'au sein de notre filiale effigemy nous sommes à la recherche dun alternante en data science pour accompagner notre data scientist     vous voulez un apprentissage qui a du sens qui donne accès à des missions concrètes et opérationnelles  lopportunité de travailler sur des projets structurants avec un impact concrêt une expérience professionnelle significative à valoriser sur votre cv ne cherchez plus candidatez toute suite     vos responsabilités seront de     participer à la collecte au nettoyage et à la préparation des données pour lanalyse  vous serez impliquée dans le processus de collecte de données leur nettoyage et leur préparation en vue de lanalyse   contribuer à la conception et à la mise en œuvre de modèles dapprentissage automatique et dalgorithmes  vous serez responsable de la conception du développement et de la mise en œuvre de modèles dapprentissage automatique pour résoudre des problèmes de prévision de classification et de segmentation vous travaillerez sur des projets importants visant à améliorer la performance de notre service    collaborer avec les équipes métier  vous travaillerez en étroite collaboration avec les équipes afin de comprendre leurs besoins en termes danalyse de données et vous proposez des solutions techniques appropriées    participer à lautomatisation des processus  vous contribuerez à lautomatisation des processus liés à lanalyse de données pour améliorer lefficacité et la précision de nos opérations et pour ce faire  vous serez chargée dévaluer la qualité des données et de veiller à leur intégrité   analyser les résultats et recommandations  vous analyserez les résultats de vos modèles et fournirez des recommandations pour améliorer les performances des modèles et répondre aux besoins de lentreprisevous êtes inscrite en m ou m dans le domaine de la data science de linformatique des mathématiques de la statistique ou dun domaine connexe   vous avez une maitrise du python et r vous connaissez les outils comme pandas numpy scikitlearn etou des bibliothèques similaires    vous êtes curieux et vous avez uin esprit danalyse et de résolution de problèmes liées au données    you have good english level to read and understand technical procedure', 'data scientist python sql terraform bitbucket jenkins airflow docker kubernetes gcp bigquery spark dataprocidéalement montpellier jsem à massyjanviercontexte lanalytics factory sappuie sur un pôle data science rassemblant  ingénieurs data scientists data engineers software engineers et ops pour résoudre  principalement avec du machine learning  des défis commerciaux et opérationnels comme les ruptures en magasin la prévision des ventes loptimisation de lassortiment des produits la personnalisation de lexpérienceprofil nous recherchons un lead data scientist expérimenté sur les problématiques de prévision à laise pour mener des discussions avec différents métiers en capacité de guider des profils moins expérimentés sur leur pratiques de data scienceprérequis  sql python  expérience du développement logiciel agile avec multiples contributeurs git code review cicd bonnes pratiques  expérience du cloud idéalement gcp environnement technique des projets python sql terraform bitbucket jenkins airflow docker kubernetes gcp bigquery spark dataprocprofil candidatdata scientistidéalement montpellier jsem à massyjanviercontexte lanalytics factory sappuie sur un pôle data science rassemblant  ingénieurs data scientists data engineers software engineers et ops pour résoudre  principalement avec du machine learning  des défis commerciaux et opérationnels comme les ruptures en magasin la prévision des ventes loptimisation de lassortiment des produits la personnalisation de lexpérienceprofil nous recherchons un lead data scientist expérimenté sur les problématiques de prévision à laise pour mener des discussions avec différents métiers en capacité de guider des profils moins expérimentés sur leur pratiques de data scienceprérequis  sql python  expérience du développement logiciel agile avec multiples contributeurs git code review cicd bonnes pratiques  expérience du cloud idéalement gcp environnement technique des projets python sql terraform bitbucket jenkins airflow docker kubernetes gcp bigquery spark dataproc', 'description du poste iziwork est une agence de recrutement digital qui sélectionne les meilleures missions et offres demploi pour les centaines de milliers dintérimaires et candidats quelle a déjà séduits postulez en quelques minutes gérez votre contrat en un clin doeil depuis notre app et bénéficiez du suivi personnalisé de votre recruteur au quotidienà propos de la mission organiser et conduire les ateliers de construction des modèles de données pour chaque référentiel groupe accompagner les métiers à la définition des règles darchivage de gestion et de contrôle qualité assurer les contrôles préliminaires de cohérence des données accompagner ladministrateur des données au transcodage des règles de contrôle qualité dans talend assurer les contrôles préliminaires de cohérence des données participer au processus de migration des données dans lerp cible en accompagnant les métiers à lidentification des écarts et à la mise en conformité des data dans lales solutions cible identifier les incohérences avec larchitecture et participer à la synchronisation de lintégrité des flux assurer la supervision et lintégration des données de diverses natures et vérifier la qualité des données qui entrent dans le data lake structurer le cycle de vie de la donnée dans le respect des réglementations rgpd  isorémunération  avantagesrémunération  ¿ €  ¿ € par anprofil recherché issue dune formation en informatique de niveau bac vous disposez dune expérience similaire de  à  ans idéalement en milieu industriel ou ssi vous possédez une première expérience de gestion de projet informatique vous savez animer des ateliers très organisée rigoureuxse réactifve vous savez gérer les priorités votre sens du service et votre aisance relationnelle vous permettent dinstaurer un climat de confiance avec vos différents interlocuteurs vous maitrisez les langages informatiques suivants  java python sql connaissances souhaitées dun outil mdm talend tibco et dun etl vous bénéficiez dune bonne maîtrise dexcel notre environnement international requiert la maîtrise de langlais à un niveau b minimum intermédiaire  avancéexpérience  entre  mois et  anscertificats requis aucun certificat requis', 'notre client dans le secteur retail recherche un data scientist gps  geo experience hfdescriptif de la missionle directeur data  middleware de notre client recherche une expertise spécialisée pour une mission de courte durée  mois afin de modéliser certaines logiques pour produire un flux de données gps en temps réel plus propre le profil sera inclus dans léquipe de mission au sein du département data  middleware dans le cadre du programme operation vision et aura accès aux ressources cloud nécessaires à lanalyse des données linfrastructure et le support seront fournis par léquipe interne ainsi que tous les coûts associés à lexécution de la missionnous recherchons un data scientist  data analysts ayant de lexpérience avec les données gps et geo pour aider léquipe à fusionner différentes sources de localisation afin de produire un flux de position plus propre et didentifier les événements de passage vers des waypoints clés avec la position la plus élevée possible travaillant dans lenvironnement danalyse des données une base de données et des machines virtuelles à adapter par léquipe en fonction des besoins le scientifique des données devra alors  analyser les sources de données brutes au fil du temps proposer et prototyper des algorithmes de correction à mettre en uvre par léquipe de développeurs pour créer le flux gps corrigé en temps réel proposer et prototyper des algorithmes de passage pour définir le passage sur des points clés stations frontières stations frontières  à émettre à lintérieur du data hub définir des mesures defficacité pour les algorithmes et proposer  prototyper des améliorations itératives définir des algorithmes dalerte pour détecter les problèmes de précisionun technologue très talentueux a développé un algorithme de correction en python qui est actuellement utilisé dans une partie de lentreprise et qui pourrait être utilisé comme référence pour une première itérationla mission sera exécutée dans un contexte agile en stricte collaboration au sein dune équipe dédiée de développeurs et en collaboration avec des analystes des services informatiques et de lentreprise le cas échéantaucun équipement nest nécessaire  il pourrait être fourni selon les besoins sur la base dune pile standard sur le nuage azure python base de données sql vmcompétences  qualités indispensablesdata scientist geoexperience gpspythonagilecompétences  qualités qui seraient un expérience précédente dans un projet lié à la mobilité', 'description du poste référence poste  jcldate de publication  entreprise dédiée aux services de leau fourniture deau potable traitement des eaux usées construction déquipements saur exerce sa mission de service au public en faisant preuve dinnovation dagilité technique organisationnelle et humaine pour contribuer à faire de leau un bien de qualité accessible à tousavec   collaborateurs en france en arabie saoudite en ecosse en espagne et en pologne saur accompagne plus de   collectivités locales et industriels et sert  millions de consommateurs dans le mondemission  au sein de lã©quipe ia du groupe saur vous aurez pour mission le dã©veloppement de solutions iacontribuant ã faire de saur le champion de la transition hydrique dâ€™ici ã lâ€™ia constitue un levier essentiel pour prã©server la ressource en eau et lui redonner la valeur quelle mã©riteâ€¢ contribuer ã la performance des rã©seaux dâ€™eau potable et dâ€™assainissement des collectivitã©s en particulier rã©duire lespertes dues aux fuitesâ€¢ prã©dire les anomalies et dysfonctionnements des systã¯mes industriels et ã©quipementsâ€¢ optimiser le fonctionnement des procã©dã©s de traitement en particulier gã©nã©rer des ã©conomies dã©nergie et de rã©actifsâ€¢ accompagner les territoires dans leur trajectoire dâ€™adaptation au changement climatique sã©curiser leur accã¯s dans letemps ã leau en quantitã© et qualitã©vous dã©veloppez et contribuez ã des projets ia en appliquant des techniques de lâ€™ã©tat de lâ€™art en machine learning deeplearning statistiques nlp et reinforcement learning python sparkâ€¢ extrayez et croisez des donnã©es de sources pouvant ãªtre hã©tã©rogã¯nesâ€¢ prã©parez appliquez les traitements de nettoyage et de transformation des donnã©es pertinents time series tabulairetexte pour effectuer vos analysesâ€¢ concevez et proposez les solutions et algorithmes adaptã©s aux besoins mã©tier en adã©quation avec les contraintestechniques courantes et futures ã anticiper en particulier  mise ã lâ€™ã©chelle optimisation gros volumes de donnã©esarchitecture dâ€™entrepriseâ€¢ comparez et ã©valuez diffã©rents modã¯les ou mã©thodes de calcul et anticipez les avantages et inconvã©nients dans unenvironnement mã©tier ã©valuation des modã¯les via les critã¯res pertinentsâ€¢ crã©ez des visualisations de donnã©es pour communiquer les rã©sultats et les recommandations de maniã¯re efficace plotlydash streamlitâ€¢ rã©alisez des phases dâ€™exploration afin de cadrer les projetsã©valuer leur faisabilitã© des poc des mvp participez aux testset phases de recettes mettez en production les projets mis ã lâ€™ã©chelleâ€¢ vous ãªtes moteur dans la transmission et lâ€™ã©change dâ€™expã©rience et de pratiques techniques auprã¯s de vos pairs datascientists et audelaprofil  â€¢ master ou ecole dâ€™ingã©nieur spã©cialisã©e en data science bac â€¢  ã  ans dâ€™expã©rience en tant que data scientistâ€¢ idã©alement premiã¯re expã©rience dans une ã©quipe agilecompã©tences requisesâ€¢ anglais professionelâ€¢ pythonâ€¢ machine learningâ€¢ statistiquesâ€¢ modã©lisation de sã©ries temporellesâ€¢ sparkâ€¢ sqlâ€¢ visualisation graphique exemple plotly dash streamlitcompã©tences apprã©ciã©esâ€¢ kubernetesâ€¢ dataikuâ€¢ azureâ€¢ mã©thodes agilesmindsetâ€¢ pour vous on rã©ussit en ã©quipeâ€¢ votre rigueur se ressent dans votre codeâ€¢ vous vous maintenez activement ã jour sur lesderniã¯res technologies et mã©thodes en datascienceâ€¢ vous travaillez de maniã¯re autonome et savezgã©rer plusieurs projets en parallã¯levos futurs avantages vous intégrez saur sans période dessai votre rémunération vous sera versée sur  mois accompagnée dune prime deau dune prime de participation et dintéressement selon les résultats de lentreprise ainsi que dune prime de congés payés correspondant à  de votre rémunération brute mensuelle vous bénéficierez dune mutuelle et dune prévoyance santé vous aurez la possibilité douvrir votre plan depargne groupe et votre pereco profitant de labondement de lentreprise vous bénéficierez bien sûr de congés payés mais également de rttintégrer saur cest intégrer un groupe qui vous offrira de belles pe', 'description du poste au sein de la direction datascience marketing et modélisation de la division du financement aux particuliers qui produit et distribue des crédits et des services auprès de particuliers en direct ou par lintermédiaire de partenaires distributeurs assureurs banquiers et fintech vous rejoignez le pôle datascience et risque en tant que data scientist risquevos missions au sein dun service de  personnes vous participez au développement etou à lévolution des modèles économétriques statistiques appliqués à la prédiction des risquesen qualité data scientiste risque vos principales missions seront de concevoir et analyser des bases de données de modélisation créer calibrer et back tester les modèles quantitatifs de prédiction daide à la décision et de mesure des risques documenter les modèles et instruire leur validation auprès des corps daudit contribuer au développement des solutions de datascience mises en place dans le cadre des nouveaux projets de gestion des risques participer à la dynamique déquipe sur la conception la réalisation et de développement des applications datascience pour comptepropre et au service de nos partenaires bbc participer au développement des méthodes dautomatisation de production des indicateurs des modèles des backtests et des restitutions alimentant le pilotage des activitésdescription du profil les principales compétences requises pour le poste sont maîtrise des techniques de modélisation du risque modèles économétriques modèles statistiques modèles probabilistes machine learning techniques de data visualisation etc connaissances bancaires et réglementaires outils  niveau dautonomie et de compréhension suffisants des applications et si maîtrise des langages de programmation sas en particulier r python serait un plus bonne communication écrite et orale fiabilité rigueur et organisation curiosité ouverture desprit capacité dalertede formation supérieure en statistiques vous possédez à minima au moins  à  ans dexpériences au sein dune banque dun établissement financier dun régulateur dune agence de notation ou dun cabinet de conseil ce qui vous a permis dacquérir des connaissances en modélisation du risque de la réglementation bâle  et de la modélisation statistiquenous avons la conviction que la diversité de nos collaborateurs sous toutes ses formes est une richesse pour notre entreprise et ses clients nos postes sont ainsi ouverts à tous nous garantissons légalité de vos chances dans nos processus de recrutement et tout au long de votre carrière chez franfinance', 'dans le cadre de notre développement nous recherchons pour notre siège social situé à agen  une data scientist en cdi temps complet   rattaché au service data de  personnes vous contribuerez à la mise en place de la culture data driven du groupe    intégrez léquipe dsi dune trentaine de personnes pluridisciplinaires et participez également à la transition digitale le but étant dexploiter la puissance du numérique stimuler linnovation et améliorer le quotidien de nos équipes   dans le cadre de vos fonctions vos principaux défis seront de      contribuer à lidentification dopportunités doptimisation et à la prise de décisions éclairées pour favoriser la croissance et la rentabilité de lentreprise  participer à la construction et à la maintenance des modèles de données permettant la construction dindicateurs pertinents  à lélaboration des tableaux de bords  développer et mettre en œuvre des modèles statistiques régressions et de machine learning apprentissage automatique pour répondre à des enjeux métier  effectuer des tests et des validations pour évaluer la précision la robustesse et la pertinence des modèles et des méthodes utilisés  collaborer avec les équipes opérationnelles pour recueillir les besoins et les contraintes métier afin de proposer des solutions adaptées et participer à la conception dautomatisation des processus métiers  collaborer avec les autres membres de léquipe data pour résoudre des problèmes spécifiques et proposer des solutions innovantes    votre rôle intégrera également une dimension daccompagnement importante  formation aux outils vulgarisation des problématiques autonomie sur la gestion de projet planning présentation de résultats et de lavancement participation à des groupes de travail    vous contribuerez à la conduite du changement ainsi quà la capitalisation des connaissancesdiplômée dune école dingénieur ou équivalent bac  avec une composante mathématique etou informatique vous justifiez dune première expérience dau moins  ans dans une fonction équivalente   vous maîtrisez les fondamentaux des écosystèmes techniques de données excel sql python ou autre langage de programmation data science  vous savez exploiter des algorithmes de machine learning et avez déjà utilisé des outils de data visualisation ou bi    de plus la recherche de lamélioration continue et un fort esprit déquipe seront clés une capacité à expliquer de manière claire et concise des résultats complexes sera également nécessaire   enfin un excellent relationnel permettant de collaborer de manière pertinente avec des profils aussi bien techniques que métier est souhaité    le groupe priorise le relationnel et la proximité avec ces collaborateurs lorganisation de votre temps de travail sera à établir avec votre responsable arthur le télétravail pourra être proposé occasionnellement jusquà deux jours par semaine après validation de la période dessai   vous bénéficierez de la mutuelle dentreprise de lintéressement et participation une prime dobjectif et tickets restaurants', 'safran est un groupe international de haute technologie opérant dans les domaines de laéronautique propulsion équipements et intérieurs de lespace et de la défense sa mission  contribuer durablement à un monde plus sûr où le transport aérien devient toujours plus respectueux de lenvironnement plus confortable et plus accessible implanté sur tous les continents le groupe emploie   collaborateurs pour un chiffre daffaires de  mds deuros en  et occupe seul ou en partenariat des positions de premier plan mondial ou européen sur ses marchés safran sengage dans des programmes de rd qui préservent les priorités environnementales de sa feuille de route dinnovation technologiquesafran est dans le top  des meilleurs employeurs mondiaux  selon le magazine forbessafran aircraft engines conçoit produit et commercialise seul ou en coopération des moteurs aéronautiques civils et militaires aux meilleurs niveaux de performance la société est notamment à travers cfm international le leader mondial de la propulsion davions commerciaux court et moyencourriers dans le domaine de la propulsion militaire la société a intégralement conçu développé et produit le m et le m qui équipent respectivement le rafale et le mirage  et sera intégrateur du moteur du futur avion de combat européendescriptif missionau sein de la direction des bureaux detudes systèmes propulsifs de safran aircraft engines le pôle analyse de risques en exploitation are du service sûreté de fonctionnement soccupe particulièrement de modéliser la fiabilité  sécurité des moteurs en exploitation dans ce cadre vous serez amené à intervenir sur tous les produits civils et militaires de safran aircraft engines certifiés ou qualifiés vous serez notamment en charge des activités techniques suivantes   analyser les événements en production et en service à laide de modèles de survie à partir de données censurées et évaluer statistiquement les risques associés pour les flottes  réaliser les notes de justification  capitalisation  participer aux activités daméliorations  optimisation des codes développés pour les analyses statistiques  contribuer à la captation et à lanalyse du retour dexpérience en service  participer activement au développement et à la mise en oeuvre du plan de progrès du service sur les thématiques analyses statistiques  analyse du retour dexpérience a cette fin vous travaillerez en interface avec de nombreux acteurs au sein de lentreprise bureaux détudes de la direction technique et de la direction industrielle support client marques techniques', 'safran est un groupe international de haute technologie opérant dans les domaines de laéronautique propulsion équipements et intérieurs de lespace et de la défense sa mission  contribuer durablement à un monde plus sûr où le transport aérien devient toujours plus respectueux de lenvironnement plus confortable et plus accessible implanté sur tous les continents le groupe emploie   collaborateurs pour un chiffre daffaires de  mds deuros en  et occupe seul ou en partenariat des positions de premier plan mondial ou européen sur ses marchés safran sengage dans des programmes de rd qui préservent les priorités environnementales de sa feuille de route dinnovation technologiquesafran est dans le top  des meilleurs employeurs mondiaux  selon le magazine forbessafran aircraft engines conçoit produit et commercialise seul ou en coopération des moteurs aéronautiques civils et militaires aux meilleurs niveaux de performance la société est notamment à travers cfm international le leader mondial de la propulsion davions commerciaux court et moyencourriers dans le domaine de la propulsion militaire la société a intégralement conçu développé et produit le m et le m qui équipent respectivement le rafale et le mirage  et sera intégrateur du moteur du futur avion de combat européendescriptif missionau sein de lentité engineering de la direction support  services vous serez rattachée à un service de bureau détudes focalisé sur les moteurs en service la surveillance automatisée de nos moteurs via des modèles de suivi du fonctionnement en production ou des modèles de maintenance prédictive est aujourdhui un enjeu majeur pour réduire les coûts de production et pour assurer un service efficace et optimisé au client tout en réduisant les coûts de possession des moteurscette surveillance sappuie dune part sur des données de fonctionnement moteur collectées grâce à des capacités embarquées dacquisition de données de vol et dautre part sur des données issues de la production des ateliers de réparation et de stations de mesures météorologiquesenvironnementales disponibles au niveau des aéroportsle bureau detudes support et services a mis en place un pôle analytics pour soutenir les activités de lengineering analyse causale des événements flotte suivi de létat de santé des pièces en service contribution à la maintenance prédictive  et ce grâce à lexploitation des données de vol de maintenance de production  cette activité est menée en coordination étroite avec les différents secteurs de la société qui travaillent en lien avec lanalyse de ces donnéesmissions du posteassurer un soutien actif par lanalyse de données aux analyses causales support en serviceen se basant entre autres sur les données moteurs production flotte et maintenance développer des algorithmes ayant une double composante physique et statistique permettant de réaliser un suivi individualisé des moteurs  détection dusures de pièces ou de composants moteurs aide la décision pour des inspections ou réparations ciblées participer au déploiement de la démarche analytics au sein du be support et services ce qui inclut notamment  le soutien et la formation à la démarche danalyse de données et de modélisation le soutien à lutilisation et le développement de moyens daccès de visualisation et de traitement de la donnée la communication régulière auprès des unitéscontribuer au maintien en conditions opérationnelles des outils spécifiques du be support et services utilisées pour la visualisation ou le croisement de données pour le traitement automatique des sanctions des questions clientsdans le cadre des activités du be contribuer aux échanges avec les différents secteurs en charge de la donnée et des projets associéscontribuer à lélaboration de la roadmap analytics du be en cohérence avec les besoins et roadmaps métiers de la direction et des besoins des clients internessappuyer sur le réseau métier mathématiques algorithmes et informatique scientifique pour adresser les besoins de son périmètre et diffuser au sein du be les bonnes pratiques établies par le réseau', 'au sein de notre service de recherche appliquée vous intégrez une équipe en charge du développement de lintelligence artificielle dans nos systèmes dédiés à la mesure lanalyse et le pilotage déquipements et dinstallations électriquesdans ce cadre vos missions consistent à \\tcomprendre précisément les problématiques métier et les traduire de manière analytique \\tidentifier collecter préparer les données et réaliser une première analyse statistique \\tdévelopper des algorithmes permettant de répondre aux problèmes posés et veiller à leur industrialisation \\tcommuniquer vos résultats et vos solutions en les confrontant avec les équipes métier \\taccompagner les équipes pour permettre leur montée en compétencesvotre profil\\ttitulaire dun diplôme dingénieur en science des données  intelligence artificielle ou en génie électrique  électronique avec une expérience significative en science des données sur des projetsvous disposez de connaissances en systèmes embarqués c  c et êtes rompus à la gestion de projets votre ouverture desprit alliée à votre force de proposition et votre capacité à synthétiser en vulgarisant les sujets vous permettent doptimiser vos échanges avec les métiersau regard de la dimension internationale du groupe mais également des sujets développés la maitrise de langlais niveau b minimum est impérativevous avez envie de relever ce défi  alors rejoigneznous et venez vous aussi contribuer au développement de socomec à la qualité de nos produits et services notre performance et notre notoriétéréférence  hssagtd', 'tes missions seront le développement et lautomatisation  développer des macros personnalisées sur dataiku pour faciliter le nettoyage et la validation de conformité des projets du métier automatiser les tâches récurrentes liées au nettoyage des données et à la validation des projetsla gestion des bonnes pratiques  instaurer des bonnes pratiques sur dataiku en matière de gestion de projets et de manipulation des données créer des guides et des documents de référence pour lutilisation efficace de dataikule support et lassistance  fournir un support technique sur dataiku et les macros développées en répondant aux questions des utilisateurs et en résolvant les problèmes rencontrés assister les utilisateurs dans lutilisation des macros et les aider à optimiser leurs workflowsle développement de dashboards et lanalyses de données  concevoir et développer des dashboards interactifs sur tableau pour visualiser les données et les résultats des analyses effectuer des analyses de données sur les logs de dataiku afin de segmenter les utilisateurs et de réduire les coûts de licencele challenge et lévaluation  évaluer les solutions existantes en matière de données à la poste et challenger les processus et les outils en place participer aux appels doffres liés aux données en proposant des améliorations et des solutions innovantesla migration du data lake  assurer le suivi et la gestion de la migration du data lake en garantissant une transition sans heurts des données critiques vers la nouvelle infrastructure sassurer de lintégrité et de laccessibilité des données tout au long du processus de migrationla communication et la présentation  présenter et communiquer les résultats des analyses de données les macros développées et les bonnes pratiques aux équipes métier organiser des sessions de formation et des réunions pour partager les connaissances et favoriser ladoption des meilleures pratiqueston profil  exigence  ton objectif principal est de comprendre les objectifs du projet et les besoins des parties prenantes tu accordes une grande importance à la communication et poses des questions pour garantir une compréhension mutuelle claire tu excelles à loral comme à lécrit texprimant de manière claire et efficace grâce à ta capacité danalyse et de synthèse tu simplifies les informations complexes pour les transmettre facilement à léquipe tu es un collaborateur harmonieux attentif aux besoins des clients et prêt à soutenir tes collègues enfin tu es rigoureux dans la gestion du projet et as une réelle motivation pour atteindre les objectifs fixés pour toi la réussite se traduit par une livraison de qualité passion  geek est un compliment tu aimes lunivers digital et notamment dans sa dimension technique cette passion de la tech te permet dêtre naturellement à laise dans les projets qui peuvent parfois savérer complexes et pointus tu ne peux pas te sentir largué donc ce nest pas un effort que de te mettre à jour régulièrement sur les sujets de technologie cest un plaisir nourrissant ouverture  comme nous tu regardes le monde entier avec intérêt  tu aimes rencontrer des gens dorigines diverses tu parles ou apprends plusieurs langues les autres cultures sont des sources dinspiration tu peux ou souhaiterais voyager  tu es ouvert aux richesses de lautreavignon agenceweb digital', 'ce poste est accessible après une formation en poei de  semaineslela data scientist développe des algorithmes dapprentissage automatique selon les besoins des équipes métiers ses compétences en statistiques lui permettent de construire des modèles de machine learning et ses connaissances en informatique laident à anticiper leur mise en production en amont de ces deux missions ilelle est également en charge de structurer et danalyser les données quilelle utiliseactivitésextraction et structuration des donnéesélaboration des algorithmes dintelligence artificielleindustrialisation des modèles dintelligence artificielle dans les applicationsparticipation active aux projets', 'safran est un groupe international de haute technologie opérant dans les domaines de laéronautique propulsion équipements et intérieurs de lespace et de la défense sa mission  contribuer durablement à un monde plus sûr où le transport aérien devient toujours plus respectueux de lenvironnement plus confortable et plus accessible implanté sur tous les continents le groupe emploie   collaborateurs pour un chiffre daffaires de  milliards deuros en  et occupe seul ou en partenariat des positions de premier plan mondial ou européen sur ses marchés safran sengage dans des programmes de recherche et développement qui préservent les priorités environnementales de sa feuille de route dinnovation technologiquesafran est dans le top  des meilleurs employeurs mondiaux  selon le magazine forbessafran engineering services offre des services en ingénierie de haute technologie dans les domaines de laéronautique de lénergie et du transport terrestre avec  ans dexpérience la société sappuie sur   ingénieurs répartis dans  pays à travers le mondedescriptif missionla data science est au coeur de la transformation industrielle chez safran et se met au service de nos métiers de la production manufacturing  ou de la surveillance de nos systèmes en vol service en intégrant safran engineering services vous aurez lopportunité de pouvoir répondre aux problématiques industrielles actuelles en utilisant les données métier issues des machines de production des capteurs embarqués des opérations de maintenance etc et mettant en oeuvre les technologies algorithmiques de létat de lartdans ce cadre et au sein du pôle data de safran engineering services votre mission consistera à intervenir sur toutes les phases du cycle de vie dun projet data prise de besoin métier proof of concept industrialisation vous aurez la responsabilité dencadrer techniquement les jeunes data scientist de léquipe sur leur projet dassurer leur montée en compétences et de supporter le management sur la structuration de léquipe dans sa croissance concrètement vous aurez trois principaux volets de responsabilité  o production technique définir le besoin en échangeant avec les métiers appliquer des techniques dextraction et danalyse dinformations obtenues à partir de différentes sources de données industrielles  evaluer la qualité et la richesse des données les analyser et en restituer les résultats vers le métier  analyser les données pour traduire une problématique métier en problème mathématiquestatistique et réciproquement comparer et évaluer différents modèles ou méthodes de calculs machine learning deep learning et anticiper les avantages et inconvénients dans un environnement métier concevoir et développer des visualisations impactantes pour le métier utiliser les infrastructures cloud de safran aws spécifier les solutions retenues et accompagner léquipe dans lindustrialisation des traitements de données dans un logiciel industrielo support au cadrage des projets contribuer à lélaboration des réponses techniques aux appels doffres  identifier les work packages des projets en phase de démarrageo mentoring technique des profils juniors participer à lévolution et lamélioration continue de léquipe data nouvelles offres méthodes pratiques de code  assurer la montée en compétences des data scientist veille technique et scientifique animation de léquipe', 'description du poste  au sein d’une équipe vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs si missions principales    modéliser traiter et transformer des données complexes  concevoir une solution de stockage de données modèle en étoile  développer des connecteurs ou passerelles de données à l’aide des outils etl talend  lire comprendre et rédiger des documents techniques en lien avec le poste de data architect  data engineer  dictionnaire de données modélisation merise uml matrice de bus  rester à jour et en veille sur les différentes technologies et méthodes liées au poste de data architect  data engineer par le biais de l’auto formation ou la formation professionnelle  des compétences en machine learning  ia au sens large sont appréciées ', 'description du poste  au sein d’une équipe vous assurez le cycle de vie des applications développées avec de grands challenges techniques et organisationnels pour accompagner nos clients dans la transformation de leurs si missions principales    modéliser traiter et transformer des données complexes  concevoir une solution de stockage de données modèle en étoile  développer des connecteurs ou passerelles de données à l’aide des outils etl talend  lire comprendre et rédiger des documents techniques en lien avec le poste de data architect  data engineer  dictionnaire de données modélisation merise uml matrice de bus  rester à jour et en veille sur les différentes technologies et méthodes liées au poste de data architect  data engineer par le biais de l’auto formation ou la formation professionnelle  des compétences en machine learning  ia au sens large sont appréciées ', 'rejoignez un collectif anime par le gout du defiles équipes data science sont garantes de l’avancée innovatrice sur les concurrents participent à la diffusion de la culture data au sein de cdiscount tissent des liens avec le monde académique et exercent une veille active sur l’état de l’art des modèles mathématiques et des nouvelles technologiesen rejoignant notre équipe vous aurez la possibilité d’exploiter toutes les nouveautés du machine  deep learning ainsi que d’ia générative large language models avec notamment openai mistralai et bien d’autres pour mener vos missions à bien vous aurez à votre disposition un ensemble de technos matures  snowflake environnements jupyter hébergés serverside un pipeline cicd solide construit autour de docker et kubernetes gpus et cpus etc notre terrain de jeux se base sur plus de  to de données actives portant sur un éventail de domaines différents comme un référentiel de m de produits actifs m de recherches client par jour et jusqu’à m de visiteurs uniques pendant la période du black fridayvous serez notamment en charge de •    production d’algorithmes de machine learning•    définition de protocoles de tests statistiques pour quantifier la performance de ces algorithmes•    suivi et reporting aux clients internes•    contribution et participation aux séminaires et hackathons internes avec l’ensemble des membres des équipes data •    rayonnement extérieur  publications conférences séminaires…venez développer vos compétences et votre employabilité dans un environnement de travail unique   un accord télétravail pouvant aller jusqu’à  jours par semaine  des locaux modernes et situés au bord de la garonne en plein cœur des bassins à flots hub de la tech bordelaise  de nombreux labels obtenus great place to work happy trainees afnor diversité et egalité fh  l’opportunité d’être acteur d’initiatives rse et liées à la diversité  handiteam greenteam', 'qui sommesnous thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées les forces de sécurité et les opérateurs d’importance vitale ces activités qui regroupent radiocommunications réseaux systèmes de protection systèmes d’information critiques et cybersécurité répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante thales intervient tout au long de la chaîne de valeur des équipements aux systèmes en passant par le soutien logistique et les services associésnos équipes de l’activité systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenacesle département augmented data recherche un ingénieur data scientist expérimenté hf basé à sophiaantipolis qui etesvous de formation bac  minimum vous maitrisez le fonctionnement des algorithmes de machine learning et possédez de bonnes connaissances en ingénierie logicielle vous avez de l’expérience sur une plateforme cloud azureawsgcp vous êtes familier avec certains outils data tels que dataiku mlflow dvc kibana sagemaker vous maitrisez des langages de développement logiciel python spark scala java cc … tensorflow keras pytorch scikitlearn ou pandas … n’ont pas de secrets pour vous vous maitrisez l’anglais vous souhaitez mettre en application vos compétences pour la résolution de problèmes complexes dans des domaines métiers variés vous aimez transmettre vos savoirs faires et accompagner les utilisateurs dans la prise en main de vos solutions innovantes vous aimez travailler en équipe au quotidien et vous savez interagir en mode « agile » pour vous le succès n’est que collectif vous avez plus de  ans d’expérience sur un poste équivalentvous vous reconnaissez  alors parlons missions …ce que nous pouvons accomplir ensemble le département augmented data fédère et coordonne les savoirfaire algorithmie big data data science et data viz au travers d’une structure permettant d’accélérer la transformation des enjeux data de nos clientsnos savoirs faires data science intelligence artificielle algorithmie expertise imagerie data engineering devops mlopsnos partenaires recherche  inria cnrs inserm ia… externes  nvidia elastic mongodb…vos missions en collaboration avec les membres de notre structure augmented data assurer la veille technologique pour suivre les évolutions en machine', 'léquipe de bd orange business toulouse recherche sonsa future data scientist pour rejoindre sa team data ton quotidien  en intégrant business  decision orange business tu peux participer à une grande diversité dactivités dans la data en voici un aperçu  au démarrage du projet  recueillir et analyser les besoins du client analyser lécosystème data du client et en déduire la faisabilité du projet estimer les charges pendant la phase de réalisation  analyse exploratoire et statistique de la donnée savoir utiliser et intervenir sur les pipelines de données développer les procédures dalimentation et de labellisation structurer la donnée en vue de répondre aux besoins du modèle développer des modèles de statistiques et dapprentissage machine evaluer la performance des modèles valoriser les travaux par des visualisations mettre en production mise en place du monitoring des modèles mlopstu interviens dans divers environnements concernant  les technologies  python r torch tensorflow jax scikitlearn etc les domaines dapplication  nlp computer vision audio processing les méthodes de machine learning  deep learning clustering classification régression optimisation indexation les éditeurs  gcp azure aws alteryx dataiku denodo knime etcen fonction de ton évolution et de nos enjeux tu peux aussi évoluer sur des missions transverses conseil coaching avantvente formation audit etc la prise dinitiative est toujours la bienvenue ', 'l équipe de bd orange business toulouse recherche sonsa future data scientist pour rejoindre sa team dataton quotidien en intégrant business  decision orange business tu peux participer à une grande diversité d activités dans la data en voici un aperçu au démarrage du projet  recueillir et analyser les besoins du client analyser l écosystème data du client et en déduire la faisabilité du projet estimer les chargespendant la phase de réalisation  analyse exploratoire et statistique de la donnée savoir utiliser et intervenir sur les pipelines de données développer les procédures d alimentation et de labellisation structurer la donnée en vue de répondre aux besoins du modèle développer des modèles de statistiques et d apprentissage machine evaluer la performance des modèles valoriser les travaux par des visualisations mettre en production mise en place du monitoring des modèles mlopstu interviens dans divers environnements concernant les technologies  python r torch tensorflow jax scikitlearn etcles domaines d application  nlp computer vision audio processingles méthodes de machine learning  deep learning clustering classification régression optimisation indexationles éditeurs  gcp azure aws alteryx dataiku denodo knime etcen fonction de ton évolution et de nos enjeux tu peux aussi évoluer sur des missions transverses conseil coaching avantvente formation audit etc la prise d initiative est toujours la bienvenue ', 'l équipe de bd orange business toulouse recherche sonsa future data scientist pour rejoindre sa team dataton quotidien en intégrant business  decision orange business tu peux participer à une grande diversité d activités dans la data en voici un aperçu au démarrage du projet recueillir et analyser les besoins du clientanalyser l écosystème data du client et en déduire la faisabilité du projetestimer les chargespendant la phase de réalisation analyse exploratoire et statistique de la donnéesavoir utiliser et intervenir sur les pipelines de donnéesdévelopper les procédures d alimentation et de labellisationstructurer la donnée en vue de répondre aux besoins du modèledévelopper des modèles de statistiques et d apprentissage machineevaluer la performance des modèlesvaloriser les travaux par des visualisationsmettre en production mise en place du monitoring des modèles mlopstu interviens dans divers environnements concernant les technologies  python r torch tensorflow jax scikitlearn etcles domaines d application  nlp computer vision audio processingles méthodes de machine learning  deep learning clustering classification régression optimisation indexationles éditeurs  gcp azure aws alteryx dataiku denodo knime etcen fonction de ton évolution et de nos enjeux tu peux aussi évoluer sur des missions transverses conseil coaching avantvente formation audit etc la prise d initiative est toujours la bienvenue ', 'nous vous proposons de rejoindre le data lab en qualité de data scientist au sein de léquipe retailtout dabord vous prendrez part à des missions de linspection générale ou de laudit au cours de ces missions vous vous assurerez de comprendre et expliciter la problématique notamment avec une orientation « data »vous identifierez les données à forte valeur visàvis de la mission et assurerez la liaison avec les propriétaires de ces donnéesvous organiserez la collecte des données dans le respect de leur sensibilité et du cycle de vie définivous réaliserez lanalyse des données en accord avec les besoins des intervenants de la missionlorsque possible etou nécessaire vous vous attacherez à présenter les résultats de vos analyses à la fois aux intervenants de la mission ainsi quau service auditévous rédigerez un rapport danalyse détaillévous serez le référent « data » de la mission et assurerez le contact privilégié entre les intervenants de la mission et le data labvous participerez également à la définition de loffre de service du data lab vous serez amené à travailler avec la dsi digad pour déterminer loffre outillée adéquate et nécessaire à lactivité danalyse de donnéesvous participerez à des activités transverses que ce soit au niveau du data lab ou plus globalement digad vous participerez à la formation des inspecteurs et des auditeurs à lanalyse de donnéesvous participerez à la « communauté data » particulièrement au sein du data lab mais également au niveau du groupeenfin vous travaillerez à des sujets plus orientés « recherche » vous assurerez une veille technologique sur le sujet de la data sciencevous prendrez part aux activités de recherche menées par le data lab', 'venez extraire analyser et développer des algorithmes complexes dont le machine learning votre objectif  optimiser le performances des métiers sur le domaine confiéet si être « data scientist » chez april vous permettait …de choisir un métier dont vous pourrez être fier  «accompagner et protéger à chaque moment qui compte simplement» telle est la mission et la raison d’être partagée par l’ensemble de nos collaborateursde développer votre expertise dans un environnement en pleine transformation au carrefour de l’innovation et de l’expérience client  notre ambition à horizon  être un acteur digital omnicanal et agile champion de lexpérience clientde vous engager au sein dune entreprise engagée  nous rejoindre c’est faire partie d’un groupe responsable qui agit en entreprise citoyenne en étant mobilisé autour de  axes santé aidants éducation et environnement avec un impact sociétal positif et réelnous nous engageons à promouvoir des emplois respectant la diversité et la différence ouverts à chacunvos futures missions  gestion des données et support à la décisionparticiper aux ateliers dexpression des besoins internes métiers comprendre leurs problématiques et les traduire de manière analytiquecollecter et analyser les données internes et externes par lutilisation de méthodes statistiques pour connaitre et exploiter en continu les évolutions des domaines dapplicationsélectionner et mettre en œuvre des algorithmes dapprentissage automatique pertinents sur les cas dusage machine learning deep learning etccommuniquer les résultat et les solutions avec les équipes métiers et instances de direction en veillant à vulgariser les concepts complexes veille et développement de lactivitémaintenir faire évoluer et documenter les modèles existants en collaboration avec les utilisateurspromouvoir lindustrialisation des modèles auprès des utilisateurs des domaines dapplication après la réalisation de poceffectuer une veille sur les nouvelles technologies et solutions digitales de data science et expérimenter de nouvelles méthodes de modélisation et data sciencecette opportunité est à pourvoir dans le cadre d’un remplacementdirectement rattachée à jean marc responsable de léquipe data vous rejoindrez notre équipe lyonnaisedès votre arrivée vous bénéficierez dun parcours dintégration pour favoriser votre prise de poste', 'venez extraire analyser et développer des algorithmes complexes dont le machine learning votre objectif  optimiser le performances des métiers sur le domaine confiéet si être « data scientist » chez april vous permettait de choisir un métier dont vous pourrez être fier  «accompagner et protéger à chaque moment qui compte simplement» telle est la mission et la raison dêtre partagée par lensemble de nos collaborateurs de développer votre expertise dans un environnement en pleine transformation au carrefour de linnovation et de lexpérience client  notre ambition à horizon  être un acteur digital omnicanal et agile champion de lexpérience client de vous engager au sein dune entreprise engagée  nous rejoindre cest faire partie dun groupe responsable qui agit en entreprise citoyenne en étant mobilisé autour de  axes santé aidants éducation et environnement avec un impact sociétal positif et réelnous nous engageons à promouvoir des emplois respectant la diversité et la différence ouverts à chacunvos futures missions  gestion des données et support à la décision participer aux ateliers dexpression des besoins internes métiers comprendre leurs problématiques et les traduire de manière analytique collecter et analyser les données internes et externes par lutilisation de méthodes statistiques pour connaitre et exploiter en continu les évolutions des domaines dapplication sélectionner et mettre en oeuvre des algorithmes dapprentissage automatique pertinents sur les cas dusage machine learning deep learning etc communiquer les résultat et les solutions avec les équipes métiers et instances de direction en veillant à vulgariser les concepts complexes veille et développement de lactivité maintenir faire évoluer et documenter les modèles existants en collaboration avec les utilisateurs promouvoir lindustrialisation des modèles auprès des utilisateurs des domaines dapplication après la réalisation de poc effectuer une veille sur les nouvelles technologies et solutions digitales de data science et expérimenter de nouvelles méthodes de modélisation et data sciencecette opportunité est à pourvoir dans le cadre dun remplacement directement rattachée à jean marc responsable de léquipe data vous rejoindrez notre équipe lyonnaisedès votre arrivée vous bénéficierez dun parcours dintégration pour favoriser votre prise de poste', 'qui sommesnous thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées les forces de sécurité et les opérateurs d’importance vitale ces activités qui regroupent radiocommunications réseaux systèmes de protection systèmes d’information critiques et cybersécurité répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante thales intervient tout au long de la chaîne de valeur des équipements aux systèmes en passant par le soutien logistique et les services associésnos équipes de l’activité systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenacesle département augmented data recherche un ingénieur data scientist expérimenté hf basé à sophiaantipolis qui etesvous de formation bac  minimum vous maitrisez le fonctionnement des algorithmes de machine learning et possédez de bonnes connaissances en ingénierie logicielle vous avez de l’expérience sur une plateforme cloud azureawsgcp vous êtes familier avec certains outils data tels que dataiku mlflow dvc kibana sagemaker vous maitrisez des langages de développement logiciel python spark scala java cc … tensorflow keras pytorch scikitlearn ou pandas … n’ont pas de secrets pour vous vous maitrisez l’anglais vous souhaitez mettre en application vos compétences pour la résolution de problèmes complexes dans des domaines métiers variés vous aimez transmettre vos savoirs faires et accompagner les utilisateurs dans la prise en main de vos solutions innovantes vous aimez travailler en équipe au quotidien et vous savez interagir en mode « agile » pour vous le succès n’est que collectif v…', 'premier assureur en france nous voulons aller plus loin en devenant lassureur digital de référencela direction data  analytics développe lusage de la data dans les interactions avec nos clientsau sein de cette grande direction vous serez rattaché plus précisément à léquipe ai factory e caa qui comprends  collaborateurs en cdi  data scientist  pilotes de projet ia  ia engineer  manager ia a pour grande mission de développer les moteurs dintelligence artificielle pour le groupe crédit agricole assurances modèles de machine learning et deep learning en logique industrielleet concrètement de quoi sagitil sur le terrain nous couvrons les grands domaines de lia  traitement de texte reconnaissance de document contrôle des risques détections de la fraude ia générativeprincipales missions en production en cours et à venir         des modèles supervisés et non supervisés sur de la donnée structurée  prédiction des anomalies dans linfocentre avec de lia xgb  réseaux de neurones        analyse de texte libre pour comprendre lintention des questions dans loutil de remonté des interrogations des caisses régionales vers caa ia générative topic modeling tfidf etc        traitement automatiques des documents ia générative ocr computer vision nlpclassification de documentlecture dinformation dans les documents ex factures carte grise etcidentification dintention des clients        surveillance des comportements clients anormaux rnns xgb        détection de fraude à lassurance        business analytics pour les filiales internationales xgbà ces missions sajoutent des missions plus générales  interagir avec lensemble des filiales du groupe crédit agricole mener des développements rd au sein des projets qui sont ensuite partagés dans léquipe participer à la vie de la communauté data science dans le groupe crédit agricole assurances participer à la veille technologique en data science et échanger avec le datalab groupe casavos avantagesnous proposons des opportunités professionnelles au sein de lensemble du groupe crédit agricole et un modèle managérial favorisant la mise en responsabilité et la prise dinitiativesparmi vos avantages          jours télétravaillés soit   du temps de travail annuel à temps plein         jours de congés payés  quinzaine de rtt        rémunération fixe variable individuelle et variable collective        epargne salariale avec système dabondement        avantages bancaires avantages cse compte épargne temps mutuelle prise en charge à   par lemployeur        une salle de sports deux restaurants dentreprise deux cafétérias des lounges…tous nos postes sont ouverts aux personnes en situation de handicap', 'léquipe ds propose des algorithmes et solutions logicielles innovantes pour améliorer la performance des grands industriels airbus renault safran etc nous travaillons en équipe dans nos locaux pas de prestation en régie chez les clients avec possibilité de télétravail  jours par semaine nous sommes basés au cœur des alpes à grenoblevous participerez au développement de solutions analytiques  ia ayant un vrai impact dans lindustrie les missions sont variées avec des contextes et environnement techniques spécifiques à chaque projet nos briques technologiques propriétaires sont le fruit dune rd interne active vous devrez proposer des solutions articulant les modèles et algorithmes pertinents dans le respect des délais avec un haut niveau de qualité la plupart des développements sont en python le package est très attractif salaire fixe  primes négociable selon lexpérience avec mutuelle tickets restaurants frais de transports etc nos atoutsune équipe soudée favorisant la montée en compétenceslassociation avec le cabinet de conseil step groupe de  collaborateurs entre paris et toulouse avec qui nous travaillons au quotidienune rd sur projet client et en interne pour rester à la pointe des technologies développéesde fortes compétences en informatique nous livrons des solutions fonctionnelles du prototype au logiciella reconnaissance du top management de nos clients avec qui nous travaillons depuis plusieurs annéespossibilité de télétravail  jours par semaineles team events  fois par an avec les consultants de step', 'nous recrutons un ingénieur data scientist pour accélérer le déploiement en production de modèles mldl dans un cloud awsen tant que data scientistml vous intégrerez une équipe et serez responsable de concevoir développer et mettre en œuvre des composantesmodèles de mldl vous serez donc amené à participer aux différentes étapes dun projet de la conception au déploiement idéation poc conception des pipelines mlops gestion du cycle de vie des modèles en production… ', 'nous recrutons une ingénieur data scientist expérimentée pour rejoindre notre business unit industrie au sein de la business line data intelligence elle accompagne nos clients dans leurs problématiques associées à la transformation digitale nos offres se déclinent autour de la data intelligence  de la maintenance prédictivevotre mission  analyser de gros volumes de données de type ‘série temporelle’ développer et déployer des modèles prédictifs et assurer la communication avec le client  contribuer aux activités de prospection et d’avantvente de l’offre ‘maintenance prédictive’ compréhension du besoin proposition de solutions techniques réalisation de missions d’audit …l’environnement technique  java python r spark  time series ', 'description de la mission vous intégrerez le service performance opérationnelle au sein dune équipe de  personnes ce service a deux fonctions principales  sassurer du respect de la qualité de service avec le réseau colis privé agences et hubs et assurer le suivi de la prestation auprès des clients chargeurs votre mission consiste à collecter et valoriser les données liées à la qualité de livraison du réseau colis privé pour améliorer la performance opérationnelle pour cela vous êtes en charge de   identifier des outils danalyse et des outils de reporting pertinents  mettre en place les requêtes permettant dinterroger le système dinformation  recueillir trier nettoyer analyser et faire parler les données  créer des dashboard interactifs afin de rendre les résultats lisibles et exploitables  mettre en forme les données et mettre en place des requêtes pour automatiser et publier les analyses de manière récurrente  formaliser et construire les supports de formation pour les utilisateurs ', 'notre partenaire élu parmi les meilleures sociétés de conseil et entreprise à plus forte croissance est à la recherche de data scientist  ml ops engineer pour rejoindre ses équipes cette jeune société  ans dexistence composée dune aine de collaborateurs est dotée dune véritable communauté dexperts data data analyst  scientist  engineer spécialisée dans la conception et création de plateformes data et ia ce groupe est également réputé pour le très bon accompagnement de ses collaborateursen tant que data scientist  ml ops tu participeras aux différents projets auprès des clients avec pour principales missions contribuer à la conception complète des produits de data sciencemettre à contribution votre expertise et compétences en data science et en intelligence artificielle pour le bénéfice de lensemble de lentreprise et de ses partenairesparticiper à lélaboration de la stratégie et du savoirfaire en data sciencecollaborer à lédification de la réputation de lentreprise dans le domaine de la data science et de lintelligence artificielleoptimiser les processus de déploiement pour assurer la fiabilité la reproductibilité et la surveillance des modèles en production dans des environnements cloud', 'notre client startup basé en région parisienne est à la recherche de talents passionnés de data et dia pour intégrer leurs équipe en tant que data scientist  machine learning engineerrejoignez une entreprise dynamique en plein essor résolument tournée vers lexcellence bénéficiez des nombreux avantages offerts par un poste attrayant dans le domaine de la data et de lia avec une rapide expansion de vos compétences et des opportunités de prise de responsabilitésvous collaborerez étroitement avec des collègues aux profils diversifiés tels que des data ingénieurs des data scientists des machine learning engineers etc au sein dune équipe multidisciplinaire unie avec pour principales missions contribuer à la conception complète des produits de data sciencemettre à contribution votre expertise et compétences en data science et en intelligence artificielle pour le bénéfice de lensemble de lentreprise et de ses partenairesparticiper à lélaboration de la stratégie et du savoirfaire en data sciencecollaborer à lédification de la réputation de lentreprise dans le domaine de la data science et de lintelligence artificielle', 'nous recherchons une data scientist hf ayant déjà une expérience réussie dans lindustrie pour rejoindre notre équipe performance opérationnellevotre mission dans le cadre de notre stratégie industrie  vous ferez preuve dinnovation pour optimiser nos processus industriels vous développerez des solutions en modélisation mathématique recherche opérationnelle et aide à la décision computer vision machine learning analyse de séries temporelles statistique data mining maintenance prédictive etcvos responsabilitéstravailler en étroite collaboration avec les équipes opérationnelles pour comprendre les besoins métier et identifier les opportunités doptimisation grâce à lintelligence artificielleanalyser les données concevoir des solutions développer vos modèles pour résoudre des problèmes opérationnelstravailler avec les équipes du système dinformation pour déployer votre solution sur la plateforme ia du site industriel', 'nous recherchons une data scientist hf ayant déjà une expérience réussie dans lindustrie pour rejoindre notre équipe performance opérationnellevotre mission dans le cadre de notre stratégie industrie  vous ferez preuve dinnovation pour optimiser nos processus industriels vous développerez des solutions en modélisation mathématique recherche opérationnelle et aide à la décision computer vision machine learning analyse de séries temporelles statistique data mining maintenance prédictive etcvos responsabilitéstravailler en étroite collaboration avec les équipes opérationnelles pour comprendre les besoins métier et identifier les opportunités doptimisation grâce à lintelligence artificielleanalyser les données concevoir des solutions développer vos modèles pour résoudre des problèmes opérationnelstravailler avec les équipes du système dinformation pour déployer votre solution sur la plateforme ia du site industriel', 'vous faites partie de celles et ceux qui pensent que même avec plusieurs années dexpérience on continue à apprendre  alors nous sommes sur la même longueur donde  et si on en parlait au sein de latelier data  ai on retrouve des communautés de pratique organisées par tribus lidée cest de se retrouver et de partager des expertises communes de développer ses compétences en équipes à taille humaine vous aurez donc pour missions de faire du conseil du delivery et de la rdêtre citizen data scientist chez octo cest  faire du conseil autant que du delivery  accompagner nos clients dans la mise en oeuvre de solutions autour de la gestion et transformation de leur data participer au développement agile et à limplémentation dapplications dans le respect des bonnes pratiques et bien sûr qui dit conseil dit convictions  proposer la solution la plus adaptée cest aussi savoir et oser challenger nos clients et cest dans notre adn  participer aux réponses aux appels doffres et avantventes participer activement à la rd data  ai  au programme veille technologique  bonnes pratiques quelques sujets chauds du moment  le green ai green data et aigreen former  mentorer  le partage de connaissances et la montée en compétences des collaborateurs vous importent  nous sommes convaincus et prônons haut et fort la valeur de transmission mentoring et gestion de votre carrière seront donc à lhonneur et oui chez octo le savoir nest pas chasse gardée ', 'au sein de notre service de recherche appliquée vous intégrez une équipe en charge du développement de l intelligence artificielle dans nos systèmes dédiés à la mesure l analyse et le pilotage d équipements et d installations électriquesdans ce cadre vos missions consistent à ·        comprendre précisément les problématiques métier et les traduire de manière analytique ·        identifier collecter préparer les données et réaliser une première analyse statistique ·        développer des algorithmes permettant de répondre aux problèmes posés et veiller à leur industrialisation ·        communiquer vos résultats et vos solutions en les confrontant avec les équipes métier ·        accompagner les équipes pour permettre leur montée en compétences', 'pour le compte de clients bancaires et assurantiels vous  assurez le monitoring de la performance de votre solution sur lensemble du cycle de production en lien étroit avec les sponsors métiers et utilisateurs finaux intervenez sur la conception de solutions data science  ia du prototypage à lindustrialisation au sein déquipes pluridisciplinaires intervenez sur des thématiques faisant appel à du machine learning et scoring en lien avec la connaissance client lefficacité opérationnelle loptimisation de processus la lutte antifraude dans les directions data orientées risque et marketing évoluez dans un environnement technologique data science etou big data et vous serez ainsi amené à travailler en python r spark sas ou des solutions reconnues telles que dataikuen interne vous  participez aux réponses dappels doffres sur votre spécialité contribuez à la production de contenus dexpertise podcasts focus articles interviews et tables rondes pour le domaine dexcellence data jouez un rôle de référent pour les consultants juniors bénéficiez du programme de formations certifiantes spécialisées en data data science machine learning engineer cdo ainsi quà un large choix de formations en ligne sur lensemble des expertises portées par le groupe', 'pour le compte de clients bancaires et assurantiels vous assurez le monitoring de la performance de votre solution sur lensemble du cycle de production en lien étroit avec les sponsors métiers et utilisateurs finauxintervenez sur la conception de solutions data science  ia du prototypage à lindustrialisation au sein déquipes pluridisciplinairesintervenez sur des thématiques faisant appel à du machine learning et scoring en lien avec la connaissance client lefficacité opérationnelle loptimisation de processus la lutte antifraude dans les directions data orientées risque et marketingévoluez dans un environnement technologique data science etou big data et vous serez ainsi amené à travailler en python r spark sas ou des solutions reconnues telles que dataikuen interne vous participez aux réponses dappels doffres sur votre spécialitécontribuez à la production de contenus dexpertise podcasts focus articles interviews et tables rondes pour le domaine dexcellence datajouez un rôle de référent pour les consultants juniorsbénéficiez du programme de formations certifiantes spécialisées en data data science machine learning engineer cdo ainsi quà un large choix de formations en ligne sur lensemble des expertises portées par le groupe', 'en tant que senior data scientist au sein de léquipe de lutte contre la fraude de msh international vous serez en charge du développement de la mise en oeuvre et de lamélioration continue des modèles dintelligence artificielle et des nouveautés technologiques pour détecter les fraudes potentielles et les profils suspicieux de nos assurés  prestataires de santé frauduleux vous travaillerez en étroite collaboration avec léquipe antifraude et abus existante pour renforcer notre capacité à identifier et prévenir les activités frauduleuses dans le domaine de lassurance santé internationale et de la prévoyance          concevoir développer et mettre en oeuvre des modèles de machine learning datamining et des algorithmes dapprentissage automatique pour la détection de la fraude          collaborer avec léquipe antifraude et abus pour comprendre les tendances et les schémas de fraude potentiels          analyser les données existantes et collecter de nouvelles données pertinentes pour améliorer la performance des modèles          mettre en place des processus dapprentissage automatique automatisés pour surveiller en continu les données en temps réel          travailler en étroite collaboration avec dautres départements y compris la sécurité de linformation les opérations le réseau médical et le médical pour garantir la mise en oeuvre efficient efficace des modèles de détection de fraude et des abus          participer à la veille technologique et rester à jour avec les avancées en matière de lutte contre la fraude et dintelligence artificielle          mener des investigations et livrer des rapports de fraude pour tout cas de fraude avérée          elaborer du reporting standard et personnalisé selon les instructions de la direction          contribuer à lanimation du réseau interne de correspondants antifraude et abus          assister à des réunions externes avec les clients assureurs partenaires de manière régulière', 'vous intégrerez une équipe d’une quinzaine d’ingénieurs et docteurs régulièrement accompagnés de postdoctorants doctorants et stagiaires spécialisée dans l’évaluation et la qualification des systèmes d’intelligence artificielle et la cybersécurité cette équipe est historiquement reconnue pour son expertise dans l’évaluation des systèmes de traitement automatique de l’information traitement de la langue traitement de limage etc depuis quelques années elle couvre également l’évaluation des systèmes robotiques intelligents tels que les dispositifs médicaux les robots industriels collaboratifs les véhicules autonomes etcl’équipe met actuellement en place les leia laboratoires d’evaluation des intelligences artificielles des infrastructures de test physiques en simulation et mixtes pour l’ia et la robotique elle capitalise sur les savoirfaire à la fois divers et ciblés de ses experts tal imagerie robotique etc afin d’apporter conjointement une solution satisfaisante au besoin d’évaluation et de certification des systèmes intelligents pour tous les secteurs de l’industrieen tant que data scientist  expert en données vous serez la référence de l’équipe sur tous les aspects « données » liés à nos projets outre la structuration de nos propres bases de données vous contribuerez à tous nos projets nécessitant une expertise sur la donnée dans le cadre de son utilisation en intelligence artificielle machine learning réseaux de neurones etcactivités principales sur projets  développement de notre offre de services liés à la qualité des donnéesexploration des méthodes existantes pour la qualification des données dans le contexte de l’iadéfinition de méthodes de qualification des données pour l’ia du concept jusqu’à l’implémentation des outilsactivités de structuration au long cours  administration des bases de données au sein de l’équipe structuration des infrastructures mise en partage opensource gestion des licences et doi etcactivités ponctuelles  à  fois par an pilotage  création et suivi de l’application des protocoles de collecte prétraitement annotation posttraitement et qualification des jeux de donnéespilotage des travaux réalisés par les prestataires annotateurs', 'le projet nous recherchons une\\u202fcheffe de projet ri dans le domaine de\\u202fl’intelligence artificielle et du training dans le domaine du nucléaire   vous contribuerez particulièrement à la création de\\u202fmodules de\\u202fformation immersive\\u202fréalité augmentée réalité virtuelle mixed reality vous expérimenterez et réaliserez des recherches afin d’adapter personnaliser et générer des scénarios de formation  vous aurez loccasion dévoluer dans un contexte de\\u202frecherche applicative\\u202fproche de la recherche académique vous aurez aussi l’opportunité de monter en compétence sur la gestion de projet et d’encadrer des collaborateurs    votre mission votre mission sera de participer à la création de\\u202fmodules de\\u202fformation immersive votre mission en détails  définir avec le chef de projet actuel et le responsable du programme les orientations scientifiques du projet en accord avec la stratégie du groupe assurer la veille scientifique et technologique du projet afin d’être force de proposition sur de nouveaux cas d’applications définir l’organisation des travaux et méthodes de recherche piloter le projet\\u202f contenu technique réalisation des travaux de recherche et encadrement des collaborateurs  contribuer techniquement au développement des travaux de recherche valoriser les résultats du projet au travers notamment de communications d’articles scientifiques et de congrès de conférences… participer le cas échéant à des réponses d’appels à projets  propositions collaboratives ', 'le projet nous recherchons une\\u202fcheffe de projet ri dans le domaine de\\u202fl’intelligence artificielle  notre ambition est de construire un modèle de\\u202fprédiction des arrêts de centrales nucléaires\\u202fgénérés par le\\u202fchangement climatique\\u202fet particulièrement les épisodes de\\u202fcanicules  les centrales étant refroidies par des sources froides eaux des fleuves et rivières\\u202fvous expérimenterez et développerez les méthodes et outils afin de prédire la température de l’eau en aval et amont des centrales en fonction des données environnementales\\u202fdébit température de l’eau et de l’air… ainsi que les\\u202fpotentielles interruptions ou réductions d’activité des centrales  vous aurez loccasion dévoluer dans un contexte de\\u202frecherche applicative\\u202fproche de la recherche académique vous aurez aussi l’opportunité de monter en compétence sur la gestion de projet et d’encadrer des collaborateurs    votre mission votre mission sera de participer au développement du modèle de\\u202fprédiction des arrêts de centrales nucléaires votre mission en détails  définir avec le chef de projet actuel et le responsable du programme les orientations scientifiques du projet en accord avec la stratégie du groupe assurer la veille scientifique et technologique du projet afin d’être force de proposition sur de nouveaux cas d’applications définir l’organisation des travaux et méthodes de recherche piloter le projet\\u202f contenu technique réalisation des travaux de recherche et encadrement des collaborateurs  contribuer techniquement au développement des travaux de recherche valoriser les résultats du projet au travers notamment de communications d’articles scientifiques et de congrès de conférences… participer le cas échéant à des réponses d’appels à projets  propositions collaboratives  ', 'l’arrivée à maturité de solutions informatiques permettant un traitement automatique du langage naturel ainsi qu’un apprentissage par l’exemple a ouvert à crédit mutuel alliance fédérale de nouvelles perspectives pour mieux assister les collaborateurs et mieux servir leurs clientsle groupe a donc décidé d’investir fortement dans l’informatique cognitive  nous avons été la première entreprise à mettre en œuvre la technologie ibm watson en franceplusieurs solutions dites « cognitives » ont ainsi été déployées  assistants virtuels chatbot analyseurs d’emails assistant vocal téléphoniqueau sein de l’équipe en charge de concevoir déployer et maintenir les services en machine learning liés aux solutions cognitives du groupe vos missions seront les suivantes réaliser des études initiales pour évaluer le coût et les gains potentiels d’utilisation du machine learningconcevoir des algorithmes et des modèles performants répondant aux différents besoins métierconcevoir et rédiger des spécifications fonctionnelles et techniquesgérer les demandes d’évolution organiser les déploiements le suivi et la maintenance en productiontravailler en mode projet dans le respect du système de management de la qualitéassurer un travail de vieille scientifique notamment via l’animation de formations internes', 'concrètement votre futur quotidien vous prendrez en charge lensemble des travaux autour de la thématique de la petite enfance et de lenfancejeunesse enjeu majeur de la branche famille les prestations concernant le domaine de la petite enfance constituent le cœur dactivité des prestations légales versées par la branchevous serez en charge du suivi statistique des prestations sur le champ de la petite enfance et de lenfancejeunesse production de données statistiques alimentation de lopen data de la branche famille de répondre aux demandes et sollicitations concernant les prestations légales sur le champ de la petite enfance et de lenfancejeunesse ces demandes émanent notamment des cabinets ministériels des directions dadministration centrale des corps dinspection de la réalisation de travaux danalyse sur les prestations de la petite enfance et de lenfancejeunesse dassurer le suivi statistique transversal à lensemble des prestations familiales notamment le profil socioéconomique des bénéficiaires de mettre à jour et contribuer à faire évoluer les outils de tableau de bord et de datavisualisation construits sur ce sujet', 'mission en tant que data scientist spécialisé en intelligence artificielle ia vous serez au cœur de la conception et du déploiement de solutions basées sur lia pour répondre aux défis complexes au sein de la dnum vous utiliserez des techniques avancées dapprentissage automatique et de traitement du langage naturel pour élaborer des modèles innovants responsabilités   concevoir entraîner tester et déployer des modèles dapprentissage profond et dautres techniques avancées dia collecter nettoyer et prétraiter des données pour les rendre utilisables pour lentraînement de modèles dia explorer et visualiser des grands ensembles de données pour identifier des tendances et des caractéristiques pertinentes collaborer étroitement avec les équipes produit développement et métier pour définir les besoins et les objectifs en matière dia travailler avec un ingénieur data  data devops pour créer des pipelines de données adaptés aux modèles dia se tenir informé des dernières avancées en matière dia dapprentissage automatique et de traitement du langage nature assurer que les solutions dia sont conçues et déployées de manière éthique transparente et conforme aux réglementations ', ' concrètement votre futur quotidien vous produirez des données statistiques et des études sur la petite enfance permettant déclairer le débat public et dappuyer la conception et la mise en œuvre des politiques publiques portées par la cnaf vous prendrez notamment part au projet de service public de la petite enfance qui vise à développer le nombre de places offertes pour un accueil de qualité pour lensemble des enfantsexperte des données sur la petite enfance vos missions se déclineront ainsi   produire et analyser les données de la branche sur les crèches places de crèches créées ou détruites localisation types daccueil…pour cela vous exploiterez les tables statistiques annuelles produites à partir des données de gestion de la branche famille et en assurerez la maîtrise douvrage vous valoriserez le contenu à destination des directions de la cnaf du réseau des caf et du grand public articles en format «  pages » ou dossiers détudes rapport de lobservatoire national de la petite enfance onape rapport dévaluation des politiques de sécurité sociale présentation en séminaire diffusion de données en opendata…  produire et analyser le taux de couverture des jeunes enfants par une offre daccueil à partir de sources de données provenant de différentes institutions cnaf drees depp ccmsa acoss insee diffusé par lonape et décliné au niveau territorial jusquà la commune cet indicateur est central pour lanalyse et le pilotage des politiques publiques sur la petite enfance vous participerez aux réflexions méthodologiques autour de la mesure du taux de couverture dans le cadre de groupes de travail réunissant la cnaf linsee la drees et la depppiloter le tableau de bord imaje indicateurs de mesure de laccueil du jeune enfant qui vise à restituer des informations statistiques stratégiques à plusieurs échelons géographiques communaux et supracommunaux au réseau des caisses sur quatre thèmes  le public loffre lusage et la tension entre loffre et la demande avec les nouveaux outils informatiques mis à disposition power bi plateforme opendata en relation avec les chargés détudes du réseauconcevoir produire et analyser des indicateurs dévaluation des politiques publiquesinvestir dans la connaissance et la compréhension du modèle économique des eaje en particulier des « microcrèches »des déplacements occasionnels peuvent être à prévoir en provinceles travaux de la direction sont consultables sur etudes recherches et évaluations  bienvenue sur caffr  ']\n"
     ]
    }
   ],
   "source": [
    "#enlever les \"\\n\":\n",
    "corpus = [s.replace(\"\\n\",\"\") for s in corpus]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/natachaperez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nécessité de punkt - modèle de tokénisation\n",
    "#à charger en ligne si ce n'est pas déjà fait\n",
    "import nltk\n",
    "#nltk.download()\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['presentation', 'delipce', 'experte', 'en', 'développement', 'logiciel', 'data', 'et', 'interprétation', 'métier', 'elipce', 'se', 'positionne', 'sur', 'axes', 'efficacité', 'opérationnelle', 'business', 'intelligence', 'et', 'centre', 'de', 'services', 'logicielspour', 'accompagner', 'nos', 'clients', 'nous', 'créons', 'des', 'solutions', 'digitales', 'adaptées', 'qui', 'correspondent', 'à', 'leur', 'fonctionnement', 'et', 'à', 'la', 'réalité', 'de', 'leur', 'entreprise', 'nous', 'proposons', 'également', 'des', 'solutions', 'dexternalisation', 'permettant', 'dassurer', 'la', 'maintenance', 'lévolution', 'ou', 'le', 'développement', 'dapplications', 'logicielles', 'pour', 'le', 'compte', 'de', 'nos', 'clients', 'via', 'la', 'mise', 'à', 'disposition', 'de', 'pool', 'de', 'compétences', 'au', 'sein', 'des', 'équipes', 'client', 'et', 'sur', 'nos', 'plateaux', 'techniquesnous', 'nous', 'engageons', 'à', 'fournir', 'des', 'solutions', 'de', 'qualité', 'à', 'promouvoir', 'linnovation', 'et', 'à', 'cultiver', 'une', 'véritable', 'cohésion', 'au', 'sein', 'de', 'notre', 'équipedescription', 'du', 'poste', 'au', 'sein', 'dune', 'équipe', 'vous', 'assurez', 'le', 'cycle', 'de', 'vie', 'des', 'applications', 'développées', 'avec', 'de', 'grands', 'challenges', 'techniques', 'et', 'organisationnels', 'pour', 'accompagner', 'nos', 'clients', 'dans', 'la', 'transformation', 'de', 'leurs', 'simissions', 'principales', 'modéliser', 'traiter', 'et', 'transformer', 'des', 'données', 'complexesconcevoir', 'une', 'solution', 'de', 'stockage', 'de', 'données', 'modèle', 'en', 'étoiledévelopper', 'des', 'connecteurs', 'ou', 'passerelles', 'de', 'données', 'à', 'laide', 'des', 'outils', 'etl', 'talendlire', 'comprendre', 'et', 'rédiger', 'des', 'documents', 'techniques', 'en', 'lien', 'avec', 'le', 'poste', 'de', 'data', 'architect', 'data', 'engineer', 'dictionnaire', 'de', 'données', 'modélisation', 'merise', 'uml', 'matrice', 'de', 'busrester', 'à', 'jour', 'et', 'en', 'veille', 'sur', 'les', 'différentes', 'technologies', 'et', 'méthodes', 'liées', 'au', 'poste', 'de', 'data', 'architect', 'data', 'engineer', 'par', 'le', 'biais', 'de', 'lauto', 'formation', 'ou', 'la', 'formation', 'professionnelledes', 'compétences', 'en', 'machine', 'learning', 'ia', 'au', 'sens', 'large', 'sont', 'appréciéesprofil', 'recherché', 'vous', 'êtes', 'data', 'architect', 'et', 'ou', 'data', 'engineer', 'et', 'ou', 'data', 'scientist', 'confirmé', 'ou', 'aguerri', 'vous', 'souhaitez', 'intégrer', 'une', 'équipe', 'jdynamique', 'et', 'relever', 'de', 'nouveaux', 'challenges', 'vous', 'avez', 'besoin', 'de', 'transversalité', 'dautonomie', 'et', 'ne', 'pas', 'être', 'cantonné', 'à', 'une', 'seule', 'tâche', 'vous', 'êtes', 'curieux', 'et', 'souhaitez', 'explorer', 'des', 'données', 'en', 'provenance', 'de', 'différents', 'secteurs', 'industrie', 'finance', 'transport', 'servicevous', 'êtes', 'ou', 'avez', 'été', 'analyste', 'programmeur', 'vous', 'êtes', 'curieux', 'de', 'savoir', 'la', 'différence', 'entre', 'une', 'base', 'de', 'données', 'et', 'un', 'entrepôt', 'de', 'données', 'vous', 'avez', 'envie', 'daller', 'plus', 'loin', 'que', 'le', 'simple', 'stockage', 'et', 'vous', 'souhaitez', 'apprendre', 'à', 'valoriser', 'les', 'données', 'ce', 'poste', 'vous', 'permettra', 'de', 'vous', 'épanouir', 'par', 'la', 'formation', 'aux', 'technologies', 'et', 'techniques', 'en', 'business', 'intelligence', 'nhésitez', 'pas', 'à', 'postuler', 'qualités', 'requises', 'couteau', 'suisseorganisé', 'réactif', 'et', 'rigoureuxetre', 'créatif', 'avoir', 'le', 'sens', 'de', 'linnovationavoir', 'un', 'état', 'desprit', 'analytique', 'et', 'de', 'synthèseforce', 'de', 'propositionbonus', 'mutuelle', 'prise', 'en', 'charge', 'à', 'accord', 'dintéressementvélo', 'électrique', 'de', 'fonction', 'à', 'la', 'demandeséance', 'de', 'sport', 'en', 'entreprise']\n"
     ]
    }
   ],
   "source": [
    "#transformer le corpus en liste de listes (les documents)\n",
    "#par tokénisation\n",
    "corpus_tk = [word_tokenize(doc) for doc in corpus]\n",
    "\n",
    "#avant\n",
    "#print(corpus[0])\n",
    "\n",
    "#après tokénisation\n",
    "#print('\\n')\n",
    "print(corpus_tk[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['presentation', 'delipce', 'experte', 'en', 'développement', 'logiciel', 'data', 'et', 'interprétation', 'métier', 'elipce', 'se', 'positionne', 'sur', 'ax', 'efficacité', 'opérationnelle', 'business', 'intelligence', 'et', 'centre', 'de', 'service', 'logicielspour', 'accompagner', 'no', 'client', 'nous', 'créons', 'de', 'solution', 'digitales', 'adaptées', 'qui', 'correspondent', 'à', 'leur', 'fonctionnement', 'et', 'à', 'la', 'réalité', 'de', 'leur', 'entreprise', 'nous', 'proposons', 'également', 'de', 'solution', 'dexternalisation', 'permettant', 'dassurer', 'la', 'maintenance', 'lévolution', 'ou', 'le', 'développement', 'dapplications', 'logicielles', 'pour', 'le', 'compte', 'de', 'no', 'client', 'via', 'la', 'mise', 'à', 'disposition', 'de', 'pool', 'de', 'compétences', 'au', 'sein', 'de', 'équipes', 'client', 'et', 'sur', 'no', 'plateau', 'techniquesnous', 'nous', 'engageons', 'à', 'fournir', 'de', 'solution', 'de', 'qualité', 'à', 'promouvoir', 'linnovation', 'et', 'à', 'cultiver', 'une', 'véritable', 'cohésion', 'au', 'sein', 'de', 'notre', 'équipedescription', 'du', 'poste', 'au', 'sein', 'dune', 'équipe', 'vous', 'assurez', 'le', 'cycle', 'de', 'vie', 'de', 'application', 'développées', 'avec', 'de', 'grand', 'challenge', 'technique', 'et', 'organisationnels', 'pour', 'accompagner', 'no', 'client', 'dans', 'la', 'transformation', 'de', 'leurs', 'simissions', 'principales', 'modéliser', 'traiter', 'et', 'transformer', 'de', 'données', 'complexesconcevoir', 'une', 'solution', 'de', 'stockage', 'de', 'données', 'modèle', 'en', 'étoiledévelopper', 'de', 'connecteurs', 'ou', 'passerelles', 'de', 'données', 'à', 'laide', 'de', 'outils', 'etl', 'talendlire', 'comprendre', 'et', 'rédiger', 'de', 'document', 'technique', 'en', 'lien', 'avec', 'le', 'poste', 'de', 'data', 'architect', 'data', 'engineer', 'dictionnaire', 'de', 'données', 'modélisation', 'merise', 'uml', 'matrice', 'de', 'busrester', 'à', 'jour', 'et', 'en', 'veille', 'sur', 'le', 'différentes', 'technology', 'et', 'méthodes', 'liées', 'au', 'poste', 'de', 'data', 'architect', 'data', 'engineer', 'par', 'le', 'biais', 'de', 'lauto', 'formation', 'ou', 'la', 'formation', 'professionnelledes', 'compétences', 'en', 'machine', 'learning', 'ia', 'au', 'sen', 'large', 'sont', 'appréciéesprofil', 'recherché', 'vous', 'êtes', 'data', 'architect', 'et', 'ou', 'data', 'engineer', 'et', 'ou', 'data', 'scientist', 'confirmé', 'ou', 'aguerri', 'vous', 'souhaitez', 'intégrer', 'une', 'équipe', 'jdynamique', 'et', 'relever', 'de', 'nouveaux', 'challenge', 'vous', 'avez', 'besoin', 'de', 'transversalité', 'dautonomie', 'et', 'ne', 'pa', 'être', 'cantonné', 'à', 'une', 'seule', 'tâche', 'vous', 'êtes', 'curieux', 'et', 'souhaitez', 'explorer', 'de', 'données', 'en', 'provenance', 'de', 'différents', 'secteurs', 'industrie', 'finance', 'transport', 'servicevous', 'êtes', 'ou', 'avez', 'été', 'analyste', 'programmeur', 'vous', 'êtes', 'curieux', 'de', 'savoir', 'la', 'différence', 'entre', 'une', 'base', 'de', 'données', 'et', 'un', 'entrepôt', 'de', 'données', 'vous', 'avez', 'envie', 'daller', 'plus', 'loin', 'que', 'le', 'simple', 'stockage', 'et', 'vous', 'souhaitez', 'apprendre', 'à', 'valoriser', 'le', 'données', 'ce', 'poste', 'vous', 'permettra', 'de', 'vous', 'épanouir', 'par', 'la', 'formation', 'aux', 'technology', 'et', 'technique', 'en', 'business', 'intelligence', 'nhésitez', 'pa', 'à', 'postuler', 'qualités', 'requises', 'couteau', 'suisseorganisé', 'réactif', 'et', 'rigoureuxetre', 'créatif', 'avoir', 'le', 'sen', 'de', 'linnovationavoir', 'un', 'état', 'desprit', 'analytique', 'et', 'de', 'synthèseforce', 'de', 'propositionbonus', 'mutuelle', 'prise', 'en', 'charge', 'à', 'accord', 'dintéressementvélo', 'électrique', 'de', 'fonction', 'à', 'la', 'demandeséance', 'de', 'sport', 'en', 'entreprise']\n"
     ]
    }
   ],
   "source": [
    "#Lemmatisation\n",
    "lem = WordNetLemmatizer()\n",
    "corpus_lm = [[lem.lemmatize(mot) for mot in doc] for doc in corpus_tk]\n",
    "print(corpus_lm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#charger les stopwords\n",
    "mots_vides = stopwords.words('french')\n",
    "#print(mots_vides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['presentation', 'delipce', 'experte', 'en', 'développement', 'logiciel', 'data', 'et', 'interprétation', 'métier', 'elipce', 'se', 'positionne', 'sur', 'ax', 'efficacité', 'opérationnelle', 'business', 'intelligence', 'et', 'centre', 'de', 'service', 'logicielspour', 'accompagner', 'no', 'client', 'nous', 'créons', 'de', 'solution', 'digitales', 'adaptées', 'qui', 'correspondent', 'à', 'leur', 'fonctionnement', 'et', 'à', 'la', 'réalité', 'de', 'leur', 'entreprise', 'nous', 'proposons', 'également', 'de', 'solution', 'dexternalisation', 'permettant', 'dassurer', 'la', 'maintenance', 'lévolution', 'ou', 'le', 'développement', 'dapplications', 'logicielles', 'pour', 'le', 'compte', 'de', 'no', 'client', 'via', 'la', 'mise', 'à', 'disposition', 'de', 'pool', 'de', 'compétences', 'au', 'sein', 'de', 'équipes', 'client', 'et', 'sur', 'no', 'plateau', 'techniquesnous', 'nous', 'engageons', 'à', 'fournir', 'de', 'solution', 'de', 'qualité', 'à', 'promouvoir', 'linnovation', 'et', 'à', 'cultiver', 'une', 'véritable', 'cohésion', 'au', 'sein', 'de', 'notre', 'équipedescription', 'du', 'poste', 'au', 'sein', 'dune', 'équipe', 'vous', 'assurez', 'le', 'cycle', 'de', 'vie', 'de', 'application', 'développées', 'avec', 'de', 'grand', 'challenge', 'technique', 'et', 'organisationnels', 'pour', 'accompagner', 'no', 'client', 'dans', 'la', 'transformation', 'de', 'leurs', 'simissions', 'principales', 'modéliser', 'traiter', 'et', 'transformer', 'de', 'données', 'complexesconcevoir', 'une', 'solution', 'de', 'stockage', 'de', 'données', 'modèle', 'en', 'étoiledévelopper', 'de', 'connecteurs', 'ou', 'passerelles', 'de', 'données', 'à', 'laide', 'de', 'outils', 'etl', 'talendlire', 'comprendre', 'et', 'rédiger', 'de', 'document', 'technique', 'en', 'lien', 'avec', 'le', 'poste', 'de', 'data', 'architect', 'data', 'engineer', 'dictionnaire', 'de', 'données', 'modélisation', 'merise', 'uml', 'matrice', 'de', 'busrester', 'à', 'jour', 'et', 'en', 'veille', 'sur', 'le', 'différentes', 'technology', 'et', 'méthodes', 'liées', 'au', 'poste', 'de', 'data', 'architect', 'data', 'engineer', 'par', 'le', 'biais', 'de', 'lauto', 'formation', 'ou', 'la', 'formation', 'professionnelledes', 'compétences', 'en', 'machine', 'learning', 'ia', 'au', 'sen', 'large', 'sont', 'appréciéesprofil', 'recherché', 'vous', 'êtes', 'data', 'architect', 'et', 'ou', 'data', 'engineer', 'et', 'ou', 'data', 'scientist', 'confirmé', 'ou', 'aguerri', 'vous', 'souhaitez', 'intégrer', 'une', 'équipe', 'jdynamique', 'et', 'relever', 'de', 'nouveaux', 'challenge', 'vous', 'avez', 'besoin', 'de', 'transversalité', 'dautonomie', 'et', 'ne', 'pa', 'être', 'cantonné', 'à', 'une', 'seule', 'tâche', 'vous', 'êtes', 'curieux', 'et', 'souhaitez', 'explorer', 'de', 'données', 'en', 'provenance', 'de', 'différents', 'secteurs', 'industrie', 'finance', 'transport', 'servicevous', 'êtes', 'ou', 'avez', 'été', 'analyste', 'programmeur', 'vous', 'êtes', 'curieux', 'de', 'savoir', 'la', 'différence', 'entre', 'une', 'base', 'de', 'données', 'et', 'un', 'entrepôt', 'de', 'données', 'vous', 'avez', 'envie', 'daller', 'plus', 'loin', 'que', 'le', 'simple', 'stockage', 'et', 'vous', 'souhaitez', 'apprendre', 'à', 'valoriser', 'le', 'données', 'ce', 'poste', 'vous', 'permettra', 'de', 'vous', 'épanouir', 'par', 'la', 'formation', 'aux', 'technology', 'et', 'technique', 'en', 'business', 'intelligence', 'nhésitez', 'pa', 'à', 'postuler', 'qualités', 'requises', 'couteau', 'suisseorganisé', 'réactif', 'et', 'rigoureuxetre', 'créatif', 'avoir', 'le', 'sen', 'de', 'linnovationavoir', 'un', 'état', 'desprit', 'analytique', 'et', 'de', 'synthèseforce', 'de', 'propositionbonus', 'mutuelle', 'prise', 'en', 'charge', 'à', 'accord', 'dintéressementvélo', 'électrique', 'de', 'fonction', 'à', 'la', 'demandeséance', 'de', 'sport', 'en', 'entreprise']\n",
      "\n",
      "\n",
      "['presentation', 'delipce', 'experte', 'développement', 'logiciel', 'data', 'interprétation', 'métier', 'elipce', 'positionne', 'ax', 'efficacité', 'opérationnelle', 'business', 'intelligence', 'centre', 'service', 'logicielspour', 'accompagner', 'no', 'client', 'créons', 'solution', 'digitales', 'adaptées', 'correspondent', 'fonctionnement', 'réalité', 'entreprise', 'proposons', 'également', 'solution', 'dexternalisation', 'permettant', 'dassurer', 'maintenance', 'lévolution', 'développement', 'dapplications', 'logicielles', 'compte', 'no', 'client', 'via', 'mise', 'disposition', 'pool', 'compétences', 'sein', 'équipes', 'client', 'no', 'plateau', 'techniquesnous', 'engageons', 'fournir', 'solution', 'qualité', 'promouvoir', 'linnovation', 'cultiver', 'véritable', 'cohésion', 'sein', 'équipedescription', 'poste', 'sein', 'dune', 'équipe', 'assurez', 'cycle', 'vie', 'application', 'développées', 'grand', 'challenge', 'technique', 'organisationnels', 'accompagner', 'no', 'client', 'transformation', 'leurs', 'simissions', 'principales', 'modéliser', 'traiter', 'transformer', 'données', 'complexesconcevoir', 'solution', 'stockage', 'données', 'modèle', 'étoiledévelopper', 'connecteurs', 'passerelles', 'données', 'laide', 'outils', 'etl', 'talendlire', 'comprendre', 'rédiger', 'document', 'technique', 'lien', 'poste', 'data', 'architect', 'data', 'engineer', 'dictionnaire', 'données', 'modélisation', 'merise', 'uml', 'matrice', 'busrester', 'jour', 'veille', 'différentes', 'technology', 'méthodes', 'liées', 'poste', 'data', 'architect', 'data', 'engineer', 'biais', 'lauto', 'formation', 'formation', 'professionnelledes', 'compétences', 'machine', 'learning', 'ia', 'sen', 'large', 'appréciéesprofil', 'recherché', 'data', 'architect', 'data', 'engineer', 'data', 'scientist', 'confirmé', 'aguerri', 'souhaitez', 'intégrer', 'équipe', 'jdynamique', 'relever', 'nouveaux', 'challenge', 'besoin', 'transversalité', 'dautonomie', 'pa', 'être', 'cantonné', 'seule', 'tâche', 'curieux', 'souhaitez', 'explorer', 'données', 'provenance', 'différents', 'secteurs', 'industrie', 'finance', 'transport', 'servicevous', 'analyste', 'programmeur', 'curieux', 'savoir', 'différence', 'entre', 'base', 'données', 'entrepôt', 'données', 'envie', 'daller', 'plus', 'loin', 'simple', 'stockage', 'souhaitez', 'apprendre', 'valoriser', 'données', 'poste', 'permettra', 'épanouir', 'formation', 'technology', 'technique', 'business', 'intelligence', 'nhésitez', 'pa', 'postuler', 'qualités', 'requises', 'couteau', 'suisseorganisé', 'réactif', 'rigoureuxetre', 'créatif', 'avoir', 'sen', 'linnovationavoir', 'état', 'desprit', 'analytique', 'synthèseforce', 'propositionbonus', 'mutuelle', 'prise', 'charge', 'accord', 'dintéressementvélo', 'électrique', 'fonction', 'demandeséance', 'sport', 'entreprise']\n"
     ]
    }
   ],
   "source": [
    "#suppression des mots-vides\n",
    "corpus_sw = [[mot for mot in doc if not (mot in mots_vides)] for doc in corpus_lm]\n",
    "\n",
    "#vérification - origine\n",
    "print(corpus_lm[0])\n",
    "\n",
    "#sans les stopwords\n",
    "print('\\n')\n",
    "print(corpus_sw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['presentation', 'delipce', 'experte', 'développement', 'logiciel', 'data', 'interprétation', 'métier', 'elipce', 'positionne', 'efficacité', 'opérationnelle', 'business', 'intelligence', 'centre', 'service', 'logicielspour', 'accompagner', 'client', 'créons', 'solution', 'digitales', 'adaptées', 'correspondent', 'fonctionnement', 'réalité', 'entreprise', 'proposons', 'également', 'solution', 'dexternalisation', 'permettant', 'dassurer', 'maintenance', 'lévolution', 'développement', 'dapplications', 'logicielles', 'compte', 'client', 'via', 'mise', 'disposition', 'pool', 'compétences', 'sein', 'équipes', 'client', 'plateau', 'techniquesnous', 'engageons', 'fournir', 'solution', 'qualité', 'promouvoir', 'linnovation', 'cultiver', 'véritable', 'cohésion', 'sein', 'équipedescription', 'poste', 'sein', 'dune', 'équipe', 'assurez', 'cycle', 'vie', 'application', 'développées', 'grand', 'challenge', 'technique', 'organisationnels', 'accompagner', 'client', 'transformation', 'leurs', 'simissions', 'principales', 'modéliser', 'traiter', 'transformer', 'données', 'complexesconcevoir', 'solution', 'stockage', 'données', 'modèle', 'étoiledévelopper', 'connecteurs', 'passerelles', 'données', 'laide', 'outils', 'etl', 'talendlire', 'comprendre', 'rédiger', 'document', 'technique', 'lien', 'poste', 'data', 'architect', 'data', 'engineer', 'dictionnaire', 'données', 'modélisation', 'merise', 'uml', 'matrice', 'busrester', 'jour', 'veille', 'différentes', 'technology', 'méthodes', 'liées', 'poste', 'data', 'architect', 'data', 'engineer', 'biais', 'lauto', 'formation', 'formation', 'professionnelledes', 'compétences', 'machine', 'learning', 'sen', 'large', 'appréciéesprofil', 'recherché', 'data', 'architect', 'data', 'engineer', 'data', 'scientist', 'confirmé', 'aguerri', 'souhaitez', 'intégrer', 'équipe', 'jdynamique', 'relever', 'nouveaux', 'challenge', 'besoin', 'transversalité', 'dautonomie', 'être', 'cantonné', 'seule', 'tâche', 'curieux', 'souhaitez', 'explorer', 'données', 'provenance', 'différents', 'secteurs', 'industrie', 'finance', 'transport', 'servicevous', 'analyste', 'programmeur', 'curieux', 'savoir', 'différence', 'entre', 'base', 'données', 'entrepôt', 'données', 'envie', 'daller', 'plus', 'loin', 'simple', 'stockage', 'souhaitez', 'apprendre', 'valoriser', 'données', 'poste', 'permettra', 'épanouir', 'formation', 'technology', 'technique', 'business', 'intelligence', 'nhésitez', 'postuler', 'qualités', 'requises', 'couteau', 'suisseorganisé', 'réactif', 'rigoureuxetre', 'créatif', 'avoir', 'sen', 'linnovationavoir', 'état', 'desprit', 'analytique', 'synthèseforce', 'propositionbonus', 'mutuelle', 'prise', 'charge', 'accord', 'dintéressementvélo', 'électrique', 'fonction', 'demandeséance', 'sport', 'entreprise']\n"
     ]
    }
   ],
   "source": [
    "#retirer les token de moins de 3 lettres\n",
    "corpus_sw = [[mot for mot in doc if len(mot) >= 3] for doc in corpus_sw]\n",
    "print(corpus_sw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['description', 'poste', 'sein', 'dune', 'équipe', 'assurez', 'cycle', 'vie', 'application', 'développées', 'grand', 'challenge', 'technique', 'organisationnels', 'accompagner', 'client', 'transformation', 'leurs', 'simissions', 'principales', 'modéliser', 'traiter', 'transformer', 'données', 'complexesconcevoir', 'solution', 'stockage', 'données', 'modèle', 'étoiledévelopper', 'connecteurs', 'passerelles', 'données', 'laide', 'outils', 'etl', 'talendlire', 'comprendre', 'rédiger', 'document', 'technique', 'lien', 'poste', 'data', 'architect', 'data', 'engineer', 'dictionnaire', 'données', 'modélisation', 'merise', 'uml', 'matrice', 'busrester', 'jour', 'veille', 'différentes', 'technology', 'méthodes', 'liées', 'poste', 'data', 'architect', 'data', 'engineer', 'biais', 'lauto', 'formation', 'formation', 'professionnelledes', 'compétences', 'machine', 'learning', 'sen', 'large', 'appréciéesprofil', 'recherché', 'data', 'architect', 'data', 'engineer', 'data', 'scientist', 'confirmé', 'aguerri', 'souhaitez', 'intégrer', 'équipe', 'jeune', 'dynamique', 'relever', 'nouveaux', 'challenge', 'besoin', 'transversalité', 'dautonomie', 'être', 'cantonné', 'seule', 'tâche', 'curieux', 'souhaitez', 'explorer', 'données', 'provenance', 'différents', 'secteurs', 'industrie', 'finance', 'transport', 'service', 'analyste', 'programmeur', 'curieux', 'savoir', 'différence', 'entre', 'base', 'données', 'entrepôt', 'données', 'envie', 'daller', 'plus', 'loin', 'simple', 'stockage', 'souhaitez', 'apprendre', 'valoriser', 'données', 'poste', 'permettra', 'épanouir', 'formation', 'technology', 'technique', 'business', 'intelligence', 'nhésitez', 'postuler', 'qualités', 'requises', 'organisé', 'réactif', 'rigoureux', 'goût', 'travail', 'équipeetre', 'créatif', 'avoir', 'sen', 'linnovation', 'avoir', 'état', 'desprit', 'analytique', 'synthèseforce', 'propositionbonus', 'mutuelle', 'prise', 'charge', 'accord', 'dintéressementvélo', 'électrique', 'fonction', 'demande', 'séance', 'sport', 'entreprise']\n"
     ]
    }
   ],
   "source": [
    "print(corpus_sw[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['present', 'delipc', 'expert', 'développ', 'logiciel', 'dat', 'interpret', 'méti', 'elipc', 'position', 'efficac', 'opérationnel', 'business', 'intelligent', 'centr', 'servic', 'logiciel', 'accompagn', 'client', 'créon', 'solut', 'digital', 'adapt', 'correspondent', 'fonction', 'réalit', 'entrepris', 'proposon', 'égal', 'solut', 'dexternalis', 'permet', 'dassur', 'mainten', 'lévolu', 'développ', 'dappliqu', 'logiciel', 'compt', 'client', 'vi', 'mis', 'disposit', 'pool', 'compétent', 'sein', 'équip', 'client', 'plateau', 'techniqu', 'engageon', 'fourn', 'solut', 'qualit', 'promouvoir', 'linnov', 'cultiv', 'vérit', 'cohes', 'sein', 'équip', 'descript', 'post', 'sein', 'dun', 'équip', 'assur', 'cycl', 'vi', 'appliqu', 'développ', 'grand', 'challeng', 'techniqu', 'organisationnel', 'accompagn', 'client', 'transform', 'leur', 'mission', 'principal', 'modélis', 'trait', 'transform', 'don', 'complex', 'concevoir', 'solut', 'stockag', 'don', 'model', 'étoil', 'développ', 'connecteur', 'passerel', 'don', 'laid', 'outil', 'etl', 'talend', 'lir', 'comprendr', 'rédig', 'docu', 'techniqu', 'lien', 'post', 'dat', 'architect', 'dat', 'engine', 'dictionnair', 'don', 'modélis', 'meris', 'uml', 'matric', 'bus', 'rest', 'jour', 'veil', 'différent', 'technology', 'méthod', 'li', 'post', 'dat', 'architect', 'dat', 'engine', 'bi', 'lauto', 'format', 'format', 'professionnel', 'compétent', 'machin', 'learning', 'sen', 'larg', 'appréci', 'profil', 'recherch', 'dat', 'architect', 'dat', 'engine', 'dat', 'scientist', 'confirm', 'aguerr', 'souhait', 'integr', 'équip', 'jdynam', 'relev', 'nouveau', 'challeng', 'besoin', 'transversal', 'dautonom', 'être', 'canton', 'seul', 'tâch', 'curieux', 'souhait', 'explor', 'don', 'proven', 'différent', 'secteur', 'industr', 'financ', 'transport', 'servic', 'analyst', 'programmeur', 'curieux', 'savoir', 'différent', 'entre', 'bas', 'don', 'entrepôt', 'don', 'envi', 'dall', 'plus', 'loin', 'simpl', 'stockag', 'souhait', 'apprendr', 'valoris', 'don', 'post', 'permettr', 'épanou', 'format', 'technology', 'techniqu', 'business', 'intelligent', 'nhésit', 'postul', 'qualit', 'requis', 'couteau', 'suiss', 'organis', 'réactif', 'rigour', 'etre', 'créatif', 'avoir', 'sen', 'linnov', 'avoir', 'état', 'despr', 'analyt', 'synthes', 'forc', 'proposit', 'bonus', 'mutuel', 'pris', 'charg', '100', 'accord', 'dintéress', 'vélo', 'électr', 'fonction', 'demand', 'séanc', 'sport', 'entrepris']\n"
     ]
    }
   ],
   "source": [
    "#outil pour stemming - racinisation des termes, mais en français avec SnowballStemmer (\"french\"): c'est pas terrible!\n",
    "#stemmer_fr = SnowballStemmer(\"french\")\n",
    "\n",
    "#transformation par racinisation des mots:\n",
    "#corpus_stem = [[stemmer_fr.stem(mot) for mot in doc] for doc in corpus_sw]\n",
    "#print(corpus_stem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec avec Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presentation delipce experte développement logiciel data interprétation métier elipce positionne efficacité opérationnelle business intelligence centre service logicielspour accompagner client créons solution digitales adaptées correspondent fonctionnement réalité entreprise proposons également solution dexternalisation permettant dassurer maintenance lévolution développement dapplications logicielles compte client via mise disposition pool compétences sein équipes client plateau techniquesnous engageons fournir solution qualité promouvoir linnovation cultiver véritable cohésion sein équipedescription poste sein dune équipe assurez cycle vie application développées grand challenge technique organisationnels accompagner client transformation leurs simissions principales modéliser traiter transformer données complexesconcevoir solution stockage données modèle étoiledévelopper connecteurs passerelles données laide outils etl talendlire comprendre rédiger document technique lien poste data architect data engineer dictionnaire données modélisation merise uml matrice busrester jour veille différentes technology méthodes liées poste data architect data engineer biais lauto formation formation professionnelledes compétences machine learning sen large appréciéesprofil recherché data architect data engineer data scientist confirmé aguerri souhaitez intégrer équipe jdynamique relever nouveaux challenge besoin transversalité dautonomie être cantonné seule tâche curieux souhaitez explorer données provenance différents secteurs industrie finance transport servicevous analyste programmeur curieux savoir différence entre base données entrepôt données envie daller plus loin simple stockage souhaitez apprendre valoriser données poste permettra épanouir formation technology technique business intelligence nhésitez postuler qualités requises couteau suisseorganisé réactif rigoureuxetre créatif avoir sen linnovationavoir état desprit analytique synthèseforce propositionbonus mutuelle prise charge accord dintéressementvélo électrique fonction demandeséance sport entreprise\n"
     ]
    }
   ],
   "source": [
    "#reformer les documents sous forme de chaîne\n",
    "documents = [\" \".join(doc) for doc in corpus_sw]\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "#from gensim.models import Word2Vec\n",
    "#vector_size=2 pour projeter les termes dans 2 dimensions car je veux afficher une representation graphique\n",
    "#window=5 : on regarde les 5 plus proche voisins: les 5 termes qui précède le token(mot) d'intérêt, et les 5 suivants\n",
    "modele = Word2Vec(corpus_sw,vector_size=2,window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.word2vec.Word2Vec'>\n"
     ]
    }
   ],
   "source": [
    "#type de l'objet\n",
    "print(type(modele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_corpus_sanity',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_epoch',\n",
       " '_do_train_job',\n",
       " '_get_next_alpha',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_specials',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_scan_vocab',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_train_epoch_corpusfile',\n",
       " '_worker_loop',\n",
       " '_worker_loop_corpusfile',\n",
       " 'add_lifecycle_event',\n",
       " 'add_null_word',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'cbow_mean',\n",
       " 'comment',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'corpus_total_words',\n",
       " 'create_binary_tree',\n",
       " 'cum_table',\n",
       " 'effective_min_count',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'get_latest_training_loss',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'init_sims',\n",
       " 'init_weights',\n",
       " 'layer1_size',\n",
       " 'lifecycle_events',\n",
       " 'load',\n",
       " 'make_cum_table',\n",
       " 'max_final_vocab',\n",
       " 'max_vocab_size',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'negative',\n",
       " 'ns_exponent',\n",
       " 'null_word',\n",
       " 'predict_output_word',\n",
       " 'prepare_vocab',\n",
       " 'prepare_weights',\n",
       " 'random',\n",
       " 'raw_vocab',\n",
       " 'reset_from',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'scan_vocab',\n",
       " 'score',\n",
       " 'seed',\n",
       " 'seeded_vector',\n",
       " 'sg',\n",
       " 'shrink_windows',\n",
       " 'sorted_vocab',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'update_weights',\n",
       " 'vector_size',\n",
       " 'window',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#propriété de l'objet (méthodes):\n",
    "#wv est important: word vector= transcription en vecteur des différents termes qui composent l'ensemble des documents\n",
    "dir(modele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
     ]
    }
   ],
   "source": [
    "#propriété de \"wv\" -> wordvector\n",
    "words = modele.wv\n",
    "\n",
    "#type\n",
    "print(type(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_load_specials',\n",
       " '_log_evaluate_word_analogies',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " '_upconvert_old_d2vkv',\n",
       " '_upconvert_old_vocab',\n",
       " 'add_lifecycle_event',\n",
       " 'add_vector',\n",
       " 'add_vectors',\n",
       " 'allocate_vecattrs',\n",
       " 'closer_than',\n",
       " 'cosine_similarities',\n",
       " 'distance',\n",
       " 'distances',\n",
       " 'doesnt_match',\n",
       " 'evaluate_word_analogies',\n",
       " 'evaluate_word_pairs',\n",
       " 'expandos',\n",
       " 'fill_norms',\n",
       " 'get_index',\n",
       " 'get_mean_vector',\n",
       " 'get_normed_vectors',\n",
       " 'get_vecattr',\n",
       " 'get_vector',\n",
       " 'has_index_for',\n",
       " 'index2entity',\n",
       " 'index2word',\n",
       " 'index_to_key',\n",
       " 'init_sims',\n",
       " 'intersect_word2vec_format',\n",
       " 'key_to_index',\n",
       " 'load',\n",
       " 'load_word2vec_format',\n",
       " 'log_accuracy',\n",
       " 'log_evaluate_word_pairs',\n",
       " 'mapfile_path',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'most_similar_to_given',\n",
       " 'n_similarity',\n",
       " 'next_index',\n",
       " 'norms',\n",
       " 'rank',\n",
       " 'rank_by_centrality',\n",
       " 'relative_cosine_similarity',\n",
       " 'resize_vectors',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'set_vecattr',\n",
       " 'similar_by_key',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'similarity_unseen_docs',\n",
       " 'sort_by_descending_frequency',\n",
       " 'unit_normalize_all',\n",
       " 'vector_size',\n",
       " 'vectors',\n",
       " 'vectors_for_all',\n",
       " 'vectors_lockf',\n",
       " 'vectors_norm',\n",
       " 'vocab',\n",
       " 'wmdistance',\n",
       " 'word_vec',\n",
       " 'words_closer_than']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#les propriétés:\n",
    "dir(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 0,\n",
       " 'données': 1,\n",
       " 'solution': 2,\n",
       " 'mission': 3,\n",
       " 'scientist': 4,\n",
       " 'science': 5,\n",
       " 'développement': 6,\n",
       " 'modèles': 7,\n",
       " 'client': 8,\n",
       " 'learning': 9,\n",
       " 'technique': 10,\n",
       " 'plus': 11,\n",
       " 'sein': 12,\n",
       " 'machine': 13,\n",
       " 'équipe': 14,\n",
       " 'dune': 15,\n",
       " 'service': 16,\n",
       " 'dun': 17,\n",
       " 'poste': 18,\n",
       " 'recherche': 19,\n",
       " 'projets': 20,\n",
       " 'python': 21,\n",
       " 'expérience': 22,\n",
       " 'métiers': 23,\n",
       " 'formation': 24,\n",
       " 'équipes': 25,\n",
       " 'compétences': 26,\n",
       " 'léquipe': 27,\n",
       " 'projet': 28,\n",
       " 'groupe': 29,\n",
       " 'algorithmes': 30,\n",
       " 'développer': 31,\n",
       " 'besoins': 32,\n",
       " 'outils': 33,\n",
       " 'production': 34,\n",
       " 'notamment': 35,\n",
       " 'environnement': 36,\n",
       " 'participer': 37,\n",
       " 'également': 38,\n",
       " 'performance': 39,\n",
       " 'afin': 40,\n",
       " 'leurs': 41,\n",
       " 'business': 42,\n",
       " 'métier': 43,\n",
       " 'engineer': 44,\n",
       " 'être': 45,\n",
       " 'direction': 46,\n",
       " 'cadre': 47,\n",
       " 'tant': 48,\n",
       " 'chez': 49,\n",
       " 'modélisation': 50,\n",
       " 'travail': 51,\n",
       " 'mise': 52,\n",
       " 'produits': 53,\n",
       " 'mettre': 54,\n",
       " 'méthodes': 55,\n",
       " 'veille': 56,\n",
       " 'statistiques': 57,\n",
       " 'technology': 58,\n",
       " 'nouveaux': 59,\n",
       " 'gestion': 60,\n",
       " 'différents': 61,\n",
       " 'expertise': 62,\n",
       " 'cest': 63,\n",
       " 'artificielle': 64,\n",
       " 'résultats': 65,\n",
       " 'accompagner': 66,\n",
       " 'qualité': 67,\n",
       " 'domaines': 68,\n",
       " 'etc': 69,\n",
       " 'domaine': 70,\n",
       " 'faire': 71,\n",
       " 'analyser': 72,\n",
       " 'travailler': 73,\n",
       " 'lensemble': 74,\n",
       " 'systèmes': 75,\n",
       " 'rejoindre': 76,\n",
       " 'niveau': 77,\n",
       " 'processus': 78,\n",
       " 'traitement': 79,\n",
       " 'collaboration': 80,\n",
       " 'problématiques': 81,\n",
       " 'connaissances': 82,\n",
       " 'complex': 83,\n",
       " 'entre': 84,\n",
       " 'intelligence': 85,\n",
       " 'bac': 86,\n",
       " 'fonction': 87,\n",
       " 'contribuer': 88,\n",
       " 'collaborateurs': 89,\n",
       " 'base': 90,\n",
       " 'cloud': 91,\n",
       " 'comprendre': 92,\n",
       " 'entreprise': 93,\n",
       " 'nouvelles': 94,\n",
       " 'interne': 95,\n",
       " 'sql': 96,\n",
       " 'communication': 97,\n",
       " 'place': 98,\n",
       " 'profil': 99,\n",
       " 'ainsi': 100,\n",
       " 'grande': 101,\n",
       " 'concevoir': 102,\n",
       " 'visualisation': 103,\n",
       " 'vision': 104,\n",
       " 'valeur': 105,\n",
       " 'lutilisation': 106,\n",
       " 'moins': 107,\n",
       " 'danalyse': 108,\n",
       " 'charge': 109,\n",
       " 'activités': 110,\n",
       " 'sujets': 111,\n",
       " 'opérationnelle': 112,\n",
       " 'application': 113,\n",
       " 'somme': 114,\n",
       " 'capacité': 115,\n",
       " 'permettant': 116,\n",
       " 'lead': 117,\n",
       " 'souhaitez': 118,\n",
       " 'dapprentissage': 119,\n",
       " 'minimum': 120,\n",
       " 'transformation': 121,\n",
       " 'quotidien': 122,\n",
       " 'vie': 123,\n",
       " 'marketing': 124,\n",
       " 'assurer': 125,\n",
       " 'analyse': 126,\n",
       " 'deep': 127,\n",
       " 'conception': 128,\n",
       " 'principales': 129,\n",
       " 'informatique': 130,\n",
       " 'pratiques': 131,\n",
       " 'transport': 132,\n",
       " 'cette': 133,\n",
       " 'technologique': 134,\n",
       " 'lanalyse': 135,\n",
       " 'enjeux': 136,\n",
       " 'bonnes': 137,\n",
       " 'grâce': 138,\n",
       " 'plateforme': 139,\n",
       " 'sen': 140,\n",
       " 'cycle': 141,\n",
       " 'analysis': 142,\n",
       " 'œuvre': 143,\n",
       " 'professionnelle': 144,\n",
       " 'diversité': 145,\n",
       " 'conseil': 146,\n",
       " 'personnes': 147,\n",
       " 'problèmes': 148,\n",
       " 'prise': 149,\n",
       " 'valoway': 150,\n",
       " 'spark': 151,\n",
       " 'identifier': 152,\n",
       " 'logiciel': 153,\n",
       " 'langages': 154,\n",
       " 'donnée': 155,\n",
       " 'consultant': 156,\n",
       " 'intégrer': 157,\n",
       " 'tout': 158,\n",
       " 'utilisateurs': 159,\n",
       " 'autres': 160,\n",
       " 'azure': 161,\n",
       " 'création': 162,\n",
       " 'maintenance': 163,\n",
       " 'maîtrise': 164,\n",
       " 'communiquer': 165,\n",
       " 'recherchons': 166,\n",
       " 'auprès': 167,\n",
       " 'gcp': 168,\n",
       " 'savoir': 169,\n",
       " 'connaissance': 170,\n",
       " 'agile': 171,\n",
       " 'automatique': 172,\n",
       " 'serum': 173,\n",
       " 'code': 174,\n",
       " 'très': 175,\n",
       " 'répondre': 176,\n",
       " 'dexpérience': 177,\n",
       " 'cœur': 178,\n",
       " 'suivi': 179,\n",
       " 'statistique': 180,\n",
       " 'mener': 181,\n",
       " 'aussi': 182,\n",
       " 'france': 183,\n",
       " 'lia': 184,\n",
       " 'non': 185,\n",
       " 'optimiser': 186,\n",
       " 'etou': 187,\n",
       " 'lien': 188,\n",
       " 'créer': 189,\n",
       " 'travaux': 190,\n",
       " 'manière': 191,\n",
       " 'réalisation': 192,\n",
       " 'loptimisation': 193,\n",
       " 'digital': 194,\n",
       " 'télétravail': 195,\n",
       " 'contexte': 196,\n",
       " 'déploiement': 197,\n",
       " 'pôle': 198,\n",
       " 'risques': 199,\n",
       " 'aimez': 200,\n",
       " 'risque': 201,\n",
       " 'participation': 202,\n",
       " 'évoluer': 203,\n",
       " 'description': 204,\n",
       " 'avancées': 205,\n",
       " 'culture': 206,\n",
       " 'communauté': 207,\n",
       " 'devops': 208,\n",
       " 'lentreprise': 209,\n",
       " 'temp': 210,\n",
       " 'big': 211,\n",
       " 'première': 212,\n",
       " 'analytics': 213,\n",
       " 'lab': 214,\n",
       " 'participerez': 215,\n",
       " 'selon': 216,\n",
       " 'responsable': 217,\n",
       " 'tous': 218,\n",
       " 'support': 219,\n",
       " 'produit': 220,\n",
       " 'carrefour': 221,\n",
       " 'avantages': 222,\n",
       " 'cdi': 223,\n",
       " 'tels': 224,\n",
       " 'réaliser': 225,\n",
       " 'maitrisez': 226,\n",
       " 'mesure': 227,\n",
       " 'environnements': 228,\n",
       " 'aws': 229,\n",
       " 'forte': 230,\n",
       " 'optimisation': 231,\n",
       " 'comme': 232,\n",
       " 'expert': 233,\n",
       " 'team': 234,\n",
       " 'résoudre': 235,\n",
       " 'santé': 236,\n",
       " 'savez': 237,\n",
       " 'opérationnelles': 238,\n",
       " 'proposition': 239,\n",
       " 'linnovation': 240,\n",
       " 'lindustrialisation': 241,\n",
       " 'département': 242,\n",
       " 'partie': 243,\n",
       " 'évolutions': 244,\n",
       " 'différentes': 245,\n",
       " 'engineering': 246,\n",
       " 'rémunération': 247,\n",
       " 'ensemble': 248,\n",
       " 'proposer': 249,\n",
       " 'innovantes': 250,\n",
       " 'tableau': 251,\n",
       " 'via': 252,\n",
       " 'recrutement': 253,\n",
       " 'anglais': 254,\n",
       " 'offre': 255,\n",
       " 'compte': 256,\n",
       " 'proposons': 257,\n",
       " 'dataiku': 258,\n",
       " 'challenge': 259,\n",
       " 'prévision': 260,\n",
       " 'collecter': 261,\n",
       " 'autour': 262,\n",
       " 'technologie': 263,\n",
       " 'force': 264,\n",
       " 'rejoignez': 265,\n",
       " 'information': 266,\n",
       " 'modèle': 267,\n",
       " 'preuve': 268,\n",
       " 'financier': 269,\n",
       " 'computer': 270,\n",
       " 'part': 271,\n",
       " 'industrie': 272,\n",
       " 'lexpérience': 273,\n",
       " 'maîtrisez': 274,\n",
       " 'dintelligence': 275,\n",
       " 'documenter': 276,\n",
       " 'thales': 277,\n",
       " 'croissance': 278,\n",
       " 'programmation': 279,\n",
       " 'tensorflow': 280,\n",
       " 'jours': 281,\n",
       " 'scikitlearn': 282,\n",
       " 'datascience': 283,\n",
       " 'grand': 284,\n",
       " 'pipeline': 285,\n",
       " 'recherché': 286,\n",
       " 'dingénieur': 287,\n",
       " 'organisation': 288,\n",
       " 'langage': 289,\n",
       " 'safran': 290,\n",
       " 'collecte': 291,\n",
       " 'société': 292,\n",
       " 'programme': 293,\n",
       " 'chaque': 294,\n",
       " 'jour': 295,\n",
       " 'autonomie': 296,\n",
       " 'master': 297,\n",
       " 'lindustrie': 298,\n",
       " 'panda': 299,\n",
       " 'depuis': 300,\n",
       " 'cela': 301,\n",
       " 'peut': 302,\n",
       " 'système': 303,\n",
       " 'monde': 304,\n",
       " 'bonne': 305,\n",
       " 'possibilité': 306,\n",
       " 'défis': 307,\n",
       " 'idéalement': 308,\n",
       " 'dau': 309,\n",
       " 'public': 310,\n",
       " 'toutes': 311,\n",
       " 'ingénieur': 312,\n",
       " 'type': 313,\n",
       " 'scientifique': 314,\n",
       " 'fois': 315,\n",
       " 'partage': 316,\n",
       " 'lintelligence': 317,\n",
       " 'mode': 318,\n",
       " 'atelier': 319,\n",
       " 'travaillerez': 320,\n",
       " 'conférences': 321,\n",
       " 'impact': 322,\n",
       " 'bénéficierez': 323,\n",
       " 'validation': 324,\n",
       " 'suivantes': 325,\n",
       " 'dynamique': 326,\n",
       " 'parcours': 327,\n",
       " 'mathématiques': 328,\n",
       " 'pytorch': 329,\n",
       " 'analytique': 330,\n",
       " 'prix': 331,\n",
       " 'java': 332,\n",
       " 'rôle': 333,\n",
       " 'principaux': 334,\n",
       " 'continue': 335,\n",
       " 'alors': 336,\n",
       " 'basé': 337,\n",
       " 'large': 338,\n",
       " 'améliorer': 339,\n",
       " 'moteurs': 340,\n",
       " 'sécurité': 341,\n",
       " 'doptimisation': 342,\n",
       " 'diver': 343,\n",
       " 'relation': 344,\n",
       " 'besoin': 345,\n",
       " 'oeuvre': 346,\n",
       " 'architect': 347,\n",
       " 'détection': 348,\n",
       " 'test': 349,\n",
       " 'travers': 350,\n",
       " 'nlp': 351,\n",
       " 'partenaires': 352,\n",
       " 'bien': 353,\n",
       " 'flux': 354,\n",
       " 'liées': 355,\n",
       " 'amené': 356,\n",
       " 'savoirfaire': 357,\n",
       " 'significative': 358,\n",
       " 'externes': 359,\n",
       " 'définition': 360,\n",
       " 'étroite': 361,\n",
       " 'concept': 362,\n",
       " 'dont': 363,\n",
       " 'stage': 364,\n",
       " 'candidature': 365,\n",
       " 'cadrage': 366,\n",
       " 'stratégie': 367,\n",
       " 'transverses': 368,\n",
       " 'années': 369,\n",
       " 'mutuelle': 370,\n",
       " 'accord': 371,\n",
       " 'déjà': 372,\n",
       " 'dexcellence': 373,\n",
       " 'pertinents': 374,\n",
       " 'esprit': 375,\n",
       " 'expériences': 376,\n",
       " 'petite': 377,\n",
       " 'succès': 378,\n",
       " 'valeurs': 379,\n",
       " 'structure': 380,\n",
       " 'talent': 381,\n",
       " 'nécessaire': 382,\n",
       " 'interagir': 383,\n",
       " 'déquipe': 384,\n",
       " 'mois': 385,\n",
       " 'développées': 386,\n",
       " 'décision': 387,\n",
       " 'définir': 388,\n",
       " 'présenter': 389,\n",
       " 'rapport': 390,\n",
       " 'site': 391,\n",
       " 'école': 392,\n",
       " 'efficace': 393,\n",
       " 'prédictive': 394,\n",
       " 'process': 395,\n",
       " 'source': 396,\n",
       " 'phase': 397,\n",
       " 'assurerez': 398,\n",
       " 'vulgariser': 399,\n",
       " 'déployer': 400,\n",
       " 'qualités': 401,\n",
       " 'maitrise': 402,\n",
       " 'secteurs': 403,\n",
       " 'management': 404,\n",
       " 'échange': 405,\n",
       " 'construction': 406,\n",
       " 'réseau': 407,\n",
       " 'bon': 408,\n",
       " 'distribution': 409,\n",
       " 'capable': 410,\n",
       " 'infrastructure': 411,\n",
       " 'plusieurs': 412,\n",
       " 'carrière': 413,\n",
       " 'opportunités': 414,\n",
       " 'enfance': 415,\n",
       " 'descriptif': 416,\n",
       " 'autonome': 417,\n",
       " 'collaborer': 418,\n",
       " 'compréhension': 419,\n",
       " 'fraude': 420,\n",
       " 'donc': 421,\n",
       " 'activité': 422,\n",
       " 'montée': 423,\n",
       " 'internationale': 424,\n",
       " 'dinformation': 425,\n",
       " 'international': 426,\n",
       " 'fait': 427,\n",
       " 'augmented': 428,\n",
       " 'profils': 429,\n",
       " 'critique': 430,\n",
       " 'paris': 431,\n",
       " 'retail': 432,\n",
       " 'exploiter': 433,\n",
       " 'avon': 434,\n",
       " 'dapplication': 435,\n",
       " 'prédiction': 436,\n",
       " 'poc': 437,\n",
       " 'google': 438,\n",
       " 'consultante': 439,\n",
       " 'yann': 440,\n",
       " 'lenvironnement': 441,\n",
       " 'factory': 442,\n",
       " 'valoriser': 443,\n",
       " 'ventes': 444,\n",
       " 'relationnel': 445,\n",
       " 'pourrez': 446,\n",
       " 'mieux': 447,\n",
       " 'requises': 448,\n",
       " 'qualification': 449,\n",
       " 'ingénieurs': 450,\n",
       " 'desprit': 451,\n",
       " 'curiosité': 452,\n",
       " 'opportunité': 453,\n",
       " 'rigueur': 454,\n",
       " 'préparation': 455,\n",
       " 'opérationnels': 456,\n",
       " 'long': 457,\n",
       " 'rupture': 458,\n",
       " 'loffre': 459,\n",
       " 'référent': 460,\n",
       " 'contrôle': 461,\n",
       " 'recrutons': 462,\n",
       " 'contraintes': 463,\n",
       " 'document': 464,\n",
       " 'partager': 465,\n",
       " 'disposez': 466,\n",
       " 'lévolution': 467,\n",
       " 'future': 468,\n",
       " 'ambition': 469,\n",
       " 'développeurs': 470,\n",
       " 'fonctionnement': 471,\n",
       " 'relever': 472,\n",
       " 'plan': 473,\n",
       " 'dia': 474,\n",
       " 'proposant': 475,\n",
       " 'mlops': 476,\n",
       " 'intégrerez': 477,\n",
       " 'dentreprise': 478,\n",
       " 'commerciaux': 479,\n",
       " 'curieux': 480,\n",
       " 'orange': 481,\n",
       " 'traduire': 482,\n",
       " 'laise': 483,\n",
       " 'intégrant': 484,\n",
       " 'capacités': 485,\n",
       " 'construire': 486,\n",
       " 'compris': 487,\n",
       " 'peux': 488,\n",
       " 'bienvenue': 489,\n",
       " 'acteur': 490,\n",
       " 'implémenter': 491,\n",
       " 'produire': 492,\n",
       " 'aide': 493,\n",
       " 'choix': 494,\n",
       " 'postuler': 495,\n",
       " 'maintenir': 496,\n",
       " 'dêtre': 497,\n",
       " 'toujours': 498,\n",
       " 'industriels': 499,\n",
       " 'membres': 500,\n",
       " 'rattachée': 501,\n",
       " 'référence': 502,\n",
       " 'transformer': 503,\n",
       " 'assurez': 504,\n",
       " 'partir': 505,\n",
       " 'justifiez': 506,\n",
       " 'offres': 507,\n",
       " 'approche': 508,\n",
       " 'spécialisé': 509,\n",
       " 'appliquée': 510,\n",
       " 'guider': 511,\n",
       " 'tech': 512,\n",
       " 'llm': 513,\n",
       " 'échanges': 514,\n",
       " 'mathématique': 515,\n",
       " 'moteur': 516,\n",
       " 'julien': 517,\n",
       " 'responsabilité': 518,\n",
       " 'classification': 519,\n",
       " 'stratégiques': 520,\n",
       " 'réseaux': 521,\n",
       " 'prime': 522,\n",
       " 'sans': 523,\n",
       " 'premier': 524,\n",
       " 'dautres': 525,\n",
       " 'junior': 526,\n",
       " 'docker': 527,\n",
       " 'expérimenté': 528,\n",
       " 'français': 529,\n",
       " 'savoirs': 530,\n",
       " 'faciliter': 531,\n",
       " 'variés': 532,\n",
       " 'bureau': 533,\n",
       " 'dusages': 534,\n",
       " 'participez': 535,\n",
       " 'cabinet': 536,\n",
       " 'pilotage': 537,\n",
       " 'respect': 538,\n",
       " 'ligne': 539,\n",
       " 'diplôme': 540,\n",
       " 'sou': 541,\n",
       " 'possédez': 542,\n",
       " 'donnéesvous': 543,\n",
       " 'létat': 544,\n",
       " 'jusquà': 545,\n",
       " 'entretien': 546,\n",
       " 'alice': 547,\n",
       " 'secteur': 548,\n",
       " 'pratique': 549,\n",
       " 'disposition': 550,\n",
       " 'promouvoir': 551,\n",
       " 'professionnels': 552,\n",
       " 'état': 553,\n",
       " 'dassurer': 554,\n",
       " 'modéliser': 555,\n",
       " 'principalement': 556,\n",
       " 'dusage': 557,\n",
       " 'adaptées': 558,\n",
       " 'digitales': 559,\n",
       " 'défense': 560,\n",
       " 'évaluation': 561,\n",
       " 'traiter': 562,\n",
       " 'utilisation': 563,\n",
       " 'stockage': 564,\n",
       " 'chaîne': 565,\n",
       " 'objectifs': 566,\n",
       " 'consistera': 567,\n",
       " 'solide': 568,\n",
       " 'cherchez': 569,\n",
       " 'finance': 570,\n",
       " 'différence': 571,\n",
       " 'manager': 572,\n",
       " 'sport': 573,\n",
       " 'avoir': 574,\n",
       " 'personnalisation': 575,\n",
       " 'équipements': 576,\n",
       " 'familier': 577,\n",
       " 'bénéficiez': 578,\n",
       " 'datalab': 579,\n",
       " 'situation': 580,\n",
       " 'matière': 581,\n",
       " 'démarche': 582,\n",
       " 'pourvoir': 583,\n",
       " 'monitoring': 584,\n",
       " 'apprentissage': 585,\n",
       " 'pertinentes': 586,\n",
       " 'algorithmie': 587,\n",
       " 'demandes': 588,\n",
       " 'faires': 589,\n",
       " 'résolution': 590,\n",
       " 'kera': 591,\n",
       " 'scala': 592,\n",
       " 'certains': 593,\n",
       " 'technologiques': 594,\n",
       " 'product': 595,\n",
       " 'kubernetes': 596,\n",
       " 'vue': 597,\n",
       " 'carte': 598,\n",
       " 'aujourdhui': 599,\n",
       " 'partagée': 600,\n",
       " 'power': 601,\n",
       " 'software': 602,\n",
       " 'banque': 603,\n",
       " 'salaire': 604,\n",
       " 'deux': 605,\n",
       " 'rtt': 606,\n",
       " 'professionnel': 607,\n",
       " 'possible': 608,\n",
       " 'aperçu': 609,\n",
       " 'durée': 610,\n",
       " 'générative': 611,\n",
       " 'indicateurs': 612,\n",
       " 'particulier': 613,\n",
       " 'ouverts': 614,\n",
       " 'orientation': 615,\n",
       " 'lamélioration': 616,\n",
       " 'régulière': 617,\n",
       " 'fort': 618,\n",
       " 'structuration': 619,\n",
       " 'informatiques': 620,\n",
       " 'sûr': 621,\n",
       " 'permettent': 622,\n",
       " 'quelques': 623,\n",
       " 'scientifiques': 624,\n",
       " 'accompagne': 625,\n",
       " 'claire': 626,\n",
       " 'doffres': 627,\n",
       " 'crédit': 628,\n",
       " 'cybersécurité': 629,\n",
       " 'réponses': 630,\n",
       " 'dinnovation': 631,\n",
       " 'faisant': 632,\n",
       " 'entreprises': 633,\n",
       " 'propose': 634,\n",
       " 'titulaire': 635,\n",
       " 'propulsion': 636,\n",
       " 'contrat': 637,\n",
       " 'cohérence': 638,\n",
       " 'favoriser': 639,\n",
       " 'aimes': 640,\n",
       " 'bancaires': 641,\n",
       " 'directeur': 642,\n",
       " 'légalité': 643,\n",
       " 'prendrez': 644,\n",
       " 'intervenants': 645,\n",
       " 'article': 646,\n",
       " 'fournir': 647,\n",
       " 'prédictifs': 648,\n",
       " 'évaluer': 649,\n",
       " 'doté': 650,\n",
       " 'particulièrement': 651,\n",
       " 'lélaboration': 652,\n",
       " 'annuel': 653,\n",
       " 'brut': 654,\n",
       " 'développements': 655,\n",
       " 'saur': 656,\n",
       " 'lassurance': 657,\n",
       " 'haut': 658,\n",
       " 'débats': 659,\n",
       " 'rester': 660,\n",
       " 'traduit': 661,\n",
       " 'challenger': 662,\n",
       " 'lart': 663,\n",
       " 'rassemblant': 664,\n",
       " 'mining': 665,\n",
       " 'travaillez': 666,\n",
       " 'résultat': 667,\n",
       " 'indispensable': 668,\n",
       " 'telles': 669,\n",
       " 'envie': 670,\n",
       " 'volume': 671,\n",
       " 'rejoindrez': 672,\n",
       " 'appliquées': 673,\n",
       " 'danone': 674,\n",
       " 'synthèse': 675,\n",
       " 'bord': 676,\n",
       " 'simulation': 677,\n",
       " 'git': 678,\n",
       " 'owner': 679,\n",
       " 'transverse': 680,\n",
       " 'mobile': 681,\n",
       " 'biais': 682,\n",
       " 'séminaires': 683,\n",
       " 'démarrage': 684,\n",
       " 'marque': 685,\n",
       " 'similaire': 686,\n",
       " 'lassortiment': 687,\n",
       " 'antifraude': 688,\n",
       " 'utilisé': 689,\n",
       " 'contribution': 690,\n",
       " 'magasin': 691,\n",
       " 'cicd': 692,\n",
       " 'recueillir': 693,\n",
       " 'nrj': 694,\n",
       " 'approches': 695,\n",
       " 'nettoyage': 696,\n",
       " 'évolution': 697,\n",
       " 'intégration': 698,\n",
       " 'industrialisation': 699,\n",
       " 'dintégration': 700,\n",
       " 'ouvert': 701,\n",
       " 'particuliers': 702,\n",
       " 'prestations': 703,\n",
       " 'continu': 704,\n",
       " 'animer': 705,\n",
       " 'cse': 706,\n",
       " 'vers': 707,\n",
       " 'équivalent': 708,\n",
       " 'séries': 709,\n",
       " 'temporelles': 710,\n",
       " 'ingénierie': 711,\n",
       " 'accessible': 712,\n",
       " 'perspective': 713,\n",
       " 'sélectionner': 714,\n",
       " 'sengage': 715,\n",
       " 'motivé': 716,\n",
       " 'humaine': 717,\n",
       " 'développerez': 718,\n",
       " 'jenkins': 719,\n",
       " 'collectif': 720,\n",
       " 'pay': 721,\n",
       " 'marchés': 722,\n",
       " 'apporter': 723,\n",
       " 'met': 724,\n",
       " 'collaboratifs': 725,\n",
       " 'soutien': 726,\n",
       " 'lactivité': 727,\n",
       " 'discussion': 728,\n",
       " 'spécialisée': 729,\n",
       " 'main': 730,\n",
       " 'question': 731,\n",
       " 'spécialisation': 732,\n",
       " 'langlais': 733,\n",
       " 'module': 734,\n",
       " 'ambitieux': 735,\n",
       " 'concernant': 736,\n",
       " 'scoring': 737,\n",
       " 'objectif': 738,\n",
       " 'solides': 739,\n",
       " 'prévisions': 740,\n",
       " 'partenariats': 741,\n",
       " 'ladoption': 742,\n",
       " 'développé': 743,\n",
       " 'danglais': 744,\n",
       " 'analystes': 745,\n",
       " 'leader': 746,\n",
       " 'framework': 747,\n",
       " 'choisir': 748,\n",
       " 'digitale': 749,\n",
       " 'expérimenter': 750,\n",
       " 'appels': 751,\n",
       " 'réel': 752,\n",
       " 'aventure': 753,\n",
       " 'limites': 754,\n",
       " 'développés': 755,\n",
       " 'active': 756,\n",
       " 'ecommerce': 757,\n",
       " 'centrales': 758,\n",
       " 'gouvernance': 759,\n",
       " 'composée': 760,\n",
       " 'seul': 761,\n",
       " 'numériques': 762,\n",
       " 'moment': 763,\n",
       " 'utiliser': 764,\n",
       " 'meilleurs': 765,\n",
       " 'étroitement': 766,\n",
       " 'top': 767,\n",
       " 'voici': 768,\n",
       " 'contribuez': 769,\n",
       " 'permet': 770,\n",
       " 'passant': 771,\n",
       " 'intervenir': 772,\n",
       " 'surveillance': 773,\n",
       " 'nécessaires': 774,\n",
       " 'mondial': 775,\n",
       " 'stratégique': 776,\n",
       " 'rédiger': 777,\n",
       " 'connaitre': 778,\n",
       " 'prototypage': 779,\n",
       " 'lutte': 780,\n",
       " 'quelle': 781,\n",
       " 'dernières': 782,\n",
       " 'documentation': 783,\n",
       " 'quà': 784,\n",
       " 'instance': 785,\n",
       " 'prototype': 786,\n",
       " 'dalgorithmes': 787,\n",
       " 'après': 788,\n",
       " 'veillant': 789,\n",
       " 'effectuer': 790,\n",
       " 'arrivée': 791,\n",
       " 'vekia': 792,\n",
       " 'compétence': 793,\n",
       " 'assurantiels': 794,\n",
       " 'existants': 795,\n",
       " 'détudes': 796,\n",
       " 'réussie': 797,\n",
       " 'laide': 798,\n",
       " 'position': 799,\n",
       " 'liés': 800,\n",
       " 'changement': 801,\n",
       " 'alternance': 802,\n",
       " 'contribuerez': 803,\n",
       " 'numérique': 804,\n",
       " 'devient': 805,\n",
       " 'prototyper': 806,\n",
       " 'prêt': 807,\n",
       " 'pendant': 808,\n",
       " 'ops': 809,\n",
       " 'avancée': 810,\n",
       " 'amenée': 811,\n",
       " 'etl': 812,\n",
       " 'retours': 813,\n",
       " 'stack': 814,\n",
       " 'transmettre': 815,\n",
       " 'assurance': 816,\n",
       " 'utilisés': 817,\n",
       " 'briques': 818,\n",
       " 'restitution': 819,\n",
       " 'senior': 820,\n",
       " 'corp': 821,\n",
       " 'haute': 822,\n",
       " 'pointe': 823,\n",
       " 'collaborez': 824,\n",
       " 'passion': 825,\n",
       " 'favorisant': 826,\n",
       " 'ouverture': 827,\n",
       " 'postes': 828,\n",
       " 'congés': 829,\n",
       " 'chance': 830,\n",
       " 'semaine': 831,\n",
       " 'décisions': 832,\n",
       " 'cours': 833,\n",
       " 'rejoigneznous': 834,\n",
       " 'structurer': 835,\n",
       " 'sadapter': 836,\n",
       " 'activement': 837,\n",
       " 'présence': 838,\n",
       " 'davantvente': 839,\n",
       " 'communautés': 840,\n",
       " 'dactivités': 841,\n",
       " 'parle': 842,\n",
       " 'pouvoir': 843,\n",
       " 'collaborateur': 844,\n",
       " 'puissance': 845,\n",
       " 'microsoft': 846,\n",
       " 'restaurant': 847,\n",
       " 'tester': 848,\n",
       " 'spécifiques': 849,\n",
       " 'équivalente': 850,\n",
       " 'nombreux': 851,\n",
       " 'swile': 852,\n",
       " 'enjeu': 853,\n",
       " 'lécrit': 854,\n",
       " 'souhaite': 855,\n",
       " 'recherches': 856,\n",
       " 'manipulation': 857,\n",
       " 'dsi': 858,\n",
       " 'sujet': 859,\n",
       " 'mondiaux': 860,\n",
       " 'dashboard': 861,\n",
       " 'lefficacité': 862,\n",
       " 'idées': 863,\n",
       " 'partenaire': 864,\n",
       " 'rse': 865,\n",
       " 'meilleures': 866,\n",
       " 'pris': 867,\n",
       " 'diffusion': 868,\n",
       " 'maintien': 869,\n",
       " 'aider': 870,\n",
       " 'contenus': 871,\n",
       " 'consommation': 872,\n",
       " 'dingénieurs': 873,\n",
       " 'nest': 874,\n",
       " 'permettra': 875,\n",
       " 'somfy': 876,\n",
       " 'apprendre': 877,\n",
       " 'exemple': 878,\n",
       " 'alimentation': 879,\n",
       " 'nettoyer': 880,\n",
       " 'ecole': 881,\n",
       " 'adapter': 882,\n",
       " 'participé': 883,\n",
       " 'responsabilités': 884,\n",
       " 'lintégration': 885,\n",
       " 'champ': 886,\n",
       " 'engine': 887,\n",
       " 'concrètes': 888,\n",
       " 'bigquery': 889,\n",
       " 'exploitation': 890,\n",
       " 'lunivers': 891,\n",
       " 'environnemental': 892,\n",
       " 'horizon': 893,\n",
       " 'airflow': 894,\n",
       " 'handicap': 895,\n",
       " 'reconnues': 896,\n",
       " 'politique': 897,\n",
       " 'terraform': 898,\n",
       " 'courant': 899,\n",
       " 'études': 900,\n",
       " 'langue': 901}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#affichage des termes de leur index\n",
    "words.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4913917 1.4793843]\n"
     ]
    }
   ],
   "source": [
    "#coordonnées du terme 'data'\n",
    "vec1 = words['data']\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.28792   1.2293696]\n"
     ]
    }
   ],
   "source": [
    "#coordonnées de 'analyser'\n",
    "vec2 = words['analyser']\n",
    "print(vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847484"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarité cosinus entre 'data' et 'analyser': pour voir si ils sont proche dans l'espace de représentation:\n",
    "#ils sont proches car similarité proche de 1\n",
    "words.similarity('data','analyser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('expérimenté', 1.0),\n",
       " ('liées', 0.9999999403953552),\n",
       " ('dun', 0.9999999403953552),\n",
       " ('marketing', 0.9999999403953552),\n",
       " ('maîtrise', 0.9999998807907104),\n",
       " ('participerez', 0.9999997615814209),\n",
       " ('recherchons', 0.9999991059303284),\n",
       " ('expérience', 0.9999989867210388),\n",
       " ('stratégiques', 0.9999982714653015),\n",
       " ('être', 0.9999979138374329)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#les termes les plus proches de \"data\"\n",
    "words.most_similar(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pay', 0.9999998211860657), ('développement', 0.9999995231628418), ('opérationnels', 0.9999983906745911), ('appliquées', 0.9999983310699463)]\n"
     ]
    }
   ],
   "source": [
    "#plus proches de la conjonction de \"data\" et \"anlyser\"\n",
    "#l'algo regarde le baricentre des deux termes et renvoie les termes les plus proches:\n",
    "print(words.most_similar(positive=['data','analyser'],topn=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dactivités', 0.9975885152816772), ('lart', 0.9971565008163452), ('compétence', 0.9836879372596741), ('activement', 0.9718143939971924)]\n"
     ]
    }
   ],
   "source": [
    "#plus proches de \"data\", loin de (\"analyser\")\n",
    "print(words.most_similar(positive=['data'],negative=['analyser'],topn=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 V1        V2\n",
      "data       4.491392  1.479384\n",
      "données    4.667695  1.968462\n",
      "solution   3.779600  1.074003\n",
      "mission    3.578980  1.584622\n",
      "scientist  2.933786  0.870230\n",
      "...             ...       ...\n",
      "politique  0.996916  0.569636\n",
      "terraform  0.367041  0.045500\n",
      "courant    0.735636 -0.163554\n",
      "études     1.017359 -0.315529\n",
      "langue     0.156077  0.305325\n",
      "\n",
      "[902 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#récupérer les données dans un data frame\n",
    "df = pd.DataFrame(words.vectors,columns=['V1','V2'],index=words.key_to_index.keys())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 V1        V2\n",
      "data       4.491392  1.479384\n",
      "analyser   2.287920  1.229370\n",
      "données    4.667695  1.968462\n",
      "scientist  2.933786  0.870230\n",
      "engineer   2.175416  1.114539\n"
     ]
    }
   ],
   "source": [
    "#quelques mots clés\n",
    "mots = ['data','analyser','données','scientist','engineer']\n",
    "dfMots = df.loc[mots,:]\n",
    "print(dfMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graphique dans le plan\n",
    "plt.scatter(dfMots.V1,dfMots.V2,s=0.5)\n",
    "for i in range(dfMots.shape[0]):\n",
    "    plt.annotate(dfMots.index[i],(dfMots.V1[i],dfMots.V2[i]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "natachaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
